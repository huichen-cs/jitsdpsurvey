# Summary of JIT-SDP Studies

This table lists JIT-SDP studies and for each, we provide a one-sentence
summary and assign a category of the following 4 categories,
1. Model. The study proposes a new JIT-SDP model.
2. Feature/Metrics. The study proposes a new software metrics or examines existing ones
	 in JIT-SDP
3. Tool. The study proposes a new JIT-SDP tool or system.
4. Field Test. The study investigates effectiveness JIT-SDP in a particular
	 domain of software applications.

| No.| Author              | Category                                   | Summary                                                                                                                                                                                                                                                                    |
| -- | ------------------- | ------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1  | Duan et al.         | Noise reduction                            | impact of duplicate changes, i.e., identical changes applied to multiple SCM branches on prediction performance                                                                                                                                                            |
| 2  | Zhao et al.         | Within-project model, application domain   | assessment of a custom deep forest model for Android mobile apps                                                                                                                                                                                                           |
| 3  | Hoang et al.        | Model, feature representation              | Building a convolutional network to extract feature representations of software changes considering change structure and to use the features for defect prediction                                                                                                         |
| 4  | Kang et al.         | SDLC, application domain                   | within and cross-project SDP comparison and costbenefit analysis for post-release changes in maritime software                                                                                                                                                             |
| 5  | Tabassum et al.     | Cross-project model                        | assessment of cross-project SDP with an online learning (data stream learning) model                                                                                                                                                                                       |
| 6  | Tian et al.         | Within-project model evaluation, SDLC      | evaluations of long-term JIT-SDP for reliability improvement in terms of the usage-weighted defects and short-term JIT-SDP for early defect prediction                                                                                                                     |
| 7  | Trautsch et al.     | Sub-change prediction, metrics, SZZ        | investigation of extensive list of metrics including static analysis warnings and improved SZZ algorithm for sub-change (files in a change) defect prediction                                                                                                              |
| 8  | Bennin et al.       | Data distribution                          | investigation of concept drift within software projects                                                                                                                                                                                                                    |
| 9  | Zhu et al.          | Model                                      | investigation of effectiveness of convolutional neural networks on defect prediction using software metrics as input features                                                                                                                                              |
| 0  | Yan et al.          | Prediction setting, application domain     | investigation of the effectiveness of supervised (CBS+, CBS, OneWay, and EALR) and unsupervised (LT and Code Churn) effort-aware JIT-SDP in an industry setting (on Alibaba projects)                                                                                      |
| 11 | Khanan et al.       | Prediction setting, applications of JIT-SDP| design of explainable JIT-SDP bot that “explains” a defect prone change with the “contribution” of software metrics to the defect proneness                                                                                                                                |
| 12 | Li et al.           | Model                                      | investigation of semi-supervised effort-aware JIT-SDP using a tri-training method (also see Zhang et al. **[108]**)                                                                                                                                                        |
| 13 | Catolino et al.     | Application domain, model                  | investigation of cross-project JIT-SDP in mobile platforms and comparison of four classifiers and four ensemble techniques                                                                                                                                                 |
| 14 | Kondo et al.        | Software metrics                           | design and investigation of “context metrics”, a metric measure the complexity or the size of the surrounding lines of a change                                                                                                                                            |
| 15 | Fan et al.          | Noise reduction                            | investigation of impact of SZZ algorithms and labeling errors                                                                                                                                                                                                              |
| 16 | Hoang et al.        | Model                                      | investigation of cross-validation, short-term, and long-term prediction of convolutional neural networks using tokens (words) from both commit messages and changes as input                                                                                               |
| 17 | Pascarella et al.   | Prediction setting                         | Predicting whether in the specific files, contained in a commit, that are defect-inducing                                                                                                                                                                                  |
| 18 | Huang et al.        | Model                                      | investigation of a supervised effort-aware model (called CBS+) combining Kamei et al.’s supervised EALR model [43] and Yang et al.’s unsupervised LT [103]                                                                                                                 |
| 19 | Cabral et al.       | Model                                      | investigation of an Oversampling Online Bagging (ORB) to tackle class imbalance evolution in an online JIT-SDP scenario while considering verification latency                                                                                                             |
| 20 | Zhang et al.        | Model                                      | investigation of semi-supervised effort-aware JITSDP using a tri-training method (also see Li et al. [54])                                                                                                                                                                 |
| 21 | Guo et al.          | Evaluation                                 | investigation of the relationship between classification performance and the cost-effectiveness performance metrics to obtain insights, e.g., that there is great variability in repair effort.                                                                            |
| 22 | Young et al.        | Model                                      | comparison of the prediction of defect-prone changes using traditional machine learning techniques and ensemble learning algorithms                                                                                                                                        |
| 23 | Chen et al.         | Model                                      | formulating prediction as a dual-objective optimization problem based on logistic regression and NSGA-II to balance the benefit, i.e., the predicted defects and the cost, i.e., the review efforts                                                                        |
| 24 | Fu and Menzies      | Model                                      | investigation of Yang et al.’s unsuperivsed models (LT) and the prosed OneWay that uses the supervise models to prune unsupervised models                                                                                                                                  |
| 25 | Huang et al.        | Model                                      | investigation of a suprervised effort-aware model (called CBS) combining Kamei et al.’s supervised EALR model [43] and Yang et al.’s unsupervised LT [103]                                                                                                                 |
| 26 | Liu et al.          | Model                                      | investigation of the effectiveness of code churn based unsupervised defect prediction model (CCUM) for effort-aware prediction                                                                                                                                             |
| 27 | McIntosh and Kamei  | Prediction setting                         | investigation of evolving nature of software project with software projects with insights, such as, JIT models that should be retrained using recently recorded data                                                                                                       |
| 28 | Yang et al.         | Model                                      | investigation of a two-layer ensemble model (TLEL) for effort-aware prediction                                                                                                                                                                                             |                                                                    
| 29 | Kamei et al.        | Prediction setting, model                  | Examination of an ensemble approach for crossproject JIT-SDP with random forest base learner (also see Fukushima et al. [23])                                                                                                                                              |
| 30 | Tourani and Adams   | Data, metrics                              | investigation of using issue and review discussions to predict the defect-proneness of software patchs                                                                                                                                                                     |
| 31 | Herzig et al.       | Data, model                                | investigation of tangled changes on defect prediction and examination of a multi-predictor approach to untangle changes                                                                                                                                                    |
| 32 | Yang et al.         | Model                                      | investigation of the predictive power of simple unsupervised models, such as, LT and AGE in effort-aware JIT defect prediction and comparison of a variety of supervised and unsupervised models                                                                           |
| 33 | Rosen et al.        | Tool                                       | describing a publicly available defect prediction tool called Commit Guru                                                                                                                                                                                                  |
| 34 | Tan et al.          | Model                                      | proposing an online JIT-SDP model and investigating class imbalance problem and time-sensitive change classification for defect prediction where bag-ofwords feature of commit message, static code metrics, the node type in abstract syntax trees and meta data features.|
| 35 | Yang et al.         | Model                                      | proposing a model called Deeper consisting of a deep belief network and a logistic regression classifier to predict defect proneness of software changes                                                                                                                   |
| 36 | Fukushima et al.    | Model                                      | Examination of an ensemble approach for crossproject JIT-SDP with random forest base learner (also see Kamei et al. [41])                                                                                                                                                  |
| 37 | Jiang et al.        | Model                                      | Building (file) change-level defect prediction model for each developer from file modification histories (i.e., a personlized defect prediction)                                                                                                                           |
| 38 | Singh and Chaturvedi| Metrics, model                             | investigation of entropy change metrics, metrics decay (aging) function, and defect prediction model using linear regression and support vector machine for defect prediction                                                                                              |
| 39 | Kamei et al.        | Model                                      | Predicting defect-proneness of software changes with logistic regression and quality assurance effort of software changes with linear regression (EALR) from software metrics                                                                                              |
| 40 | Kim et al.          | Model                                      | Predicting with a Support Vector Machine (SVM) using the bag-of-words features of the identifiers in added and deleted source code and the words in file change logs to classify changes as being defect-inducing or clean                                                 |
| 41 | Mockus and Weiss    | Prediction setting, model                  | Predicting from software change metrics with logistic regression the defect-proneness of the Initial Modification Requests (IMR) in 5ESS network switch project where IMRs may consist of multiple Modification Requests (MR) corresponding to multiple changes            |




