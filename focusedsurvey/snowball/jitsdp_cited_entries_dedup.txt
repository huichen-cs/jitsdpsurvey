288313ee551fcca0c23a2f4ff9ad666f ; [3] Erik Arisholm and Lionel C Briand. 2006. Predicting fault-prone components in a java legacy system. In Proceedings of the 2006 ACM/IEEE international symposium on Empirical software engineering. ACM, 8ś17.
8952a6da18ab68a4ea36a6ae82281b45 ; [28] E. Arisholm, L. C. Briand, and E. B. Johannessen, “A systematic and comprehensive investigation of methods to build and evaluate fault prediction models,” Journal of Systems and Software, vol. 83, no. 1, pp. 2–17, 2010.
ff72804ec91b9f6b50430e6ccd9d3aa4 ; [5] Lerina Aversano, Luigi Cerulo, and Concettina Del Grosso. 2007. Learning from bug-introducing changes to prevent fault prone code. In Ninth international workshop on Principles of software evolution: in conjunction with the 6th ESEC/FSE joint meeting. ACM, 19–26.
a69c1cb325d5bdd535df2172a0d27653 ; [4] V.R. Basili, L.C. Briand, and W.L. Melo, “A Validation of Object- Oriented Design Metrics as Quality Indicators,” IEEE Trans. Software Eng., vol. 22, no. 10, pp. 751-761, Oct. 1996.
20b2df43c79648782d5775718d2a5788 ; [5] C. Bird, N. Nagappan, B. Murphy, H. Gall, and P. Devanbu, “Don’t Touch My Code!: Examining the Effects of Ownership on Software Quality,” Proc. European Software Eng. Conf. and Symp. the Foundations of Software Eng., pp. 4-14, 2011.
22109db41b328bbc45e8e61aec055acc ; [6] L.C. Briand, V.R. Basili, and C.J. Hetmanski, “Developing Interpretable Models with Optimized Set Reduction for Identifying High-Risk Software Components,” IEEE Trans. Software Eng., vol. 19, no. 11, pp. 1028-1044, Nov. 1993.
c2ebbc157a68b1db3b38026ce5ee90ff ; [7] L.C. Briand, J. Wu¨ st, S.V. Ikonomovski, and H. Lounis, “Investigating Quality Factors in Object-Oriented Designs: An Industrial Case Study,” Proc. Int’l Conf. Software Eng., pp. 345-354, 1999.
b5ffcf150cb43025fde14d7090716ec2 ; [8] M. Cataldo, A. Mockus, J.A. Roberts, and J.D. Herbsleb, “Software Dependencies, Work Dependencies, and Their Impact on Failures,” IEEE Trans. Software Eng., vol. 35, no. 6, pp. 864-878, Nov./ Dec. 2009.
6fbc07d61718a1636efd29421c3ccaee ; [5] Chidamber, S. and Kemerer, C. 1994. A metrics suite for object oriented design. IEEE Transactions on Software Engineering. 20, 6 (Jun. 1994), 476–493. DOI:https://doi.org/10.1109/32.295895.
f748c7c6f2e7a4cc6b4e8ef4be3db39f ; [2] M. D’Ambros, M. Lanza, and R. Robbes. 2010. An extensive comparison of bug prediction approaches. In 2010 7th IEEE Working Conference on Mining Software Repositories (MSR 2010). 31–41. https://doi.org/10.1109/MSR.2010.5463279
1488eec6164316c806af07febda7e5c8 ; [11] B. Efron, “Estimating the Error Rate of a Prediction Rule: Improvement on Cross-Validation,” J. Am. Statistical Assoc., vol. 78, no. 382, pp. 316-331, 1983.
3d964e8e04d2ebdf2b288244a23fab11 ; [9] El Emam, K. et al. 2001. The prediction of faulty classes using object-oriented design metrics. Journal of Systems and Software. 56, 1 (Feb. 2001), 63–75. DOI:https://doi.org/10.1016/S0164-1212(00) 00086-8.
1f1550c6a01661139ac2ae6082be0f57 ; [13] J. Eyolfson, L. Tan, and P. Lam, “Do time of day and developer experience affect commit bugginess?” in Proceedings of the 8th Working Conference on Mining Software Repositories (MSR), 2011, pp. 153–162.
f24350332d69ab0c3a55d54418300b60 ; [14] T. Fritz, J. Ou, G.C. Murphy, and E. Murphy-Hill, “A Degree-of- Knowledge Model to Capture Source Code Familiarity,” Proc. 32nd ACM/IEEE Int’l Conf. Software Eng., 2010.
d09811aced8b433c615da576a59287ba ; [13] Todd L Graves, Alan F Karr, James S Marron, and Harvey Siy. 2000. Predicting fault incidence using software change history. IEEE Transactions on software engineering 26, 7 (2000), 653ś661. https://doi.org/10.1109/32.859533
251a7e81cb9f3a003aeb90b33d7e1ced ; [7] Philip J. Guo, Thomas Zimmermann, Nachiappan Nagappan, and Brendan Murphy. 2010. Characterizing and Predicting Which Bugs Get Fixed: An Empirical Study of Microsoft Windows. In Proceedings of the 32Nd ACM/IEEE International Conference on Software Engineering - Volume 1 (ICSE ’10). ACM, New York, NY, USA, 495–504. https://doi.org/10.1145/1806799.1806871
57205eae70e4b1de7ed1d0a134a0c118 ; [10] Tibor Gyimothy, Rudolf Ferenc, and Istvan Siket. 2005. Empirical Validation of Object-Oriented Metrics on Open Source Software for Fault Prediction. IEEE Trans. Softw. Eng. 31, 10 (Oct. 2005), 897–910. https://doi.org/10.1109/TSE.2005. 112
7aa7b5a09a6681b2eee7c35203b1598c ; [18] T. Hall, S. Beecham, D. Bowes, D. Gray, and S. Counsell, “A Systematic Review of Fault Prediction Performance in Software Engineering,” IEEE Trans. Software Eng., vol. 38, no. 6, pp. 1276-1304, Nov./Dec. 2012.
1381a86a9013d0f71910d856c0317244 ; [11] A. E. Hassan. Predicting Faults Using the Complexity of Code Changes. In Proceedings of the 31st International Conference on Software Engineering, ICSE '09, pages 78{88, Washington, DC, USA, 2009. IEEE Computer Society.
6bfc1aa459e190fb1d8c1a7196457dff ; [19] I. Herraiz, D. M. German, J. M. Gonzalez-Barahona, and G. Robles. Towards a simplification of the bug report form in eclipse. In Proceedings of the 2008 International Working Conference on Mining Software Repositories, MSR ’08, pages 145–148, New York, NY, USA, 2008. ACM.
b2352e10087fb7260354c81e8f6f8a41 ; 13. Herraiz, I., Gonzalez-Barahona, J.M., Robles, G.: Towards a theoretical model for software growth. In: Proceedings of the 4th International Workshop on Mining Software Repositories, Minnesotta, USA (2007)
629984637b390e2208f3a9acc3fc62ce ; [22] Y. Jiang, B. Cuki, T. Menzies, and N. Bartlow, “Comparing Design and Code Metrics for Software Quality Prediction,” Proc. Fourth Int’l Workshop Predictor Models in Software Eng., pp. 11-18, 2008.
a0cb7ac03fb988328b36e64faf01916d ; [13] Y. Kamei, S. Matsumoto, A. Monden, K. Matsumoto, B. Adams, and A. E. Hassan. 2010. Revisiting common bug prediction findings using effort-aware models. In 2010 IEEE International Conference on Software Maintenance. 1–10. https: //doi.org/10.1109/ICSM.2010.5609530
21c3abdd50f16d156239d9ba85661e34 ; [19] Y. Kamei, A. Monden, S. Matsumoto, T. Kakimoto, and K. Matsumoto, “The effects of over and under sampling on fault-prone module detection,” in Proceedings of the 1st International Symposium on Empirical Software Engineering and Measurement (ESEM), 2007, pp. 196–204.
43d1805d6d56539c267fb5bd8a76749d ; [28] T. M. Khoshgoftaar, X. Yuan, and E. B. Allen, “Balancing misclassification rates in classification-tree models of software quality,” Empirical Software Engineering, vol. 5, no. 4, pp. 313–330, 2000.
22fab3678958e65107ad2348e9c6e139 ; [7] S. Kim, E. J. Whitehead, Jr., and Y. Zhang, “Classifying software changes: Clean or buggy?” IEEE Trans. Softw. Eng., vol. 34, no. 2, pp. 181–196, Mar. 2008. [Online]. Available: http://dx.doi.org/10.1109/ TSE.2007.70773
dd4a5f3ac6203f4978efc923475f0b3e ; [16] A. G. Koru, D. Zhang, K. El Emam, and H. Liu. 2009. An Investigation into the Functional Form of the Size-Defect Relationship for Software Modules. IEEE Transactions on Software Engineering 35, 2 (March 2009), 293–304. https://doi. org/10.1109/TSE.2008.90
e40353bc2958e26e7aa51ab6f7c12150 ; [26] Stefan Lessmann, Bart Baesens, Christophe Mues, and Swantje Pietsch. 2008. Benchmarking classification models for software defect prediction: A proposed framework and novel findings. IEEE Transactions on Software Engineering 34, 4 (2008), 485ś496. https://doi.org/10.1109/TSE.2008.35
edc599381509f06b0bf5991f78f4a2cf ; [29] M. Leszak, D.E. Perry, and D. Stoll, “Classification and Evaluation of Defects in a Project Retrospective,” J. Systems Software, vol. 61, no. 3, pp. 173-187, 2002.
6363403a4bc8b438de8e0acefa06fb18 ; [17] Paul Luo Li, James Herbsleb, Mary Shaw, and Brian Robinson. 2006. Experiences and Results from Initiating Field Defect Prediction and Product Test Prioritization Efforts at ABB Inc.. In Proceedings of the 28th International Conference on Software Engineering (ICSE ’06). ACM, New York, NY, USA, 413–422. https://doi.org/10. 1145/1134285.1134343
79ef4513eddc43b38c0f36f3660f2ad8 ; 31. C. L. Mallows, "Some Comments on Cp," Technometrics, Vol. 15, No. 4, Nov. 1973, pp.661-667.
db7fa1778aece6838368dbf959e19ef6 ; [18] Shinsuke Matsumoto, Yasutaka Kamei, Akito Monden, Ken-ichi Matsumoto, and Masahide Nakamura. 2010. An Analysis of Developer Metrics for Fault Prediction. In Proceedings of the 6th International Conference on Predictive Models in Software Engineering (PROMISE ’10). ACM, New York, NY, USA, Article 18, 9 pages. https://doi.org/10.1145/1868328.1868356
b9e9b317cc3605ca7c298445d8ee84e8 ; [13] T. J. McCabe, “A complexity measure,” IEEE Transactions on software Engineering, no. 4, pp. 308–320, 1976.
983ff26ee21a8651738b9b1703f80da3 ; [23] T. Mende and R. Koschke. Revisiting the Evaluation of Defect Prediction Models. In Proceedings of the 5th International Conference on Predictor Models in Software Engineering, PROMISE '09, pages 7:1{7:10, New York, NY, USA, 2009. ACM.
114324b271e779574f8e95f6ca33c231 ; [24] T. Mende and R. Koschke. Effort-aware defect prediction models. In Proceedings of the 2010 14th European Conference on Software Maintenance and Reengineering, CSMR '10, pages 107{116, Washington, DC, USA, 2010. IEEE Computer Society.
f612d8edeb1c0516df40320f886d7882 ; [36] T. Menzies, A. Dekhtyar, J. Distefano, and J. Greenwald, “Problems with Precision: A Response to “Comments on ‘Data Mining Static Code Attributes to Learn Defect Predictors’“,” IEEE Trans. Software Eng., vol. 33, no. 9, pp. 637-640, Sept. 2007.
b14c0a6e0f04b0dd43dfa95664acb067 ; [36] Tim Menzies, Zach Milton, Burak Turhan, Bojan Cukic, Yue Jiang, and Ayşe Bener. 2010. Defect prediction from static code features: current results, limitations, new approaches. Automated Software Engineering 17, 4 (2010), 375ś407.
21222cd2fedb5500790159677812d6eb ; [38] A. Mockus, “Organizational Volatility and Its Effects on Software Defects,” Proc. Int’l Symp. Foundations of Software Eng., pp. 117-126, 2010.
7797735957301d0f5f34428013bf4f0f ; [19] A. Mockus, R. T. Fielding, and J. D. Herbsleb, “Two case studies of open source software development: Apache and mozilla,” vol. 11, no. 3. New York, NY, USA: ACM, Jul. 2002, pp. 309–346. [Online]. Available: http://doi.acm.org/10.1145/567793.567795
d2df381829991445f11b076cd659e71e ; [40] A. Mockus and J. Herbsleb, “Expertise Browser: A Quantitative Approach to Identifying Expertise,” Proc. 24th Int’l Conf. Software Eng., 2002.
da14c75e08a081d804c5e59459b3dc0b ; [32] Audris Mockus and David M Weiss. 2000. Predicting risk of software changes. Bell Labs Technical Journal 5, 2 (2000), 169ś180. https://doi.org/10.1002/bltj.2229
14dc1eeaf985416cd485732577d1ae24 ; [42] A. Mockus, P. Zhang, and P.L. Li, “Predictors of Customer Perceived Software Quality,” Proc. Int’l Conf. Software Eng., pp. 225-233, 2005.
b3ced715ba605b6e348569802f4d42bd ; [33] Raimund Moser, Witold Pedrycz, and Giancarlo Succi. 2008. A comparative analysis of the efficiency of change metrics and static code attributes for defect prediction. In Proceedings of the 30th international conference on Software engineering. 181ś190. https://doi.org/10.1145/1368088.1368114
07859a7b659d515f6cccc89ddd029aba ; Munson JC, Elbaum SG (1998) Code churn: A measure for estimating the impact of code change. In: Proceedings of the international conference on software maintenance, pp 24–31. IEEE
8238aa7f4ec55419687f040be7e66467 ; [6] J. C. Munson and T. M. Khoshgoftaar, “The detection of fault-prone programs,” IEEE Transactions on Software Engineering, vol. 18, no. 5, pp. 423–433, 1992.
fa7ee173cedde13c73276ed706fe5777 ; [22] N. Nagappan and T. Ball, “Use of relative code churn measures to predict system defect density,” in Proceedings of the 27th International Conference on Software Engineering, ser. ICSE ’05. New York, NY, USA: ACM, 2005, pp. 284–292. [Online]. Available: http://doi.acm.org/10.1145/1062455.1062514
8b53080b8eb1c4c92470ace01dbf4ec0 ; [22] Nachiappan Nagappan, Thomas Ball, and Andreas Zeller. 2006. Mining Metrics to Predict Component Failures. In Proceedings of the 28th International Conference on Software Engineering (ICSE ’06). ACM, New York, NY, USA, 452–461. https: //doi.org/10.1145/1134285.1134349
54c5893cf9233bb4d9bbba10a88498bb ; [61] N. Nagappan, A. Zeller, T. Zimmermann, K. Herzig, and B. Murphy, “Change bursts as defect predictors,” in Software Reliability Engineering (ISSRE), 2010 IEEE 21st International Symposium on. IEEE, 2010, pp. 309–318.
bb5a10af6098737049e373947f394f19 ; [49] N. Ohlsson and H. Alberg, “Predicting Fault-Prone Software Modules in Telephone Switches,” IEEE Trans. Software Eng., vol. 22, no. 12, pp. 886-894, Dec. 1996.
480d56a1430a9231d03cd5b3286637b7 ; [33] Ostrand, T. et al. 2005. Predicting the location and number of faults in large software systems. IEEE Transactions on Software Engineering. 31, 4 (Apr. 2005), 340–355. DOI:https://doi.org/10.1109/ TSE.2005.49.
45bc22797e6f46b7946c4d5eeccd13c0 ; [15] T. J. Ostrand, E. J. Weyuker, and R. M. Bell, “Programmer-based fault prediction,” in Proc. of 6th Int. Conf. on Predictive Models in Software Engineering, 2010, p. 19.
4a7fd53082117d320a897dfa884784a9 ; [37] Ranjith Purushothaman and Dewayne E Perry. 2005. Toward understanding the rhetoric of small source code changes. IEEE Transactions on Software Engineering 31, 6 (2005), 511ś526. https://doi.org/10.1109/TSE.2005.74
b0f31ebe72b1e71d9d36916a3cc27567 ; [53] J. Ratzinger, T. Sigmund, and H.C. Gall, “On the Relation of Refactorings and Software Defect Prediction,” Proc. Int’l Working Conf. Mining Software Repositories, pp. 35-38, 2008.
6d6eeb76f57d066b546e2fcea3c729be ; [53] E. S. Raymond, The Cathedral and the Bazaar: Musings on Linux and Open Source by an Accidental Revolutionary. Oreilly & Associates Inc, 2001.
e881376c959b5618dd69a64e64e49698 ; [55] E. Shihab, Z.M. Jiang, W.M. Ibrahim, B. Adams, and A.E. Hassan, “Understanding the Impact of Code and Process Metrics on Post- Release Defects: A Case Study on the Eclipse Project,” Proc. Int’l Symp. Empirical Softw. Eng. and Measurement, pp. 4:1-4:10, 2010.
3baa1f71dbbf4ab92ed4be6371849c99 ; [56] E. Shihab, A. Mockus, Y. Kamei, B. Adams, and A.E. Hassan, “High-Impact Defects: A Study of Breakage and Surprise Defects,” Proc. European Software Eng. Conf. and Symp. Foundations of Software Eng., pp. 300-310, 2011.
a159f289ee522b9a7146fa085878222a ; [37] J. Sliwerski, T. Zimmermann, and A. Zeller. When do changes induce fixes? In Proceedings of the 2005 International Workshop on Mining Software Repositories, MSR 2005, Saint Louis, Missouri, USA, May 17, 2005. ACM, 2005.
528ff7f1fc8501c8e4a55e8b656b1a7f ; [58] A. Vanya, R. Premraj, and H.v. Vliet, “Approximating Change Sets at Philips Healthcare: A Case Study,” Proc. European Conf. Software Maintenance and Reeng., pp. 121-130, 2011.
3c12c11e4aa5d1513fcd95a29bfd6621 ; [38] R. Wu, H. Zhang, S. Kim, and S.-C. Cheung. ReLink: Recovering Links Between Bugs and Changes. In Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering, ESEC/FSE '11, pages 15{25, New York, NY, USA, 2011. ACM.
4b866bc381ca8f1d4d28cbd331e60089 ; [12] Z. Yin, D. Yuan, Y. Zhou, S. Pasupathy, and L. N. Bairavasundaram, “How do fixes become bugs?” in ACM SIGSOFT International Symposium on Foundations of Software Engineering, FSE 2011, Szeged, Hungary, September 5-9, 2011, T. Gyim´othy and A. Zeller, Eds. ACM, 2011, pp. 26–36.
e611441d1543a7d191c6f9a9ff7bde64 ; [61] M. Zhou and A. Mockus, “Developer Fluency: Achieving True Mastery in Software Projects,” Proc. Int’l Symp. Foundations of Software Eng., pp. 137-146, 2010.
b8b8ae7685778a217a48160af537fb49 ; [43] T. Zimmermann, N. Nagappan, H. Gall, E. Giger, and B. Murphy. Cross-project Defect Prediction: A Large Scale Experiment on Data vs. Domain vs. Process. In Proceedings of the the 7th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering, ESEC/FSE '09, pages 91{100, New York, NY, USA, 2009. ACM.
2d05bcc3fa54c42e80fabc41579249e1 ; [63] T. Zimmermann and P. Weisgerber, “Preprocessing CVS Data for Fine-Grained Analysis,” Proc. Int’l Workshop Mining Software Repositories, pp. 2-6, May 2004.
0a5ad8245ae4565190a293608d90fc37 ; [1] Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2013. Representation Learning: A Review and New Perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence 35, 8 (2013), 1798–1828.
cb019dc03d37e2de608d385962e14025 ; [2] JC Carver. 2010. Towards Reporting Guidelines for Experimental Replications: A Proposal. In Proceedings of the 1st International Workshop on Replication in Empirical Software Engineering Research (RESER) [Held during ICSE 2010]. Cape Town, South Africa, 2–5.
27d5443e80ea5edecb899520d0f08880 ; [2] Y. Kamei, E. Shihab, B. Adams, A. E. Hassan, A. Mockus, A. Sinha, and N. Ubayashi, “A large-scale empirical study of just-in-time quality assurance,” vol. 39, no. 6. Piscataway, NJ, USA: IEEE Press, Jun. 2013, pp. 757–773. [Online]. Available: http://dx.doi.org/10.1109/TSE.2012.70
1e7b19793ae586b91e3b8ae958aafbad ; [4] Ye Nan, Kian Ming Chai, Wee Sun Lee, and Hai Leong Chieu. 2012. Optimizing F-measure: A Tale of Two Approaches. In Proceedings of the 29th International Conference on Machine Learning (ICML-12). 289–296.
b37d82000916d1bd952975e07285b06c ; [44] X. Yang, D. Lo, X. Xia, and J. Sun, “Tlel: A two-layer ensemble learning approach for just-in-time defect prediction,” Information and Software Technology, vol. 87, pp. 206 – 220, 2017. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0950584917302501
6e7e1ab70d12139faf2884b6f50420f3 ; [14] X. Yang, D. Lo, X. Xia, Y. Zhang, and J. Sun, “Deep learning for just-in-time defect prediction,” in Proceedings of the 2015 IEEE International Conference on Software Quality, Reliability and Security, ser. QRS ’15. Washington, DC, USA: IEEE Computer Society, 2015, pp. 17–26. [Online]. Available: http://dx.doi.org/10.1109/QRS.2015.14
3729aa939afe8237bd8b9d008a29ae27 ; [7] Steven Young, Tamer Abdou, and Ayse Bener. 2018. Deep Super Learner: A Deep Ensemble for Classification Problems. In Proceedings of the 31st Canadian Conference on Artificial Intelligence (CanadianAI-31).
b69c643acdb59a78de3ce7e76d1e8f3c ; [8] Zhi-Hua Zhou. 2012. Ensemble Methods: Foundations and Algorithms. Chapman & Hall/CRC. Machine Learning & Pattern Recognition Series. 236 pages.
9e95be93cf2bf8bb0d523739fa3e48a5 ; [2] N. Bettenburg, M. Nagappan, and A. E. Hassan. Think locally, act globally: Improving defect and e↵ort prediction models. In Proc. Int’l Working Conf. on Mining Software Repositories (MSR’12), pages 60–69, 2012.
62bb79847d0c572e05c8aeec7347f134 ; [30] L. Breiman, “Random forests,” Mach. Learn., vol. 45, no. 1, pp. 5–32, Oct. 2001. [Online]. Available: http://dx.doi.org/10.1023/A:1010933404324
68586a8206c4300f404fac42dfa0df6e ; [4] F. L. Coolidge. Statistics: A Gentle Introduction. SAGE Publications (3rd ed.), 2012.
fb0d3a57c0f2846a3b7860d07ce1e138 ; [9] Y. Jiang, B. Cukic, and T. Menzies. Can data transformation help in the detection of fault-prone modules? In Proc. Workshop on Defects in Large Software Systems (DEFECTS’08), pages 16–20, 2008.
807594e27bf22d6dd5f4ff1a4e3bb861 ; [10] Y. Kamei, S. Matsumoto, A. Monden, K. Matsumoto, B. Adams, and A. E. Hassan. Revisiting common bug prediction findings using e↵ort aware models. In Proc. Int’l Conf. on Software Maintenance (ICSM’10), pages 1–10, 2010.
4a88e6a72b252eae6a00b4e7e1b05e8b ; [11] Y. Kamei, A. Monden, S. Matsumoto, T. Kakimoto, and K.-i. Matsumoto. The e↵ects of over and under sampling on fault-prone module detection. In Proc. Int’l Symposium on Empirical Softw. Eng. and Measurement (ESEM’07), pages 196–204, 2007.
18a9183d39a861f700183953736d2072 ; [13] T. M. Khoshgoftaar and E. B. Allen. Modeling software quality with classification trees. Recent Advances in Reliability and Quality Engineering, 2:247–270, 2001.
bb77d3f8441f6b61b954623e0ed28052 ; [15] E. Kocaguneli, T. Menzies, and J. Keung. On the value of ensemble e↵ort estimation. IEEE Trans. Softw. Eng., 38(6):1403–1416, 2012.
1d1e680d094dc003e0dac82c892f71a7 ; [18] P. L. Li, J. Herbsleb, M. Shaw, and B. Robinson. Experiences and results from initiating field defect prediction and product test prioritization e↵orts at ABB Inc. In Proc. Int’l Conf. on Softw. Eng. (ICSE’06), pages 413– 422, 2006.
972130ec005f0bf638efbccab1924c11 ; [20] T. Menzies, A. Butcher, D. Cok, A. Marcus, L. Layman, F. Shull, B. Turhan, and T. Zimmermann. Local versus global lessons for defect prediction and e↵ort estimation. IEEE Trans. Softw. Eng., 39(6):822–834, 2013.
7b9da59d76037a538fbd34ada6cff37c ; [55] A. T. Mısırlı, A. B. Bener, and B. Turhan, “An industrial case study of classifier ensembles for locating software defects,” Software Quality Journal, vol. 19, no. 3, pp. 515–536, 2011.
613fc0040d2336445c9704eff46e458d ; [43] Jaechang Nam, Sinno Jialin Pan, and Sunghun Kim. 2013. Transfer defect learning. In Proceedings of the 2013 International Conference on Software Engineering. IEEE, 382ś391.
59fdcf6cc5059f5ea24f4133f8936de8 ; [29] J. Ratzinger, T. Sigmund, and H. C. Gall. On the relation of refactorings and software defect prediction. In Proc. Int’l Working Conf. on Mining Software Repositories (MSR’08), pages 35–38, 2008.
7b540562a7017cae9ce2636d8de0bd5f ; [37] E. Shihab, A. E. Hassan, B. Adams, and Z. M. Jiang. An industrial study on the risk of software changes. In Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering, FSE ’12, pages 62:1–62:11, New York, NY, USA, 2012. ACM.
1799b872cef3f94867cb60416695ac75 ; [32] S. W. Thomas, M. Nagappan, D. Blostein, and A. E. Hassan. The impact of classifier configuration and classifier combination on bug localization. IEEE Trans. Softw. Eng., 39(10):1427–1443, 2013.
237fb379bde82ab975773b47052db2c6 ; [30] Burak Turhan, Tim Menzies, Ayşe B Bener, and Justin Di Stefano. 2009. On the relative value of cross-company and within-company data for defect prediction. Empirical Software Engineering 14, 5 (2009), 540–578.
01f66845c1e476a29b9725484c86e4f7 ; [35] F. Xing, P. Guo, and M. R. Lyu. A novel method for early software quality prediction based on support vector machine. In Proc. Int’l Symposium on Software Reliability Engineering (ISSRE’05), pages 10–pp, 2005.
4763a0c779e5e3a8c4d14bd43e266717 ; [1] A. Agrawal and T. Menzies. 2018. Is “better data” better than “better data miners”?: on the benefits of tuning SMOTE for defect prediction. In Proceedings of the 40th International Conference on Software Engineering. 1050–1061.
2362249c7b69b4eba670f02fb243f01b ; [6] George G Cabral, Leandro L Minku, Emad Shihab, and Suhaib Mujahid. 2019. Class imbalance evolution and verification latency in just-in-time software defect prediction. In 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, 666ś676. https://doi.org/10.1109/ICSE.2019.00076
5c236448bff4919cbfa38953348e1765 ; [3] Gerardo Canfora, Andrea De Lucia, Massimiliano Di Penta, Rocco Oliveto, Annibale Panichella, and Sebastiano Panichella. 2013. Multi-objective cross-project defect prediction. In 2013 IEEE Sixth International Conference on Software Testing, Verification and Validation. IEEE, 252–261.
25f3b46eaec4a05e903f5eba57638bb7 ; [4] Gemma Catolino, Dario Di Nucci, and Filomena Ferrucci. 2019. Cross-project justin- time bug prediction for mobile apps: an empirical assessment. In Proceedings of the 6th IEEE/ACM International Conference on Mobile Software Engineering and Systems (MOBILESoft). IEEE, 99–110.
ae611c28b6dbad7f02af979e21779db1 ; [5] Xiang Chen, Yingquan Zhao, Qiuping Wang, and Zhidan Yuan. 2018. MULTI: Multi-objective effort-aware just-in-time software defect prediction. Information and Software Technology 93 (2018), 1–13.
6b829d2d66a2bf011a122e7b90c5c8a5 ; [60] J. Demšar, “Statistical comparisons of classifiers over multiple data sets,” J. Mach. Learn. Res., vol. 7, no. Jan, pp. 1–30, 2006.
cd24674aaeef58fe072df68378672efc ; [7] Gregory Ditzler, Manuel Roveri, Cesare Alippi, and Robi Polikar. 2015. Learning in nonstationary environments: A survey. IEEE Computational Intelligence Magazine 10, 4 (2015), 12–25.
62f579c34793a5b9317e1a1ff6adc108 ; [8] Pedro Domingos and Geoff Hulten. 2000. Mining High-speed Data Streams. In Proceedings of the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD ’00). ACM, New York, NY, USA, 71–80. https: //doi.org/10.1145/347090.347107
124657104c8f5c5eeda394895be3cf09 ; [9] João Gama, Raquel Sebastião, and Pedro Pereira Rodrigues. 2013. On evaluating stream learning algorithms. Machine learning 90, 3 (2013), 317–346.
03e9f8880859f9e6a716797ec83f8121 ; [11] T. Hall, S. Beecham, D. Bowes, D. Gray, and S. Counsell. 2012. A Systematic Literature Review on Fault Prediction Performance in Software Engineering. Transactions on Software Engineering 38, 6 (2012), 1276–1304. https://doi.org/10. 1109/TSE.2011.103
7d4c0190596459739a1aec789184963b ; [12] Zhimin He, Fayola Peters, Tim Menzies, and Ye Yang. 2013. Learning from open-source projects: An empirical study on defect prediction. In 2013 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement. IEEE, 45–54.
5528c967ec546b5bc361ddf8dd3b8fa2 ; [13] Zhimin He, Fengdi Shu, Ye Yang, Mingshu Li, and Qing Wang. 2012. An investigation on the feasibility of cross-project defect prediction. Automated Software Engineering 19, 2 (2012), 167–199.
a3a7b550f5dfc96bcb0162351c318da9 ; [14] Xiao-Yuan Jing, Fei Wu, Xiwei Dong, and Baowen Xu. 2016. An improved SDA based defect prediction framework for both within-project and cross-project class-imbalance problems. IEEE Transactions on Software Engineering 43, 4 (2016), 321–339.
a3b59ebeca9230eefc8127f19b889e5a ; [15] Yasutaka Kamei, Takafumi Fukushima, Shane McIntosh, Kazuhiro Yamashita, Naoyasu Ubayashi, and Ahmed E. Hassan. 2016. Studying just-in-time defect prediction using cross-project models. Empirical Software Engineering 21, 5 (2016), 2072–2106. https://doi.org/10.1007/s10664-015-9400-x
f4b9f4b2ebf1f42c5beeafdd07cf390c ; [27] Jian Li, Pinjia He, Jieming Zhu, and Michael R Lyu. 2017. Software defect prediction via convolutional neural network. In 2017 IEEE International Conference on Software Quality, Reliability and Security (QRS). IEEE, 318ś328. https: //doi.org/10.1109/QRS.2017.42
eae05e40d653be93a787943a5483480e ; [18] Ruchika Malhotra. 2015. A systematic review of machine learning techniques for software fault prediction. Applied Soft Computing 27 (2015), 504–518.
d4348142199d649861c5c59a52030b8b ; [21] S. McIntosh and Y. Kamei, “Are fix-inducing changes a moving target?: A longitudinal case study of just-in-time defect prediction,” in Proceedings of the 40th International Conference on Software Engineering, ser. ICSE ’18. New York, NY, USA: ACM, 2018, pp. 560– 560. [Online]. Available: http://doi.acm.org/10.1145/3180155.3182514
5674601800ec89c12d90194ae8f53ab2 ; [31] T. Menzies, Y. Yang, G. Mathew, B. Boehm, and J. Hihn, “Negative results for software effort estimation,” Empirical Software Engineering (EMSE), vol. 22, no. 5, pp. 2658–2683, 2017.
ecad7f659d1d12dee10a4b87a1f7fa68 ; [30] N. Mittas and L. Angelis, “Ranking and clustering software cost estimation models through a multiple comparisons algorithm,” IEEE Transactions on Software Engineering (TSE), vol. 39, no. 4, pp. 537– 551, 2013.
59b42f9b1ee23e830d3fd484c9a36b7d ; [24] Annibale Panichella, Rocco Oliveto, and Andrea De Lucia. 2014. Cross-project defect prediction models: L’union fait la force. In 2014 Software Evolution Week- IEEE Conference on Software Maintenance, Reengineering, and Reverse Engineering (CSMR-WCRE). IEEE, 164–173.
2d8e0fa60149e68f2168e11fbd1ae684 ; [25] C. Rosen, B. Grawi, and E. Shihab, “Commit guru: Analytics and risk prediction of software commits,” in Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, ser. ESEC/FSE 2015. New York, NY, USA: Association for Computing Machinery, 2015, p. 966–969. [Online]. Available: https://doi.org/10.1145/2786805.2803183
bb681a7aa04eb54e41d854cfb61ba690 ; [26] Duksan Ryu, Okjoo Choi, and Jongmoon Baik. 2016. Value-cognitive boosting with a support vector machine for cross-project defect prediction. Empirical Software Engineering 21, 1 (2016), 43–71.
9d6115502765952e9d1593c50b9c54a2 ; [27] Duksan Ryu, Jong-In Jang, and Jongmoon Baik. 2017. A transfer cost-sensitive boosting approach for cross-project defect prediction. Software Quality Journal 25, 1 (2017), 235–272.
01a5f622067d5ea1f6e6ea6b6fcbb7f5 ; [28] Sadia Tabassum, Leandro L. Minku, Danyi Feng, George G. Cabral, and Liyan Song. 2020. An Investigation of Cross-Project Learning in Online Just-In-Time Software Defect Prediction – Supplementary Material. http://www.cs.bham.ac. uk/~minkull/publications/TabassumICSE2020-supplement.pdf
b25fdc8a00329fb4f11b072375187b1c ; [32] M. Tan, L. Tan, S. Dara, and C. Mayeux, “Online defect prediction for imbalanced data,” in Proceedings of the 37th International Conference on Software Engineering - Volume 2, ser. ICSE ’15. Piscataway, NJ, USA: IEEE Press, 2015, pp. 99–108.
2b6143bb452adfb1068ede5cbfff4dfb ; [32] A. Vargha and H. D. Delaney, “A critique and improvement of the cl common language effect size statistics of mcgraw and wong,” Journal of Educational and Behavioral Statistics, vol. 25, no. 2, pp. 101–132, 2000.
4fe77a67d917c3f54f614810ba03fbe0 ; [32] Romi Satria Wahono. 2015. A systematic literature review of software defect prediction: research trends, datasets, methods and frameworks. Journal of Software Engineering 1, 1 (2015), 1–16.
b66013306d564c326ec44f953862680b ; [33] Shuo Wang, Leandro L Minku, and Xin Yao. 2018. A systematic study of online class imbalance learning with concept drift. IEEE transactions on neural networks and learning systems 29, 10 (2018), 4802–4821.
8a76e6eb0526b68f330f1e98b888e323 ; [46] Tiejian Wang, Zhiwu Zhang, Xiaoyuan Jing, and Liqiang Zhang. 2016. Multiple kernel ensemble learning for software defect prediction. Automated Software Engineering 23, 4 (2016), 569ś590. https://doi.org/10.1007/s10515-015-0179-1
e02b712e2db1fdec1ba7bf1fbf77b6e9 ; [35] Thomas Zimmermann, Nachiappan Nagappan, Harald Gall, Emanuel Giger, and Brendan Murphy. 2009. Cross-project defect prediction: a large scale experiment on data vs. domain vs. process. In Proceedings of the the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering. ACM, 91–100.
dce763a2711a9d5428d5bde5bff6c44c ; [4] Emanuel Giger, Marco D’Ambros, Martin Pinzger, and Harald C. Gall. 2012. Method-level Bug Prediction. In Proceedings of the ACM-IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM ’12). ACM, New York, NY, USA, 171–180. https://doi.org/10.1145/2372251.2372285
9e2f4891251911ded33f0f8f3f58a710 ; [10] Hideaki Hata, Osamu Mizuno, and Tohru Kikuno. 2012. Bug Prediction Based on Fine-grained Module Histories. In Proceedings of the 34th International Conference on Software Engineering (ICSE ’12). IEEE Press, Piscataway, NJ, USA, 200–210. http://dl.acm.org/citation.cfm?id=2337223.2337247
73349768a1dedf499141a229574b293a ; [27] Thomas Zimmermann, Rahul Premraj, and Andreas Zeller. 2007. Predicting Defects for Eclipse. In Proceedings of the Third International Workshop on Predictor Models in Software Engineering (PROMISE ’07). IEEE Computer Society, Washington, DC, USA, 9–. https://doi.org/10.1109/PROMISE.2007.10
7e38e524f773e1876edb839fed7bdabf ; [4] E. Shihab, A. E. Hassan, B. Adams, and Z. M. Jiang, “An industrial study on the risk of software changes,” in Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering, ser. FSE ’12. New York, NY, USA: ACM, 2012, pp. 62:1– 62:11. [Online]. Available: http://doi.acm.org/10.1145/2393596.2393670
432b7076a2c0d9ca63b58a062462cdba ; [8] L. A. Belady and M. M. Lehman, “A model of large program development,” IBM Syst. J., vol. 15, no. 3, pp. 225–252, 1976.
32e8aff0660ef522b13f663ed78f3313 ; [8] O. Kononenko, O. Baysal, L. Guerrouj, Y. Cao, and M. W. Godfrey, “Investigating code review quality: Do people and participation matter?” in Proceedings of the 2015 IEEE International Conference on Software Maintenance and Evolution (ICSME), ser. ICSME ’15. Washington, DC, USA: IEEE Computer Society, 2015, pp. 111–120. [Online]. Available: http://dx.doi.org/10.1109/ICSM.2015.7332457
a00a997f1155382b2eb64dce1a9531b0 ; [32] J. Aranda and G. Venolia, “The secret life of bugs: Going past the errors and omissions in software repositories,” in Proceedings of the 31st international conference on software engineering, pp. 298–308, IEEE Computer Society, 2009.
8a9ed59804254a0baebf9fab5609b15c ; [17] G. Antoniol, K. Ayari, M. Di Penta, F. Khomh, and Y.-G. Guéhéneuc, “Is it a bug or an enhancement?: A text-based approach to classify change requests,” in Proceedings of the 2008 Conference of the Center for Advanced Studies on Collaborative Research: Meeting of Minds, ser. CASCON ’08. New York, NY, USA: ACM, 2008, pp. 23:304–23:318. [Online]. Available: http://doi.acm.org/10.1145/1463788.1463819
449f56a306595d1985a67c0b3d68918a ; [18] K. Herzig, S. Just, and A. Zeller, “It’s not a bug, it’s a feature: How misclassification impacts bug prediction,” in Proceedings of the International Conference on Software Engineering, ser. ICSE ’13. Piscataway, NJ, USA: IEEE Press, 2013, pp. 392–401. [Online]. Available: http://dl.acm.org/citation.cfm?id=2486788.2486840
5317cead184e4ffed3359636ee087163 ; [11] C. Bird, A. Bachmann, E. Aune, J. Duffy, A. Bernstein, V. Filkov, and P. Devanbu, “Fair and balanced? bias in bug-fix datasets,” in Proceedings of the 7th joint meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, 2009, pp. 121–130.
e88c033d9aac0e9bf801a00380c253b7 ; [34] S. Kim, H. Zhang, R. Wu, and L. Gong, “Dealing with noise in defect prediction,” in Proceedings of the 33rd International Conference on Software Engineering, pp. 481–490, IEEE, 2011.
2567e914cd7788ecc970766331fba446 ; [5] C. Tantithamthavorn, S. McIntosh, A. E. Hassan, A. Ihara, and K. Matsumoto, “The impact of mislabelling on the performance and interpretation of defect prediction models,” in Proceedings of the 37th International Conference on Software Engineering - Volume 1, ser. ICSE ’15. Piscataway, NJ, USA: IEEE Press, 2015, pp. 812–823. [Online]. Available: http://dl.acm.org/citation.cfm?id=2818754.2818852
dcade45108b64c802e39628cc525578d ; [18] T. H. D. Nguyen, B. Adams, and A. E. Hassan, “A case study of bias in bug-fix datasets,” in Proc. 17th Work. Conf. Reverse Eng.., 2010, pp. 259–268.
56079d01818eecd9a2c860dd26c5b539 ; [19] F. Rahman, D. Posnett, I. Herraiz, and P. Devanbu, “Sample size versus bias in defect prediction,” in Proc. 9th Joint Meeting Eur. Softw. Eng. Conf. Symp. Foundations Softw. Eng.., 2013, pp. 147–157.
38d47e9141e86f43189fdd8bd37c2efa ; [20] B. Turhan, “On the dataset shift problem in software engineering prediction models,” Empirical Softw. Eng., vol. 17, no. 1, pp. 62–74, 2012.
737ee2bd95ef706bee5bb88af0f028cf ; [11] Tim Menzies, Andrew Butcher, David R. Cok, Andrian Marcus, Lucas Layman, Forrest Shull, Burak Turhan, and Thomas Zimmermann. 2013. Local versus global lessons for defect prediction and effort estimation. IEEE Transactions on Software Engineering 39, 6 (2013), 822–834.
4b3cfb0491de5967c1542fda45efacac ; [42] S. Kim, T. Zimmermann, E. J. Whitehead Jr, and A. Zeller, “Predicting faults from cached history,” in Proceedings of the 29th international conference on Software Engineering, pp. 489–498, IEEE Computer Society, 2007.
a592d5779fe58f240bd542dba1c428ff ; [24] T. Zimmermann, N. Nagappan, and A. Zeller, “Predicting bugs from history,” in Software Evolution. Berlin, Germany: Springer, 2008, ch. 4, pp. 69–88.
9852b961c761837576c3642b6d30701f ; [11] J. Ekanayake, J. Tappolet, H. C. Gall, and A. Bernstein, “Tracking concept drift of software projects using defect prediction quality,” in Proceedings of the 6th IEEE International Working Conference on Mining Software Repositories. IEEE, 2009, pp. 51–60.
e3a752d05b829b03db6f3d0b8e9f05a1 ; [55] S. Mcintosh, Y. Kamei, B. Adams, and A. E. Hassan, “An empirical study of the impact of modern code review practices on software quality,” Empirical Softw. Engg., vol. 21, no. 5, pp. 2146–2189, Oct. 2016. [Online]. Available: http://dx.doi.org/10.1007/s10664-015-9381-9
c7497e4ee9d75e99a625d1df96c54d52 ; [52] P. Thongtanunam, S. McIntosh, A. E. Hassan, and H. Iida, “Investigating code review practices in defective files: An empirical study of the qt system,” in Proceedings of the 12th Working Conference on Mining Software Repositories. IEEE Press, 2015, pp. 168–179.
e6b810da9cae62b3d18dbe5bf3ba3e80 ; [28] P. Thongtanunam, S. McIntosh, A. E. Hassan, and H. Iida, “Review participation in modern code review: An empirical study of the Android, Qt, and OpenStack projects,” Empirical Softw. Eng., 2016. doi: 10.1007/s10664-016-9452-6.
19ca03ee6de50d945126d0a6af0eccae ; [51] A. Porter, H. Siy, A. Mockus, and L. Votta, “Understanding the sources of variation in software inspections,” ACM Transactions on Software Engineering and Methodology (TOSEM), vol. 7, no. 1, pp. 41–79, 1998.
57ddba4ea1eaf3024165e8fce3cae07f ; [35] E. S. Raymond, The Cathedral and the Bazaar. Sebastopol, CA, USA: O’Reilly Media, 1999.
53bff6a7245de95b8aa544c82b81e0f7 ; [54] S. McIntosh, Y. Kamei, B. Adams, and A. E. Hassan, “The impact of code review coverage and code review participation on software quality: A case study of the qt, vtk, and itk projects,” in Proceedings of the 11th Working Conference on Mining Software Repositories. ACM, 2014, pp. 192–201.
5a50a67074495535795e86bdb6dc30aa ; [18] S. Kim, T. Zimmermann, K. Pan, and E. J. J. Whitehead, “Automatic identification of bug-introducing changes,” in Proceedings of the 21st IEEE/ACM International Conference on Automated Software Engineering, ser. ASE ’06. Washington, DC, USA: IEEE Computer Society, 2006, pp. 81–90. [Online]. Available: http://dx.doi.org/10.1109/ASE.2006.23
d1f5e07d4552d4cff4d937403d70bbc9 ; [31] D. A. da Costa, S. McIntosh, W. Shang, U. Kulesza, R. Coelho, and A. E. Hassan, “A framework for evaluating the results of the szz approach for identifying bug-introducing changes,” IEEE Transactions on Software Engineering, vol. 43, no. 7, pp. 641–657, 2017.
7c0dbccd5d7cb29e764a438c0bede8a9 ; [41] W. S. Sarle, “The VARCLUS Procedure,” in SAS/STAT User’s Guide, 4th ed. Cary, NC, USA: SAS Institute, Inc., 1990.
ac23bf64722d25aea3f5bc8bf00acadf ; [42] F. E. Harrell Jr., K. L. Lee, R. M. Califf, D. B. Pryor, and R. A. Rosati, “Regression modelling strategies for improved prognostic pre- diction,” Statist.Med., vol. 3, no. 2, pp. 143–152, 1984.
d9abe2d49c65705e9783931cbd3f5888 ; [43] F. E. Harrell Jr., K. L. Lee, D. B. Matchar, and T. A. Reichert, “Regression models for prognostic prediction: Advantages, problems, and suggested solutions,” Cancer Treatment Rep., vol. 69, no. 10, pp. 1071–1077, 1985.
3220ecd7e2414ed544f69fad4704372f ; [44] R. Morales, S. McIntosh, and F. Khomh, “Do code review practices impact design quality? A case study of the Qt, VTK, and ITK Projects,” in Proc. Int. Conf. Softw. Eng., 2015, pp. 171–180.
eb99b7712912938a873e4a84e7120b15 ; [38] M. Zhou and A. Mockus, “Does the initial environment impact the future of developers?,” in Proceedings of the 33rd International Conference on Software Engineering, pp. 271–280, ACM, 2011.
fa9ce1a57af43ee835f6ce9aa838246f ; [46] F. E. Harrell Jr., Regression Modeling Strategies, 2nd ed. Berlin, Germany: Springer, 2015.
128995b9fa560d9ebf983e68e11e5732 ; Ghotra B, McIntosh S, Hassan AE (2015) Revisiting the impact of classification techniques on the performance of defect prediction models. In: Proceedings of the 37th International Conference on Software Engineering - Vol 1, ser. ICSE ’15. IEEE Press, pp 789–800 Guindon C Swt: The standard widget toolkit. [Online]. Available: https://www.eclipse.org/swt/
cb1bca9edb1584ec0f984e9f658567a9 ; [1] Miltiadis Allamanis, Earl T Barr, Premkumar Devanbu, and Charles Sutton. 2018. A survey of machine learning for big code and naturalness. ACM Computing Surveys (CSUR) 51, 4 (2018), 81.
0c466b62af167e79bf2469679fc3078e ; [2] Uri Alon, Shaked Brody, Omer Levy, and Eran Yahav. 2019. code2seq: Generating Sequences from Structured Representations of Code. In International Conference on Learning Representations.
4c1bf2a8ed58a524e4908c7b37f0d4c0 ; [3] Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. 2019. code2vec: Learning distributed representations of code. Proceedings of the ACM on Programming Languages 3, POPL (2019), 40.
763c5632daca6925cddead9abe43ff92 ; [4] George A Anastassiou. 2011. Univariate hyperbolic tangent neural network approximation. Mathematical and Computer Modelling 53, 5-6 (2011), 1111–1132.
3242f94dcbfc892f63c9f51acd8ef8ce ; [6] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).
78720bfe1a6ed4bb6fea7c0a34843f33 ; [7] Yalong Bai, Jianlong Fu, Tiejun Zhao, and Tao Mei. 2018. Deep attention neural tensor network for visual question answering. In Proceedings of the European Conference on Computer Vision (ECCV). 20–35.
9e3ef0f282460c690f7c7319a0f34172 ; [8] Moritz Beller, Georgios Gousios, and Andy Zaidman. 2017. Oops, my tests broke the build: An explorative analysis of Travis CI with GitHub. In 2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR). IEEE, 356– 367.
5cf89e4d14570ea2a2ff016475c45ca9 ; [9] Steven Bird and Edward Loper. 2004. NLTK: the natural language toolkit. In Proceedings of the ACL 2004 on Interactive poster and demonstration sessions. Association for Computational Linguistics, 31.
961a165b1af062a9f3a64fd03d071a05 ; [10] Guillaume Bouchard. 2007. Efficient bounds for the softmax function and applications to approximate inference in hybrid models. In NIPS 2007 workshop for approximate Bayesian inference in continuous/hybrid systems.
2719e560a6acb6990e085e6a9f6f68f4 ; [39] R. Caruana, S. Lawrence, and C. L. Giles, “Overfitting in neural nets: Backpropagation, conjugate gradient, and early stopping,” in Advances in neural information processing systems, 2001, pp. 402–408.
92daa30a627c23f4c71a2a7f0cebac96 ; [12] Olivier Chapelle, Bernhard Scholkopf, and Alexander Zien. 2009. Semi-supervised learning (chapelle, o. et al., eds.; 2006)[book reviews]. IEEE Transactions on Neural Networks 20, 3 (2009), 542–542.
19a3d026c34e026cfc80e861b43d7aeb ; [13] Brian Cheung. 2012. Convolutional neural networks applied to human face classification. In 2012 11th International Conference on Machine Learning and Applications, Vol. 2. IEEE, 580–583.
fb1c612127930b5a3ca10f7b8b20f5f6 ; [33] G. E. Dahl, T. N. Sainath, and G. E. Hinton, “Improving deep neural networks for lvcsr using rectified linear units and dropout,” in Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on. IEEE, 2013, pp. 8609–8613.
b3c13ed5a7bf53895dae0a8d24b4dbc0 ; [15] Daniel DeFreez, Aditya V Thakur, and Cindy Rubio-González. 2018. Path-based function embedding and its application to error-handling specification mining. In Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ACM, 423–433.
f4c793dedc773326640ab609cc1baed1 ; [16] Robert Dyer, Hoan Anh Nguyen, Hridesh Rajan, and Tien N Nguyen. 2013. Boa: A language and infrastructure for analyzing ultra-large-scale software repositories. In Proceedings of the 2013 International Conference on Software Engineering. IEEE Press, 422–431.
e7c3d54448daa4b4f72bed4c58a915d3 ; [17] Vasiliki Efstathiou and Diomidis Spinellis. 2019. Semantic source code models using identifier embeddings. In Proceedings of the 16th International Conference on Mining Software Repositories. IEEE Press, 29–33.
6c3fdd89070999fa59935f8e6d18cd50 ; [18] Xiaodong Gu, Hongyu Zhang, and Sunghun Kim. 2018. Deep code search. In 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE). IEEE, 933–944.
a571afd77815778d48401318a020e9a0 ; [44] M. T. Hagan and M. B. Menhaj, “Training feedforward networks with the Marquardt algorithm,” IEEE Transactions on Neural Networks, vol. 5, no. 6, pp. 989–993, 1994.
7625c61492054f4e61bbb08cf87c01c3 ; [20] Jordan Henkel, Shuvendu K Lahiri, Ben Liblit, and Thomas Reps. 2018. Code vectors: Understanding programs through embedded abstracted symbolic traces. In Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ACM, 163–174.
30f4c842677271dd4a4af3b118a40a23 ; [18] Thong Hoang, Hoa Khanh Dam, Yasutaka Kamei, David Lo, and Naoyasu Ubayashi. 2019. DeepJIT: an end-to-end deep learning framework for just-intime defect prediction. In 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR). IEEE, 34ś45. https://doi.org/10.1109/MSR.2019.00016
2ce6f45e3c2e0f946492851f4946f645 ; [22] Thong Hoang, Julia Lawall, Yuan Tian, Richard J Oentaryo, and David Lo. 2019. PatchNet: Hierarchical Deep Learning-Based Stable Patch Identification for the Linux Kernel. IEEE Transactions on Software Engineering (2019).
9ab7c3c0254e2f6527f50e34446af8ec ; [23] Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2018. Deep code comment generation. In Proceedings of the 26th Conference on Program Comprehension. ACM, 200–210.
9e29a6b3632195bb7d998e79468a8933 ; [24] Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. 2016. Summarizing source code using a neural attention model. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2073–2083.
0398ff2050b6edbc40c4b515b9aeb27a ; [25] Shuiwang Ji, Wei Xu, Ming Yang, and Kai Yu. 2012. 3D convolutional neural networks for human action recognition. IEEE transactions on pattern analysis and machine intelligence 35, 1 (2012), 221–231.
b30848552d48ef491cab7fd8146224ff ; [26] Siyuan Jiang, Ameer Armaly, and Collin McMillan. 2017. Automatically generating commit messages from diffs using neural machine translation. In Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering. IEEE Press, 135–146.
5b94a7601412923d57b1bfb81b08818f ; [27] Thorsten Joachims. 1999. Svmlight: Support vector machine. SVM-Light Support Vector Machine http://svmlight. joachims. org/, University of Dortmund 19, 4 (1999).
39160656a3e0d96bb3ded4269f84bd0a ; [41] Sunghun Kim, S. et al. 2008. Classifying Software Changes: Clean or Buggy? IEEE Transactions on Software Engineering. 34, 2 (Mar. 2008), 181–196. DOI:https://doi.org/10.1109/TSE.2007.70773.
7ea81182039becbb82a22aaae8099c15 ; [31] Yoon Kim. 2014. Convolutional Neural Networks for Sentence Classification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics, Doha, Qatar, 1746–1751. https://doi.org/10.3115/v1/D14-1181
b74752e83dce8bdd707f614d1dbb7b41 ; [32] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M Rush. 2017. Structured attention networks. arXiv preprint arXiv:1702.00887 (2017).
2f0aaec6e749a71fefad4695cfc0a262 ; [41] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” in Proceedings of 3rd International Conference on Learning Representations (ICLR), 2015.
de6b771a6a6e966eef87da7d752cccdb ; [34] Hiroyuki Kirinuki, Yoshiki Higo, Keisuke Hotta, and Shinji Kusumoto. 2014. Hey! are you committing tangled changes?. In Proceedings of the 22nd International Conference on Program Comprehension. ACM, 262–265.
3c2369571b204335dfe37923b606296a ; [35] Vladimir Kovalenko, Egor Bogomolov, Timofey Bryksin, and Alberto Bacchelli. 2019. PathMiner: a library for mining of path-based representations of code. In Proceedings of the 16th International Conference on Mining Software Repositories. IEEE Press, 13–17.
43480202385315d1f60e6119239ef2a3 ; [36] Alexander LeClair, Siyuan Jiang, and Collin McMillan. 2019. A neural model for generating natural language summaries of program subroutines. In Proceedings of the 41st International Conference on Software Engineering. IEEE Press, 795–806.
68a408e74b0f123d56f0d06a464378eb ; [37] Wee Sun Lee and Bing Liu. 2003. Learning with positive and unlabeled examples using weighted logistic regression. In ICML, Vol. 3. 448–455.
3ad2a279cdc774d5a04771c37070868d ; [38] Mario Linares-Vásquez, Luis Fernando Cortés-Coy, Jairo Aponte, and Denys Poshyvanyk. 2015. Changescribe: A tool for automatically generating commit messages. In 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, Vol. 2. IEEE, 709–712.
bd24a19eea78af182dbbcec061605393 ; [39] Zhongxin Liu, Xin Xia, Ahmed E Hassan, David Lo, Zhenchang Xing, and Xinyu Wang. 2018. Neural-machine-translation-based commit message generation: how far are we?. In Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. ACM, 373–384.
aa1ca07c0561fb25a9676bef8ff298c2 ; [40] Subhransu Maji, Lubomir Bourdev, and Jitendra Malik. 2011. Action recognition from a distributed representation of pose and appearance. In CVPR 2011. IEEE, 3177–3184.
80f779977ea48f6432c3832b41761d9d ; [41] Christopher Manning, Prabhakar Raghavan, and Hinrich Schütze. 2010. Introduction to information retrieval. Natural Language Engineering 16, 1 (2010), 100–103.
785910f0818a68484b073cf4a2662719 ; [43] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111–3119.
3b5ce2886c14acbab6b50a937cfa3db7 ; [45] Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve restricted boltzmann machines. In Proceedings of the 27th international conference on machine learning (ICML-10). 807–814. 528
a615dbf0c798c02e175c7d460cfdfd0c ; [46] Trong Duc Nguyen, Anh Tuan Nguyen, and Tien N Nguyen. 2016. Mapping API elements for code migration with vector representations. In 2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C). IEEE, 756–758.
d5c413ff3eb1319ffc56fc240aa54951 ; [47] Trong Duc Nguyen, Anh Tuan Nguyen, Hung Dang Phan, and Tien N Nguyen. 2017. Exploring API embedding for API usages and applications. In 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE). IEEE, 438–449.
a2290247b3d0853c61480e5fb89d7a80 ; [48] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics. Association for Computational Linguistics, 311–318.
f376356e5e0ae0662ba73da587477176 ; [49] Mohammad Masudur Rahman and Chanchal K Roy. 2015. TextRank based search term identification for software change tasks. In 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER). IEEE, 540–544.
1febd3529330e3b52d1c275843b57f61 ; [50] Mohammad Masudur Rahman, Chanchal K Roy, and Jason A Collins. 2016. Correct: code reviewer recommendation in github based on cross-project and technology experience. In 2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C). IEEE, 222–231.
ec8149c30194c3c9b057700c7bc7ac0c ; [40] R. Socher, A. Perelygin, J. Wu, J. Chuang, C. D. Manning, A. Y. Ng, and C. Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1631– 1642, Stroudsburg, PA, October 2013. Association for Computational Linguistics.
d29d8ef45c79440bc4c23de73c0dee15 ; [53] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research 15, 1 (2014), 1929–1958.
fb34a95a2fedad25519198c38e1385c7 ; [54] Daniel Svozil, Vladimir Kvasnicka, and Jiri Pospichal. 1997. Introduction to multilayer feed-forward neural networks. Chemometrics and intelligent laboratory systems 39, 1 (1997), 43–62.
1562683d812012599525cdc26d40d846 ; [56] Bart Theeten, Frederik Vandeputte, and Tom Van Cutsem. 2019. Import2vec learning embeddings for software libraries. In Proceedings of the 16th International Conference on Mining Software Repositories. IEEE Press, 18–28.
76a0b74741a1e44e77087de1486ce88f ; [57] Yuan Tian, Julia Lawall, and David Lo. 2012. Identifying Linux bug fixing patches. In Proceedings of the 34th International Conference on Software Engineering. IEEE Press, 386–396.
676cca97f4864395222a409135bd3fae ; [58] Ke Wang, Rishabh Singh, and Zhendong Su. 2017. Dynamic neural program embedding for program repair. arXiv preprint arXiv:1711.07163 (2017).
a232cca042b7fbc0ac7a67b7288f4429 ; [59] ShuohangWang and Jing Jiang. 2017. A Compare-Aggregate Model for Matching Text Sequences. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. https: //openreview.net/forum?id=HJTzHtqee
064bde6024ac6e91baadce0effc42922 ; [61] Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, Alex Smola, and Eduard Hovy. 2016. Hierarchical attention networks for document classification. In Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies. 1480–1489.
bf4a30e46bf588dca1011ffa225f4100 ; [62] Pengcheng Yin, Bowen Deng, Edgar Chen, Bogdan Vasilescu, and Graham Neubig. 2018. Learning to mine aligned code and natural language pairs from stack overflow. In 2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR). IEEE, 476–486. 529
7111515929d285219a6247edf3634957 ; [3] N. Nan and D. E. Harter, “Impact of budget and schedule pressure on software development cycle time and effort,” IEEE Transactions on Software Engineering (TSE), vol. 35, no. 5, pp. 624–637, 2009.
8ae1601633a06713a6896ef46920ec91 ; [10] S. Wang, L. L. Minku, and X. Yao, “Resampling-based ensemble methods for online class imbalance learning,” IEEE Transactions on Knowledge and Data Engineering (TKDE), vol. 27, no. 5, pp. 1356– 1368, 2015.
e1fc9506ff28d7dd2052b52e81c6359f ; [14] A. T. Misirli, E. Shihab, and Y. Kamei, “Studying high impact fixinducing changes,” Empirical Software Engineering Journal (EMSE), vol. 21, no. 2, pp. 605–641, 2016.
f4b89260b1664c78675c960bae080a9a ; [17] Z. Mahmood, D. Bowes, P. Lane, and T. Hall, “What is the impact of imbalance on software defect prediction performance?” in Proceedings of the 11th International Conference on Predictive Models and Data Analytics in Software Engineering (PROMISE), 2015, pp. 4.1–4.4.
2a875f143e0dfbe48dae7636f49a0b9e ; [18] S. Wang and X. Yao, “Using class imbalance learning for software defect prediction,” IEEE Transactions on Reliability (TR), vol. 62, no. 2, pp. 434–443, 2013.
e4419750e55fb69dc6b79b47b5af466d ; [20] K. E. Bennin, J. Keung, P. Phannachitta, A. Monden, and S. Mensah, “Mahakil: Diversity based oversampling approach to alleviate the class imbalance issue in software defect prediction,” IEEE Transactions on Software Engineering (TSE), vol. 44, no. 6, pp. 534–550, June 2018.
b8a2c3568ae8d4f8513dc6be03682685 ; [21] N. C. Oza, “Online bagging and boosting,” in Proceedings of the 2005 IEEE International Conference on Systems, Man and Cybernetics, vol. 3, 2005, pp. 2340–2345.
0db0106b9aff9946201792a3b00a4abe ; [23] P. Zhang, X. Zhu, J. Tan, and L. Guo, “Classifier and cluster ensembles for mining concept drifting data streams,” in Proceedings of the 2010 IEEE International Conference on Data Mining (ICDM), 2010, pp. 1175–1180.
b8aec0dad8ff98a7508e05ce1936cfc5 ; [24] K. B. Dyer, R. Capo, and R. Polikar, “Compose: A semi-supervised learning framework for initially labeled non-stationary streaming data,” IEEE Transactions on Neural Networks and Learning Systems (TNNLS), vol. 25, no. 1, pp. 12–26, 2013.
df288ed0ce8f64a21e6cb7b23bad4e24 ; [25] A. D. Pozzolo, G. Boracchi, O. Caelen, C. Alippi, and G. Bontempi, “Credit card fraud detection: a realistic modeling and a novel learning strategy,” IEEE Transactions on Neural Networks and Learning Systems (TNNLS), vol. 29, no. 8, pp. 3784–3797, 2018.
f2e6bf419bd19d89c74bcd46bb4be282 ; [26] M. Shepperd, Q. Song, Z. Sun, and C. Mair, “Data quality: Some comments on the nasa software defect datasets,” IEEE Transactions on Software Engineering (TSE), vol. 39, no. 9, pp. 1208–1215, 2013.
d8d4b0727e5f975878fc4bcfe47f1b21 ; [28] H. He and E. A. Garcia, “Learning from imbalanced data,” IEEE Transactions on Knowledge and Data Engineering (TKDE), vol. 21, no. 9, pp. 1263–1284, 2009.
ae5d2751cd516c841b2c99cecba00493 ; [27] Chakkrit Tantithamthavorn, Shane McIntosh, Ahmed E Hassan, and Kenichi Matsumoto. 2016. An empirical comparison of model validation techniques for defect prediction models. IEEE Transactions on Software Engineering (TSE) 43, 1 (2016), 1–18.
c5f1a186514541db1b1b5e7823af3c57 ; [43] Chakkrit Tantithamthavorn, Shane McIntosh, Ahmed E Hassan, and Kenichi Matsumoto. 2018. The impact of automated parameter optimization on defect prediction models. IEEE Transactions on Software Engineering (2018).
f0d5ce92ec1ce34685dba71b828f5025 ; [52] T. Menzies and M. Shepperd, “Special issue on repeatable results in software engineering prediction,” Empirical Software Engineering, vol. 17, no. 1-2, pp. 1–17, 2012.
4fd8440912f26f800697d46f14554b12 ; [36] L. Song, L. L. Minku, and X. Yao, “The impact of parameter tuning on software effort estimation using learning machines,” in Proceedings of the 9th International Conference on Predictive Models in Software Engineering (PROMISE), 2013, pp. 1–10.
69e657025fc4427a49ea2651b6e15f56 ; [2] A. E. Hassan. Predicting faults using the complexity of code changes. ICSE 2009: 78-88.
c08e3d00836c77ba1de7c1e854ea1dd5 ; [3] A. Meneely, L. Williams, W. Snipes, and J. Osborne, “Predicting failures with developer networks and social network analysis,” in SIGSOFT ’08/FSE-16, pp. 13–23.
8fd7a6fc35657a8500fc788fb409af45 ; [12] T. Fukushima, Y. Kamei, S. McIntosh, K. Yamashita, and N. Ubayashi. An empirical study of just-in-time defect prediction using cross-project models. In Proceedings of the 11th Working Conference on Mining Software Repositories, MSR 2014, pages 172–181, New York, NY, USA, 2014. ACM.
8a401a4f27e53c42cefd9dc1f5ecaa8f ; [7] N. Bettenburg, M. Nagappan, A. E. Hassan. Think locally, act globally: improving defect and effort prediction models. MSR 2012: 60-69.
85b04b40bbc5f1137e28f55f5578b03f ; [9] Y. Yang, Y. Zhou, J. Liu, Y. Zhao, H. Lu, L. Xu, B. Xu, and H. Leung, “Effort-aware just-in-time defect prediction: Simple unsupervised models could be better than supervised models,” in Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, ser. FSE 2016. New York, NY, USA: Association for Computing Machinery, 2016, p. 157–168. [Online]. Available: https://doi.org/10.1145/2950290.2950353
abd1917005728db4dd4c14ef0d019544 ; [11] L. Cheung, R. Roshandel, N. Medvidovic, and L. Golubchik, “Early prediction of software component reliability,” in ICSE ’08, pp. 111–120.
9835b9b5d8744bce9835de4fe2dfb63f ; [15] H. Valpola. Bayesian ensemble learning for nonlinear factor analysis. cta Polytechnic Scandinavia. Mathematics and Computing Series No.108, pp. 26-27
5753213e4cd9e76d423fb12e1ad7d5a8 ; [41] S. Zhong, T. M. Khoshgoftaar, and N. Seliya. Unsupervised learning for expert-based software quality estimation. In Proceedings of the Eighth IEEE International Conference on High Assurance Systems Engineering, HASE'04, pages 149{155, Washington, DC, USA, 2004. IEEE Computer Society.
2cdfc878b005f42729b92935081c86da ; [18] Y. Zhou, B. Xu, H. Leung, L. Chen. An in-depth study of the potentially confounding effect of class size in fault prediction. ACM Transactions on Software Engineering and Methodology, 2014, 23(1).
fa941cef9c263d6883f9a899bab7594e ; [20] Mockus, A. and Weiss, D.M. Predicting risk of software changes[J]. Bell Labs Technical Journal, 2000, 5(2): 169-180.
f2bd081a5c6147b612761a1b91527b18 ; [24] S. Wang, X. Yao, Using Class Imbalance Learning for Software Defect Prediction[J]. IEEE Transactions on Reliability, 2013, 62(2): 434-443.
13b2a99d888a4a47a95344498fe88582 ; [33] F. Rahman, D. Posnett, and P. Devanbu. Recalling the "imprecision" of cross-project defect prediction. In Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering, FSE '12, pages 61:1{61:11, New York, NY, USA, 2012. ACM.
58b80ff5c4e2f4bac8f0fc16e9e56f9f ; [32] F. Rahman and P. Devanbu. How, and why, process metrics are better. In Proceedings of the 2013 International Conference on Software Engineering, ICSE '13, pages 432{441, Piscataway, NJ, USA, 2013. IEEE Press.
5f532a3fc4f1ea403f37070f59a7a53a ; [30] Visual Studio, Microsoft. https://www.visualstudio.com/zh-hans/
f037c85c9000568efa3b949bc9c7ee01 ; [5] W. Fu and T. Menzies, “Revisiting unsupervised learning for defect prediction,” in ACM SIGSOFT International Symposium on Foundations of Software Engineering, FSE 2017, Paderborn, Germany, September 4- 8, 2017, E. Bodden, W. Sch¨afer, A. van Deursen, and A. Zisman, Eds. ACM, 2017, pp. 72–83.
94da5dc62f1f999db993f5789a27d9fe ; [4] Yoav Benjamini and Yosef Hochberg. 1995. Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal Statistical Society. Series B (Methodological) (1995), 289ś300.
8616aa3938bb135c2d46929c2f6609eb ; [34] J. Romano, J. D. Kromrey, J. Coraggio, J. Skowronek, L. Devine. Exploring methods for evaluating group differences on the NSSE and other surveys: Are the t-test and Cohen'sd indices the most appropriate choices. SAIR 2006.
7e29c35b58f3dfab4fca6884aff437a2 ; [38] N. Nagappan, T. Ball. Using software dependencies and churn metrics to predict field failures: An empirical case study. ESEM 2007: 364-373.
cd06975a0b14a5565fc940ee521fffd0 ; [4] Y. Shin, A. Meneely, L. Williams, and J. A. Osborne, “Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities,” IEEE Transactions on Software Engineering, vol. 37, no. 6, pp. 772–787, 2011.
f8c17402220a0e1e9554114ddfe871ae ; [1] “The economic impacts of inadequate infrastructure for software testing.” http://www.nist.gov/director/planning/upload/report02-3.pdf.
a59ad86bf17ac94b7f49a51b0f4509e8 ; Shihab E (2012) An exploration of challenges limiting pragmatic software defect prediction. Queen’s University (Canada), Ph.D. thesis
f702b1787be4e477f07dff96db679651 ; [5] Y. Brun, R. Holmes, M. D. Ernst, and D. Notkin, “Crystal: Precise and unobtrusive conflict warnings,” in Proceedings of the 19th ACM SIGSOFT symposium and the 13th European conference on Foundations of software engineering. ACM, 2011, pp. 444–447.
0fa6f5ea0d45671a0951251ed119b91a ; [6] M. L. Guimarães and A. R. Silva, “Improving early detection of software merge conflicts,” in Proceedings of the 34th International Conference on Software Engineering. IEEE Press, 2012, pp. 342–352.
af7df59aa6cc06aa2a493db59c52e03e ; [7] M. W. Godfrey, A. E. Hassan, J. Herbsleb, G. C. Murphy, M. Robillard, P. Devanbu, A. Mockus, D. E. Perry, and D. Notkin, “Future of mining software archives: A roundtable,” IEEE Software, vol. 26, no. 1, pp. 67 –70, Jan.-Feb. 2009.
082b822f0a532e3301d1a3f34a91ab7f ; [8] A. Hassan, “The road ahead for mining software repositories,” in Frontiers of Software Maintenance, 2008, Oct. 2008, pp. 48 –57.
f742ba205a00b96e1a3e3cf1dc11bf61 ; [9] E. Shihab, “Pragmatic prioritization of software quality assurance efforts,” in Proceedings of the 33rd International Conference on Software Engineering, ser. ICSE ’11, 2011, pp. 1106–1109.
7caf846386395764e6aa81d37024aeb2 ; [13] A. Hindle, D. M. German, and R. Holt, “What do large commits tell us?: A taxonomical study of large commits,” in Proceedings of the 2008 International Working Conference on Mining Software Repositories, ser. MSR ’08, 2008, pp. 99–108.
a18016ddaeb1965a1570181d3a447e9b ; [15] “List of file formats,” http://en.wikipedia.org/wiki/List_of_file_formats, Jun. 2015.
c9922cf462e737a8805f650f6ee7fd7c ; [1] P. M. Duvall, S. Matyas, and A. Glover, Continuous integration: improving software quality and reducing risk. Pearson Education, 2007.
2252887a7db031f3ba8acd3b62e75079 ; [2] G. Booch, Object oriented analysis & design with application. Pearson Education India, 2006.
ee2bdedd249fbb393c31e7e61492bb2e ; [3] K. Beck, Extreme programming explained: embrace change. addisonwesley professional, 2000.
e11a2f768aed6e21356f95a52c217396 ; [4] J. Humble and D. Farley, Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation (Adobe Reader). Pearson Education, 2010.
31b3739396242e853c091daad0b4367f ; [5] A. Hindle, A. Wilson, K. Rasmussen, E. J. Barlow, J. C. Campbell, and S. Romansky, “Greenminer: A hardware based mining software repositories software energy consumption framework,” in Proceedings of the 11th Working Conference on Mining Software Repositories. ACM, 2014, pp. 12–21.
65307fbeb3d3ad9b3e0ae2d605db786d ; [6] D. Pagano and W. Maalej, “User feedback in the appstore: An empirical study,” in Requirements Engineering Conference (RE), 2013 21st IEEE International. IEEE, 2013, pp. 125–134.
3c919960fb847ab9f22dd0fc3b0bd468 ; [7] A. Holzer and J. Ondrus, “Mobile application market: A developer’s perspective,” Telematics and informatics, vol. 28, no. 1, pp. 22–31, 2011.
5b70d2e3191ed1e2eba57b61f5e2d4ce ; [8] A. I. Wasserman, “Software engineering issues for mobile application development,” in FSE/SDP, 2010.
2b18604422dcba183bcc46ff1fd385fc ; [9] N. Chen, J. Lin, S. C. Hoi, X. Xiao, and B. Zhang, “Ar-miner: mining informative reviews for developers from mobile app marketplace,” in Proceedings of the 36th International Conference on Software Engineering. ACM, 2014, pp. 767–778.
320077c4dac22bd8f7c1818407dc9184 ; [10] A. Di Sorbo, S. Panichella, C. V. Alexandru, J. Shimagaki, C. A. Visaggio, G. Canfora, and H. C. Gall, “What would users change in my app? summarizing app reviews for recommending software changes,” in Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering. ACM, 2016, pp. 499–510.
60c83ceecf2a811b0ff1b96275c816ec ; [11] F. Palomba, P. Salza, A. Ciurumelea, S. Panichella, H. Gall, F. Ferrucci, and A. De Lucia, “Recommending and localizing change requests for mobile apps based on user reviews,” in Proceedings of the 39th International Conference on Software Engineering. IEEE Press, 2017, pp. 106–117.
03a8f0dd0b2aa20e63e24555540efd1b ; [11] Arvinder Kaur, Kamaldeep Kaur, and Harguneet Kaur. 2016. Application of machine learning on process metrics for defect prediction in mobile application. In Information Systems Design and Intelligent Applications. Springer, 81–98.
a0e0b16a89f5befb2636a4188f445e42 ; [3] Gemma Catolino. 2017. Just-in-time bug prediction in mobile applications: the domain matters!. In Proceedings of the 4th IEEE/ACM International Conference on Mobile Software Engineering and Systems (MOBILESoft). IEEE, 201–202.
434e94f349166e65cd9f130bf6571ecc ; [17] M. Linares-Vásquez, S. Klock, C. McMillan, A. Sabané, D. Poshyvanyk, and Y.-G. Guéhéneuc, “Domain matters: bringing further evidence of the relationships among anti-patterns, application domains, and qualityrelated metrics in java mobile apps,” in Proceedings of the 22nd International Conference on Program Comprehension. ACM, 2014, pp. 232–243.
17089030963b4971d25cd255b9911693 ; [18] H. van Heeringen and E. Van Gorp, “Measure the functional size of a mobile app: Using the cosmic functional size measurement method,” in IWSM-MENSURA, 2014.
463baa49d680235972aada147355d426 ; [21] T. Wang, W. Li, H. Shi, and Z. Liu, “Software defect prediction based on classifiers ensemble,” Journal of Information & Computational Science, vol. 8, no. 16, pp. 4241–4254, 2011.
6c5ddd8f75a15b86a6c4d05ee49d156e ; [22] D. Di Nucci, F. Palomba, R. Oliveto, and A. De Lucia, “Dynamic selection of classifiers in bug prediction: An adaptive method,” IEEE Transactions on Emerging Topics in Computational Intelligence, vol. 1, no. 3, pp. 202–212, 2017.
8675a25ff9e1fb8ec21ed1a864928a60 ; [23] J. Petri´c, D. Bowes, T. Hall, B. Christianson, and N. Baddoo, “Building an ensemble for software defect prediction based on diversity selection,” Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, p. 46, 2016.
2a3e989e4e878ba99274f896dd08c868 ; [25] J. R. Quinlan, “Induction of decision trees,” Machine learning, vol. 1, no. 1, pp. 81–106, 1986.
7c913614094752f4c227194e9499a3bd ; [26] S. Le Cessie and J. C. Van Houwelingen, “Ridge estimators in logistic regression,” Applied statistics, pp. 191–201, 1992.
3004152b3296d8c4a3b002c61937cfbf ; [27] R. Kohavi, “The power of decision tables,” in European conference on machine learning. Springer, 1995, pp. 174–189.
e69b6085df40c3b566fc1d62e54c54d2 ; [28] M. A. Hearst, S. T. Dumais, E. Osuna, J. Platt, and B. Scholkopf, “Support vector machines,” IEEE Intelligent Systems and their applications, vol. 13, no. 4, pp. 18–28, 1998.
7f46165474d11ee5836777d85df2cdab ; [29] R. O. Duda and P. E. Hart, Pattern classification and scene analysis, ser. A Wiley-Interscience publication. Wiley, 1973. [Online]. Available: http://www.worldcat.org/oclc/00388788
7f46165474d11ee5836777d85df2cdab ; [54] N. Cliff, Ordinal Methods for Behavioral Data Analysis. Hove, U.K.: Psychology Press, 2014. [Online]. Available: https://doi.org/10.4324/ 9781315806730
7f46165474d11ee5836777d85df2cdab ; [6] The crm114 discriminator - the controllable regex. [Online]. Available: http://crm114.sourceforge.net/
7f46165474d11ee5836777d85df2cdab ; Apache apache/cassandra (2019) [Online]. Available: https://github.com/apache/cassandra
7f46165474d11ee5836777d85df2cdab ; Apache hadoop (2020) [Online]. Available: https://hadoop.apache.org/
7f46165474d11ee5836777d85df2cdab ; Correlation (pearson kendall, spearman) (2020) [Online]. Available: https://www.statisticssolutions.com/ correlation-pearson-kendall-spearman/
7f46165474d11ee5836777d85df2cdab ; Dmwr (2020) [Online]. Available: https://www.rdocumentation.org/packages/DMwR/versions/0.4.1/topics/ SMOTE
2ab8a042b237e00edf8eab017325c4e7 ; [31] T. G. Dietterich, “Ensemble methods in machine learning,” International workshop on multiple classifier systems, pp. 1–15, 2000.
e38ff4a3845bc96024b2e3e2b9ad206a ; [32] L. Breiman, “Bagging predictors,” Machine learning, pp. 123–140, 1996.
a28c117d2d93724d5d77528b9b28bf51 ; [33] L. Rokach, “Ensemble-based classifiers,” Artificial Intelligence Review, vol. 33, no. 1, pp. 1–39, 2010.
6762a35b92e1c114f2bfea47463cf3ff ; [34] P. Refaeilzadeh, L. Tang, and H. Liu, “Cross-validation,” in Encyclopedia of database systems. Springer, 2009, pp. 532–538.
5def3624a382575c30ac9870622c5543 ; [19] D. Di Nucci, F. Palomba, G. De Rosa, G. Bavota, R. Oliveto, and A. De Lucia, “A developer centered bug prediction model,” IEEE Transactions on Software Engineering, vol. 44, no. 1, pp. 5–24, 2018.
8d06ca348359c9d08baa5727c6c4fd89 ; [1] L. Pascarella, F. Palomba, and A. Bacchelli, “Fine-grained just-in-time defect prediction,” Journal of Systems and Software, vol. 150, pp. 22 – 36, 2019. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0164121218302656
ff7589891b34bbdba9fe46cf0692279b ; [41] J. G. Barnett, C. K. Gathuru, L. S. Soldano, and S. McIntosh, “The relationship between commit message detail and defect proneness in java projects on github,” in Proceedings of the 13th International Conference on Mining Software Repositories. ACM, 2016, pp. 496–499.
66be0035a88a7ef7ce6d2d72a91a5ae7 ; [5] Qiao Huang, Xin Xia, and David Lo. 2017. Supervised vs unsupervised models: a holistic look at effort-aware just-in-time defect prediction. In IEEE International Conference on Software Maintenance and Evolution, ICSME. IEEE Computer Society, Shanghai, China, 159–170.
f30098f8daf9ce4e298dbfdda709f871 ; [31] Mathieu Nayrolles and Abdelwahab Hamou-Lhadj. 2018. CLEVER: combining code metrics with clone detection for just-in-time fault prevention and resolution in large industrial projects. In Proceedings of the 15th International Conference on Mining Software Repositories. ACM, 153–164.
94dc971259ab381fae7d6db4df3d931c ; [47] L. D’Avanzo, F. Ferrucci, C. Gravino, and P. Salza, “Cosmic functional measurement of mobile applications and code size estimation,” in Proceedings of the 30th Annual ACM Symposium on Applied Computing. ACM, 2015, pp. 1631–1636.
0c5812d1021d7ec54a8a547298e491f6 ; [48] R. Kohavi and G. H. John, “Wrappers for feature subset selection,” Artificial intelligence, vol. 97, no. 1-2, pp. 273–324, 1997.
a8442dfa96ca46c05ca954f9c27cc78e ; [51] S. Watanabe, H. Kaiya, and K. Kaijiri, “Adapting a fault prediction model to allow inter language reuse,” in Proc. of the 4th international workshop on Predictor models in software engineering. ACM, 2008, pp. 19–24.
6a3602bef5034360d44caeac6ea8e0ae ; [53] M. Jureczko and L. Madeyski, “Towards identifying software project clusters with regard to defect prediction,” in Proceedings of the 6th International Conference on Predictive Models in Software Engineering. ACM, 2010, p. 9.
ac0ba5210529b9c7793152a1cb2acc15 ; [56] Y. Zhang, D. Lo, X. Xia, and J. Sun, “An empirical study of classifier combination for cross-project defect prediction,” Proceedings of the IEEE Annual Computer Software and Applications Conference, vol. 2, pp. 264–269, 2015.
27ceb570a3bdf94c94e1970fbe3e2155 ; [57] Y. Liu, T. M. Khoshgoftaar, and N. Seliya, “Evolutionary optimization of software quality modeling with multiple repositories,” IEEE Transactions on Software Engineering, vol. 36, no. 6, pp. 852–864, Nov 2010.
6a6c2c2e17754cfb9012650cd9486798 ; [59] D. Bowes, T. Hall, and J. Petri´c, “Software defect prediction: do different classifiers find the same defects?” Software Quality Journal, vol. 26, no. 2, pp. 525–552, 2018.
0136cfbb3b5fadaac0141aea0c921ad3 ; [60] G. Catolino, F. Palomba, A. De Lucia, F. Ferrucci, and A. Zaidman, “Enhancing change prediction models using developer-related factors,” Journal of Systems and Software, vol. 143, pp. 14–28, 2018.
158929e490a2737a969958ecc5f081f1 ; [61] G. Seni and J. F. Elder, “Ensemble methods in data mining: improving accuracy through combining predictions,” Synthesis Lectures on Data Mining and Knowledge Discovery, vol. 2, no. 1, pp. 1–126, 2010.
9c6a6cae768ea4cf7abd9de3e72b3619 ; [62] G. Catolino, D. Di Nucci, and F. Ferrucci. (2019) Cross-project just-intime bug prediction for mobile app: An empirical assessment - online appendix https://figshare.com/s/9a075be3e1fb64f76b48.
13f8c6bb708069b4564da39ecf600d65 ; [66] G. Catolino, F. Palomba, A. De Lucia, F. Ferrucci, and A. Zaidman, “Developer-related factors in change prediction: an empirical assessment,” in Proceedings of the 25th International Conference on Program Comprehension. IEEE Press, 2017, pp. 186–195.
a4d4d920abe9c6359db4f0888371a10c ; [68] R. M. O’brien, “A caution regarding rules of thumb for variance inflation factors,” Quality & Quantity, vol. 41, no. 5, pp. 673–690, 2007.
0acf8be1231e24946c3d10b649fb576f ; [69] H. Liu and H. Motoda, Feature selection for knowledge discovery and data mining. Springer Science & Business Media, 2012, vol. 454.
0acf8be1231e24946c3d10b649fb576f ; [17] T. Menzies, J. Greenwald, A. Frank, "Data Mining Static Code Attributes to Learn Defect Predictors", IEEE Transactions on Software Engineering, vol. 32 no 11, 2007
8f8a67204e66c209da3196d12a91406c ; [71] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, “Smote: synthetic minority over-sampling technique,” Journal of artificial intelligence research, vol. 16, pp. 321–357, 2002.
ddb7ae2772c7ec5c6083504dadb34b00 ; [72] K. Ba´nczyk, O. Kempa, T. Lasota, and B. Trawi´nski, “Empirical comparison of bagging ensembles created using weak learners for a regression problem,” Asian Conference on Intelligent Information and Database Systems, pp. 312–322, 2011.
9855ba5d4087ebae18bca5f8e52f50cd ; [73] L. Reyzin and R. E. Schapire, “How boosting the margin can also boost classifier complexity,” Proceedings of the 23rd international conference on Machine learning, pp. 753–760, 2006.
8325202642a10a5394b87667433361d0 ; [75] E. Ceylan, F. O. Kutlubay, and A. B. Bener, “Software defect identification using machine learning techniques,” in Software Engineering and Advanced Applications, 2006. SEAA’06. 32nd EUROMICRO Conference on. IEEE, 2006, pp. 240–247.
b5209edfdf04bbe9715045c60c4a10cf ; [76] A. Okutan and O. T. Yıldız, “Software defect prediction using bayesian networks,” Empirical Software Engineering, vol. 19, no. 1, pp. 154–181, 2014.
5a4bab988d891de63e563dfff658b275 ; [77] J. Bergstra and Y. Bengio, “Random search for hyper-parameter optimization,” Journal of Machine Learning Research, vol. 13, no. Feb, pp. 281–305, 2012.
6dc093761aec52c79d885c071b23a753 ; [23] P. Baldi, S. Brunak, Y. Chauvin, C. A. F. Andersen, and H. Nielsen, “Assessing the accuracy of prediction algorithms for classification: An overview,” Bioinformatics, vol. 16, no. 5, pp. 412–424, 2000.
dd4912a445498bcfebdd9d659474c0fe ; [80] A. J. Scott and M. Knott, “A cluster analysis method for grouping means in the analysis of variance,” Biometrics, vol. 30, pp. 507–512, 1974.
50790bca85480acc40671cd29f3b25ca ; [81] F. Palomba, M. Linares-Vásquez, G. Bavota, R. Oliveto, M. Di Penta, D. Poshyvanyk, and A. De Lucia, “Crowdsourcing user reviews to support the evolution of mobile apps,” Journal of Systems and Software, vol. 137, pp. 143–162, 2018.
a49a8a2bf035e0a15c0e2ffbe29b83d5 ; [83] V. N. Inukollu, D. D. Keshamoni, T. Kang, and M. Inukollu, “Factors influencing quality of mobile apps: Role of mobile app development life cycle,” arXiv preprint arXiv:1410.4537, 2014.
815d921bbbf3997ea811bae2f34ef959 ; [84] P. Salza, F. Palomba, D. Di Nucci, C. D’Uva, A. De Lucia, and F. Ferrucci, “Do developers update third-party libraries in mobile apps?” 2018.
c97d2ecbab0de6b3c1e0dfb5483f05f8 ; [85] J. Li, T. Stålhane, J. M. Kristiansen, and R. Conradi, “Cost drivers of software corrective maintenance: An empirical study in two companies,” in Software Maintenance (ICSM), 2010 IEEE International Conference on. IEEE, 2010, pp. 1–8.
2609acc2b764635097ce38f78fd5a9bf ; [86] E. Kocaguneli, T. Menzies, and J. W. Keung, “On the value of ensemble effort estimation,” IEEE Transactions on Software Engineering, vol. 38, no. 6, pp. 1403–1416, 2012.
fe41d6176eaf3f5751ce02c0a790d5ba ; [87] G. Catolino and F. Ferrucci, “Ensemble techniques for software change prediction: A preliminary investigation,” in Machine Learning Techniques for Software Quality Evaluation (MaLTeSQuE), 2018 IEEE Workshop on. IEEE, 2018, pp. 25–30.
57db36052614d6fdb84ad25fac55799d ; [41] Chakkrit Tantithamthavorn, Shane McIntosh, Ahmed E Hassan, and Kenichi Matsumoto. 2016. Automated parameter optimization of classification techniques for defect prediction models. In Software Engineering (ICSE), 2016 IEEE/ACM 38th International Conference on. IEEE, 321–332.
4cb47a753747fb80ac14060d8c2f4ba5 ; [45] T. Wolf, A. Schroter, D. Damian, and T. Nguyen. Predicting build failures using social network analysis on developer communication. In Proceedings of the 31st International Conference on Software Engineering, ICSE ’09, pages 1–11, Washington, DC, USA, 2009. IEEE Computer Society.
d1a2465d1f131d8e1e7f59f4e374a150 ; [14] Tian Jiang, Lin Tan, and Sunghun Kim. 2013. Personalized defect prediction. In Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering. IEEE Press, 279–289.
c5ce94d295da13f41cc489a7a9f37d27 ; [10] M. D’Ambros, M. Lanza, and R. Robbes, “Evaluating defect prediction approaches: A benchmark and an extensive comparison,” Empirical Softw. Engg., vol. 17, no. 4-5, pp. 531–577, Aug. 2012. [Online]. Available: http://dx.doi.org/10.1007/s10664-011-9173-9
49d4585d5a1b5335652b40259bfa51a4 ; [46] Zimmermann, T. and Nagappan, N. 2008. Predicting defects using network analysis on dependency graphs. Proceedings of the international conference on software engineering (New York, New York, USA), 531.
ec471db73e4f76c4256b171279bd1614 ; [57] G. E. Hinton and R. R. Salakhutdinov, “Reducing the dimensionality of data with neural networks,” science, vol. 313, no. 5786, pp. 504–507, 2006.
ddeea9127d127030f61a05f180c22ff4 ; [10] G. E. Hinton, “Learning multiple layers of representation,” Trends in cognitive sciences, vol. 11, no. 10, pp. 428–434, 2007.
131ccb8a18c25a03b04ef924f11ffc8b ; [11] L. Deng, J. Li, J.-T. Huang, K. Yao, D. Yu, F. Seide, M. Seltzer, G. Zweig, X. He, J. Williams et al., “Recent advances in deep learning for speech research at microsoft,” in Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, 2013, pp. 8604–8608.
d42ff5ec03c0e3b04adebfa6bd295b75 ; [67] F. Rahman, D. Posnett, I. Herraiz, and P. Devanbu, “Sample size vs. bias in defect prediction,” in Proceedings of the 2013 9th joint meeting on foundations of software engineering. ACM, 2013, pp. 147–157.
538ee629f970c8257fc30fcee2191b9b ; 19. Arisholm, E., Briand, L.C., Fuglerud, M.: Data mining techniques for building fault‐proneness models in telecom java software. In: Proceedings of the 18th IEEE International Symposium on Software Reliability (ISSRE). (IEEE), pp. 215–224 (2007)
72f32504da0bf533219056f8377ac048 ; [18] J. Han and M. Kamber, Data Mining: Concepts and Techniques, 2006.
ae5040746fecbc718174900ecc6b30e1 ; [29] G. Hinton, S. Osindero, and Y.-W. Teh, “A fast learning algorithm for deep belief nets,” Neural computation, vol. 18, no. 7, pp. 1527–1554, 2006.
62595054ce7fba79397b56067688dbd1 ; [30] X. Xia, Y. Feng, D. Lo, Z. Chen, and X. Wang, “Towards more accurate multi-label software behavior learning,” in CSMR-WCRE, 2014, pp. 134–143.
01c0ae5f99deadec518b63cff4726a02 ; [31] X. Xia, D. Lo, X. Wang, and B. Zhou, “Tag recommendation in software information sites,” in MSR, 2013, pp. 287–296.
631a40ab354993a60716f2886fcbddd1 ; [38] N. Cliff, Ordinal Methods for Behavioral Data Analysis. New York, NY, USA: Psychology Press, 2014.
3e6a03b6ce9768d7bc08dee6536ac5d0 ; [34] X. X. Y. T. Xiao Xuan, David Lo, “Evaluating defect prediction approaches using a massive set of metrics: An empirical study,” in SAC. IEEE, 2015.
3f63c510ba50f060731ce398c4e4db2e ; [64] F. Peters, T. Menzies, and A. Marcus, “Better cross company defect prediction,” in Proc. 10th Work. Conf. Mining Softw. Repositories, 2013, pp. 409–418.
c1cbbe98ef962be5cbf488e8b2a18fd8 ; [37] M. L¨angkvist, L. Karlsson, and A. Loutfi, “A review of unsupervised feature learning and deep learning for time-series modeling,” Pattern Recognition Letters, vol. 42, pp. 11–24, 2014.
6aff4bbaf48ce3a2220fe91b3d4818e6 ; [38] Y.-l. Boureau, Y. L. Cun et al., “Sparse feature learning for deep belief networks,” in Advances in neural information processing systems, 2008, pp. 1185–1192.
a4a28b641e066adb910510533e5d8a4d ; [39] A.-r. Mohamed, G. E. Dahl, and G. Hinton, “Acoustic modeling using deep belief networks,” Audio, Speech, and Language Processing, IEEE Transactions on, vol. 20, no. 1, pp. 14–22, 2012.
746cb3a9070f057fcaf7e05bfec29749 ; [40] C. Zhu, J. Yin, and Q. Li, “A stock decision support system based on dbns,” Journal of Computational Information Systems, vol. 10, no. 2, pp. 883–893, 2014.
8e9a74dd48ecf09437d7d7c60b7667ca ; [39] Y. Kamei and E. Shihab, “Defect prediction: Accomplishments and future challenges,” in 2016 IEEE 23rd international conference on software analysis, evolution, and reengineering (SANER), vol. 5. IEEE, 2016, pp. 33–45.
c3d62e93e18c9b72ec8f5c20893ff079 ; [9] S. Wang, T. Liu, and L. Tan, “Automatically learning semantic features for defect prediction,” in Proceedings of the 38th International Conference on Software Engineering, ser. ICSE ’16. New York, NY, USA: ACM, 2016, pp. 297–308. [Online]. Available: http: //doi.acm.org/10.1145/2884781.2884804
2b22fe72451cd6832580e5237096569d ; [10] Z. Tu, Z. Su, and P. Devanbu, “On the localness of software,” in Proceedings of the 22Nd ACM SIGSOFT International Symposium on Foundations of Software Engineering, ser. FSE 2014. New York, NY, USA: ACM, 2014, pp. 269–280. [Online]. Available: http://doi.acm.org/10.1145/2635868.2635875
60525664602a2b8fecc72480b9207e79 ; [11] A. T. Nguyen and T. N. Nguyen, “Graph-based statistical language model for code,” in Proceedings of the 37th International Conference on Software Engineering - Volume 1, ser. ICSE ’15. Piscataway, NJ, USA: IEEE Press, 2015, pp. 858–868. [Online]. Available: http://dl.acm.org/citation.cfm?id=2818754.2818858
f74fd929bcbf359c2ee50dcf0840742c ; [12] A. Hindle, E. T. Barr, Z. Su, M. Gabel, and P. Devanbu, “On the naturalness of software,” in Proceedings of the 34th International Conference on Software Engineering, ser. ICSE ’12. Piscataway, NJ, USA: IEEE Press, 2012, pp. 837–847. [Online]. Available: http://dl.acm.org/citation.cfm?id=2337223.2337322
6aa83f5122b7ce260b9d208bf0862167 ; [13] Z. Li and Y. Zhou, “Pr-miner: Automatically extracting implicit programming rules and detecting violations in large software code,” in Proceedings of the 10th European Software Engineering Conference Held Jointly with 13th ACM SIGSOFT International Symposium on Foundations of Software Engineering, ser. ESEC/FSE-13. New York, NY, USA: ACM, 2005, pp. 306–315. [Online]. Available: http://doi.acm.org/10.1145/1081706.1081755
dfc77721cb9c5138d8d3311d9f038fef ; [25] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. nature 521, 7553 (2015), 436ś444. https://doi.org/10.1038/nature14539
c33e5bf9b158c1477ba1b043ef50c8b0 ; [17] C. dos Santos and M. Gatti, “Deep convolutional neural networks for sentiment analysis of short texts,” in Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, 2014, pp. 69–78.
97c973c3561f00c81e285b86afed7c6b ; [18] N. Kalchbrenner, E. Grefenstette, and P. Blunsom, “A convolutional neural network for modelling sentences,” arXiv preprint arXiv:1404.2188, 2014.
0453b9b91f46425d17405cf0d07d50e1 ; [19] X. Zhang, J. Zhao, and Y. LeCun, “Character-level convolutional networks for text classification,” in Advances in neural information processing systems, 2015, pp. 649–657.
be21496c000b08ae337b7da98e06558b ; [20] R. Johnson and T. Zhang, “Effective use of word order for text categorization with convolutional neural networks,” arXiv preprint arXiv:1412.1058, 2014.
feb959e0f4934ea47484c46ab969e4bc ; [22] A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, and L. Fei-Fei, “Large-scale video classification with convolutional neural networks,” in Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, 2014, pp. 1725–1732.
6a66c7af16a1937fda446397bf5c15e9 ; [23] S. Lawrence, C. L. Giles, A. C. Tsoi, and A. D. Back, “Face recognition: A convolutional neural-network approach,” IEEE transactions on neural networks, vol. 8, no. 1, pp. 98–113, 1997.
0e75bfc9ba20bc84abd39d875ac83c22 ; [24] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification with deep convolutional neural networks,” in Advances in neural information processing systems, 2012, pp. 1097–1105.
593345e2a023d0d2c8ffd504b862d08c ; [25] H. Zhao, O. Gallo, I. Frosio, and J. Kautz, “Loss functions for image restoration with neural networks,” IEEE Transactions on Computational Imaging, vol. 3, no. 1, pp. 47–57, 2017.
20e49986eb124733c5d0e4b81bb24bb3 ; [26] G. Tolias, R. Sicre, and H. J´egou, “Particular object retrieval with integral max-pooling of cnn activations,” arXiv preprint arXiv:1511.05879, 2015.
4a8cb8ee3b2e95829ae7bd9c51dda366 ; [27] M. D. Zeiler and R. Fergus, “Stochastic pooling for regularization of deep convolutional neural networks,” arXiv preprint arXiv:1301.3557, 2013.
a6884a9d311c2a9de282ac54a65f2d5e ; [28] L. Bottou, “Large-scale machine learning with stochastic gradient descent,” in Proceedings of the 19th International Conference on Computational Statistics (COMPSTAT). Springer, 2010, pp. 177–186.
5e5a93fad602975854c88c0484960ae1 ; [30] P. Willett, “The porter stemming algorithm: then and now,” Program, 2006.
8bf484ae6121ed990fc771ae1e276946 ; [31] M. White, C. Vendome, M. Linares-V´asquez, and D. Poshyvanyk, “Toward deep learning software repositories,” in Proceedings of the 12th Working Conference on Mining Software Repositories. IEEE Press, 2015, pp. 334–345.
39d9527c39cd96b24e59a06e2df115aa ; [34] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 770–778.
a00a60b8fb7580cf34db64ec0f161c6e ; [35] H. T. Ng and J. Zelle, “Corpus-based approaches to semantic interpretation in nlp,” AI magazine, vol. 18, no. 4, p. 45, 1997.
423dfaebb5ab6dea3c70fdc863caa212 ; [36] N. V. Chawla, N. Japkowicz, and A. Kotcz, “Special issue on learning from imbalanced data sets,” ACM Sigkdd Explorations Newsletter, vol. 6, no. 1, pp. 1–6, 2004.
465977b9e33bd0785a6c3ded5d5c7f71 ; [37] Z.-H. Zhou and X.-Y. Liu, “Training cost-sensitive neural networks with methods addressing the class imbalance problem,” IEEE Transactions on Knowledge and Data Engineering, vol. 18, no. 1, pp. 63–77, 2006.
9870a6ccdbc162576b6b6de6fd2403b1 ; [38] M. Kukar, I. Kononenko et al., “Cost-sensitive learning with neural networks.” in ECAI, 1998, pp. 445–449.
a09be5fbbac067b1a4821df125f090f7 ; [42] M. Anthimopoulos, S. Christodoulidis, L. Ebner, A. Christe, and S. Mougiakakou, “Lung pattern classification for interstitial lung diseases using a deep convolutional neural network,” IEEE transactions on medical imaging, vol. 35, no. 5, pp. 1207–1216, 2016.
e1b8fe04772fa6bc42cadb859dcf01d9 ; [43] S. Arora, N. Cohen, and E. Hazan, “On the optimization of deep networks: Implicit acceleration by overparameterization,” in 35th International Conference on Machine Learning (ICML), 2018, pp. 244–253.
4f016ed91e606aa5f8404c97f2a01728 ; [56] J. Fox, Applied regression analysis, linear models, and related methods. Sage Publications, Inc, 1997.
85f40dd167b527bfd8abd23937183bba ; [58] N. M. Nasrabadi, “Pattern recognition and machine learning,” Journal of electronic imaging, vol. 16, no. 4, p. 049901, 2007.
838b1d1d6ba1dfd94b497809b68bbec6 ; [59] G. H. Nguyen, A. Bouzerdoum, and S. L. Phung, “Learning pattern classification tasks with imbalanced data sets,” in Pattern recognition. InTech, 2009.
6c8ae92292c503a050be811f9a33bef2 ; [60] Q. Gu, Z. Cai, L. Zhu, and B. Huang, “Data mining on imbalanced data sets,” in Advanced Computer Theory and Engineering, 2008. ICACTE’08. International Conference on. IEEE, 2008, pp. 1020–1024.
cef2b5a340d43d763ca7be0712305c12 ; [61] A. Severyn and A. Moschitti, “Learning to rank short text pairs with convolutional deep neural networks,” in Proceedings of the 38th International Conference on Research and Development in Information Retrieval (SIGIR). ACM, 2015, pp. 373–382.
c39625571447bce0515e18cf8e9b82f1 ; [33] X. Huo, M. Li, Z.-H. Zhou et al., “Learning unified features from natural and programming languages for locating buggy source code.” in IJCAI, vol. 16, 2016, pp. 1606–1612.
41c6a38f9c79b26ae7b6be83127f9a7e ; [63] X. Huo and M. Li, “Enhancing the unified features to locate buggy files by exploiting the sequential nature of source code,” in Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI). AAAI Press, 2017, pp. 1909–1915.
9dc79d8910e221727c78f8feb81bfaad ; [64] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R. Salakhutdinov, “Improving neural networks by preventing co-adaptation of feature detectors,” arXiv preprint arXiv:1207.0580, 2012.
9fd70702fd578d5360ae226acaa2e1bc ; [65] L. Prechelt, “Automatic early stopping using cross validation: quantifying the criteria,” Neural Networks, vol. 11, no. 4, pp. 761–767, 1998.
aba3bece6d17e0023c28865ad6ea1aba ; [66] R. Kohavi et al., “A study of cross-validation and bootstrap for accuracy estimation and model selection,” in Ijcai, vol. 14, no. 2. Montreal, Canada, 1995, pp. 1137–1145.
6d3420f47419ae7b750b2c6d8f093200 ; [69] B. Korbar, A. M. Olofson, A. P. Miraflor, C. M. Nicka, M. A. Suriawinata, L. Torresani, A. A. Suriawinata, and S. Hassanpour, “Deep learning for classification of colorectal polyps on whole-slide images,” Journal of pathology informatics, vol. 8, 2017.
4b9823e8bb8f33574e67853050ba7140 ; [70] J. Liu, W.-C. Chang, Y. Wu, and Y. Yang, “Deep learning for extreme multi-label text classification,” in Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval. ACM, 2017, pp. 115–124.
58e5eda64ca30ff513f7ba78e2914541 ; [71] N. A. Gawande, J. A. Daily, C. Siegel, N. R. Tallent, and A. Vishnu, “Scaling deep learning workloads: Nvidia dgx-1/pascal and intel knights landing,” Future Generation Computer Systems, 2018.
81ea96fca86607c01641838269124099 ; Tantithamthavorn C, Hassan AE, Matsumoto K (2020) The impact of class rebalancing techniques on the performance and interpretation of defect prediction models. IEEE Trans Softw Eng 46(11):1200–1219 Team J Eclipse java development tools (jdt). [Online]. Available: https://www.eclipse.org/jdt/
3eea8edee7f8ac61664468ee27abe551 ; [45] SongWang, Taiyue Liu, Jaechang Nam, and Lin Tan. 2018. Deep semantic feature learning for software defect prediction. IEEE Transactions on Software Engineering (2018). https://doi.org/10.1109/TSE.2018.2877612
b318e4972228568b540ade470f24e22e ; [77] H. K. Dam, T. Tran, T. Pham, S. W. Ng, J. Grundy, and A. Ghose, “Automatic feature learning for predicting vulnerable software components,” IEEE Transactions on Software Engineering, 2019. [Online]. Available: DOI:10.1109/TSE.2018.2881961.
945819406ddd81f574b2ff7023761d0d ; [78] W. Yin, H. Sch¨utze, B. Xiang, and B. Zhou, “Abcnn: Attention-based convolutional neural network for modeling sentence pairs,” Transactions of the Association for Computational Linguistics, vol. 4, pp. 259–272, 2016.
ae45b0e27d8131a41d6487b24f70778b ; [1] Hervé Abdi. 2007. Bonferroni and Šidák corrections for multiple comparisons. Encyclopedia of measurement and statistics 3 (2007), 103–107.
d07f4b0be4d8b974fafd53b539c03da3 ; [2] Benjamin M Bolker, Mollie E Brooks, Connie J Clark, Shane W Geange, John R Poulsen, M Henry H Stevens, and Jada-Simone S White. 2009. Generalized linear mixed models: a practical guide for ecology and evolution. Trends in ecology & evolution 24, 3 (2009), 127–135.
45fce928b811ea0564c3e54d43a80a02 ; [23] A. P. Bradley, “The use of the area under the roc curve in the evaluation of machine learning algorithms,” Pattern recognition, vol. 30, no. 7, pp. 1145–1159, 1997.
f01449821e785d8eee2d51dbd2efcf28 ; [5] Jacek Czerwonka, Rajiv Das, Nachiappan Nagappan, Alex Tarvo, and Alex Teterev. 2011. Crane: Failure prediction, change analysis and test prioritization in practice– experiences from windows. In Software Testing, Verification and Validation (ICST), 2011 IEEE Fourth International Conference on. IEEE, 357–366.
f236c14761856076046c151238f165b2 ; [6] Yuanrui Fan, Xin Xia, David Lo, and Ahmed E Hassan. 2018. Chaff from the Wheat: Characterizing and Determining Valid Bug Reports. IEEE Transactions on Software Engineering (2018).
fea57eddacc5bc8f8d60716af903d226 ; [9] Frank E Harrell. 2001. Regression modeling strategies: with applications to linear models, logistic regression, and survival analysis. Springer.
1b53b06f716219c31cc8f55388bd0005 ; [10] Safwat Hassan, Chakkrit Tantithamthavorn, Cor-Paul Bezemer, and Ahmed E Hassan. 2018. Studying the dialogue between users and developers of free apps in the google play store. Empirical Software Engineering 23, 3 (2018), 1275–1312.
ab4320d065fe0412321459dc5d81f780 ; [7] Q. Huang, X. Xia, and D. Lo, “Revisiting supervised and unsupervised models for effort-aware just-in-time defect prediction,” Empirical Software Engineering, vol. 24, no. 5, pp. 2823–2862, 2019.
49f3921f4f493e09e59fd3a1575ff0db ; [21] P. C. Johnson, “Extension of nakagawa & schielzeth’s r2glmm to random slopes models,” Methods in Ecology and Evolution, vol. 5, no. 9, pp. 944–946, 2014.
c3970347e1ff3b49b3e38d3f24fc461a ; [20] Chris Lewis, Zhongpeng Lin, Caitlin Sadowski, Xiaoyan Zhu, Rong Ou, and E James Whitehead Jr. 2013. Does bug prediction support human developers? findings from a google case study. In Proceedings of the 2013 International Conference on Software Engineering. IEEE Press, 372–381.
ce044d3439280edec68efe4846533cca ; [21] Heng Li, Weiyi Shang, Ying Zou, and Ahmed E Hassan. 2017. Towards just-intime suggestions for log changes. Empirical Software Engineering 22, 4 (2017), 1831–1865.
e1d0dacd383b2856df773a0e9c2f76e5 ; [22] Chao Liu, Dan Yang, Xin Xia, Meng Yan, and Xiaohong Zhang. 2019. A twophase transfer learning model for cross-project defect prediction. Information and Software Technology 107 (2019), 125–136.
0b24122eefaff85b8f1741e07b386f78 ; [13] J. Liu, Y. Zhou, Y. Yang, H. Lu, and B. Xu, “Code churn: A neglected metric in effort-aware just-in-time defect prediction,” in ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, ESEM 2017, Toronto, ON, Canada, November 9-10, 2017, A. Bener, B. Turhan, and S. Biffl, Eds. IEEE Computer Society, 2017, pp. 11–19.
45ec74a2f75421aea070c6273fe0cce4 ; [19] Tim Menzies, Jeremy Greenwald, and Art Frank. 2006. Data mining static code attributes to learn defect predictors. IEEE Transactions on Software Engineering (TSE) 33, 1 (2006), 2–13.
e221cc014e38943171a9ec2b4e6fd811 ; [27] André N Meyer, Thomas Fritz, Gail C Murphy, and Thomas Zimmermann. 2014. Software developers’ perceptions of productivity. In Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering. ACM, 19–29.
7f4e08806efd797ce3dd809b52b515c0 ; [28] Osamu Mizuno and Tohru Kikuno. 2007. Training on errors experiment to detect fault-prone software modules by spam filter. In Proceedings of the the 6th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering. ACM, 405–414.
a5f7c28aa24da6d9cfcfa2f726d08233 ; [30] Shinichi Nakagawa and Holger Schielzeth. 2013. A general and simple method for obtaining R2 from generalized linear mixed-effects models. Methods in Ecology and Evolution 4, 2 (2013), 133–142.
2adf33abcbad7504af05ed7d715e9f77 ; [32] Chris Parnin and Alessandro Orso. 2011. Are automated debugging techniques actually helping programmers?. In Proceedings of the 2011 international symposium on software testing and analysis. ACM, 199–209.
25dfee5a882b900ae01713e462a9139e ; [33] Gopi Krishnan Rajbahadur, ShaoweiWang, Yasutaka Kamei, and Ahmed E Hassan. 2017. The impact of using regression models to build defect classifiers. In 2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR). IEEE, 135–145.
f0c19ce0ba94e3483471f197f192bcf8 ; [35] Martin Shepperd, David Bowes, and Tracy Hall. 2014. Researcher bias: The use of machine learning in software defect prediction. IEEE Transactions on Software Engineering 40, 6 (2014), 603–616.
298af13e92f3dfcecaeda189845993cb ; [38] Tom AB Snijders. 2005. Fixed and random effects. Encyclopedia of statistics in behavioral science (2005).
228d1a771fc42e64c664106e7a2f9529 ; [17] Chakkrit Tantithamthavorn and Ahmed E. Hassan. 2018. An experience report on defect modelling in practice: pitfalls and challenges. In Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice, ICSE (SEIP). ACM, Gothenburg, Sweden, 286–295.
0fb913da4f027993a89dddd31386fb6a ; [44] AB Tom, Tom AB Snijders Roel J Bosker, and Roel J Bosker. 1999. Multilevel analysis: an introduction to basic and advanced multilevel modeling. Sage.
a059fd4204f41c8beef07fd320fcbb1d ; [11] Zhiyuan Wan, Xin Xia, Ahmed E Hassan, David Lo, Jianwei Yin, and Xiaohu Yang. 2018. Perceptions, expectations, and challenges in defect prediction. IEEE Transactions on Software Engineering (TSE) (2018).
8277e0910d750195b448797616e091ad ; [46] Wikipedia. [n.d.]. https://en.wikipedia.org/wiki/Alibaba_Group. ([n. d.]).
bdcac5c85fdacc913236d5a4f541b778 ; [37] F. Wilcoxon, “Individual comparisons by ranking methods,” in Breakthroughs in Statistics. Berlin, Germany: Springer, 1992, pp. 196–202.
42599e7e195fee3ef48a0d544810b77b ; [48] Xin Xia, Lingfeng Bao, David Lo, Pavneet Singh Kochhar, Ahmed E Hassan, and Zhenchang Xing. 2017. What do developers search for on the web? Empirical Software Engineering 22, 6 (2017), 3149–3185.
26d31703e18b4631680ba8159cfee70b ; [49] Xin Xia, LO David, Sinno Jialin Pan, Nachiappan Nagappan, and Xinyu Wang. 2016. Hydra: Massively compositional model for cross-project defect prediction. IEEE Transactions on software Engineering 42, 10 (2016), 977.
151c5650778b6604ab2ab4dcff618935 ; [50] Meng Yan, Yicheng Fang, David Lo, Xin Xia, and Xiaohong Zhang. 2017. Filelevel defect prediction: Unsupervised vs. supervised models. In 2017 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM). IEEE, 344–353.
f8744685fd991b1fd4ceffc493f7e726 ; [51] Meng Yan, Xin Xia, David Lo, Ahmed E Hassan, and Shanping Li. 2019. Characterizing and identifying reverted commits. Empirical Software Engineering 24, 4 (2019), 2171–2208.
aa295e56e3a3ea6afb6c068724be0936 ; [52] Meng Yan, Xin Xia, Emad Shihab, David Lo, Jianwei Yin, and Xiaohu Yang. 2018. Automating change-level self-admitted technical debt determination. IEEE Transactions on Software Engineering 45, 12 (2018), 1211–1229.
9eb711a0c25fc2bda5d638fce7b7ec2f ; [57] Feng Zhang, Audris Mockus, Iman Keivanloo, and Ying Zou. 2014. Towards building a universal defect prediction model. In Proceedings of the 11th Working Conference on Mining Software Repositories. ACM, 182–191.
81a4f0149ddff56ea0aca12826fd4890 ; [63] F. Zhang, A. Mockus, Y. Zou, F. Khomh, and A. E. Hassan, “How does context affect the distribution of software maintainability metrics?” in Software Maintenance (ICSM), 2013 29th IEEE International Conference on. IEEE, 2013, pp. 350–359.
84aa335ae7d8d89b072e1789c5853b79 ; [59] Yuming Zhou, Yibiao Yang, Hongmin Lu, Lin Chen, Yanhui Li, Yangyang Zhao, Junyan Qian, and Baowen Xu. 2018. How FarWe Have Progressed in the Journey? An Examination of Cross-Project Defect Prediction. ACMTransactions on Software Engineering and Methodology (TOSEM) 27, 1 (2018), 1.
c7fa265b14451719e56c47673cc4a074 ; [1] E. Arisholm, L. C. Briand, and E. B. Johannessen. A systematic and comprehensive investigation of methods to build and evaluate fault prediction models. Journal of Systems and Software, 83(1):2{17, Jan. 2010.
fa27ef3ef6570e32a79e74deca7c1bc3 ; [2] Y. Benjamini and Y. Hochberg. Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing. Journal of the Royal Statistical Society. Series B (Methodological), 57(1):289{300, Jan. 1995.
fa27ef3ef6570e32a79e74deca7c1bc3 ; [35] B. Pang and L. Lee. Opinion Mining and Sentiment Analysis. Foundations and Trends in Information Retrieval, 2(1-2):1–135, Jan. 2008.
fa27ef3ef6570e32a79e74deca7c1bc3 ; [42] M. Thelwall, K. Buckley, and G. Paltoglou. Sentiment strength detection for the social web. J. Am. Soc. Inf. Sci. Technol., 63(1):163–173, Jan. 2012.
016201dfae4d28f1d303778e046490e0 ; [3] P. Bishnu and V. Bhattacherjee. Software Fault Prediction Using Quad Tree-Based K-Means Clustering Algorithm. IEEE Transactions on Knowledge and Data Engineering, 24(6):1146{1150, June 2012.
dd7c8a297a8d34ba5dc7cd4b45a1e593 ; [4] M. D'Ambros, M. Lanza, and R. Robbes. An extensive comparison of bug prediction approaches. In 2010 7th IEEE Working Conference on Mining Software Repositories (MSR), pages 31{41, May 2010.
c6795a8349a2bf4b8c586d9ef9108d64 ; [18] J. Ekanayake, J. Tappolet, H. C. Gall, and A. Bernstein, “Time variance and defect prediction in software projects,” Empirical Software Engineering, vol. 17, no. 4-5, pp. 348–389, 2012.
d41d8cd98f00b204e9800998ecf8427e ; 67. Wang Y, Liu J, Misˇic´ J, Misˇic´ VB, Lv S, Chang X (2019) Assessing optimizer impact on DNN model sensitivity to adversarial examples. IEEE Access 7:152766–152776. https://doi.org/ 10.1109/ACCESS.2019.2948658
d41d8cd98f00b204e9800998ecf8427e ; [19] D. W. Hosmer, Jr., S. Lemeshow, and R. X. Sturdivant, Applied Logistic Regression, 3rd ed. Hoboken, NJ, USA:Wiley, 2013. [Online]. Available: https://www.wiley.com/en-us/Applied Logistic Regression
d41d8cd98f00b204e9800998ecf8427e ; 1. Bishnu PS, Bhattacherjee V. Software fault prediction using quad tree-based k-means clustering algorithm. IEEE Trans Knowl Data Eng. 2012;24(6):1146-1150.
d41d8cd98f00b204e9800998ecf8427e ; 2. Elish MO, Al-Rahman Al-Khiaty M. A suite of metrics for quantifying historical changes to predict future change prone classes in object oriented software. J Softw Evol Process. 2013;25(5):407-437.
d41d8cd98f00b204e9800998ecf8427e ; 6. Ebrahimi NB. On the statistical analysis of the number of errors remaining in a software design document after inspection. IEEE Trans Softw Eng. 1997;23(8):529-532.
d41d8cd98f00b204e9800998ecf8427e ; 7. Thelin T, Runeson P. Confidence intervals for capture-recapture estimations in software inspections. Inf Softw Technol. 2002;44(12): 683-702.
d41d8cd98f00b204e9800998ecf8427e ; 9. Mockus A,Weiss DM. Predicting risk of software changes. Bell Labs Tech J. 2000;5(2):169-180.
d41d8cd98f00b204e9800998ecf8427e ; 11. Shivaji S, Whitehead Jr EJ, Akella R, Kim S. Reducing features to improve code change-based bug prediction. IEEE Trans Softw Eng. 2013;39(4):552-569.
d41d8cd98f00b204e9800998ecf8427e ; 16. Kamei Y, Shihab E, Adams B, et al. A large-scale empirical study of just-in-time quality assurance. IEEE Trans Softw Eng. 2013;39(6):757-773.
d41d8cd98f00b204e9800998ecf8427e ; 18. Rokach L. Ensemble-based classifiers. Artif Intell Rev. 2010;33(1-2):1-39.
d41d8cd98f00b204e9800998ecf8427e ; 21. Breiman L. Bagging predictors. Mach Learn. 1996;24(2):123-140.
d41d8cd98f00b204e9800998ecf8427e ; 27. Menzies T, Greenwald J, Frank A. Data mining static code attributes to learn defect predictors. IEEE Trans Softw Eng. 2007;33(1):2-13.
d41d8cd98f00b204e9800998ecf8427e ; 33. Dash M, Liu H. Feature selection for classification. Intell Data Anal. 1997;1(3):131-156.
d41d8cd98f00b204e9800998ecf8427e ; 35. Hall MA, Holmes G. Benchmarking attribute selection techniques for discrete class data mining. IEEE Trans Knowl Data Eng. 2003;15(6):1437-1447.
d41d8cd98f00b204e9800998ecf8427e ; 39. Breiman L. Random forests. Mach Learn. 2001;45(1):5-32.
d41d8cd98f00b204e9800998ecf8427e ; 44. Arisholm E, Briand LC, Johannssen EB. A systematic and comprehensive investigation of methods to build and evaluate fault prediction models. J Syst Softw. 2010;83(1):2-17.
d41d8cd98f00b204e9800998ecf8427e ; 45. Tantithamthavorn C, McIntosh S, HassanAE, Matsumoto K. An empirical comparison ofmodel validation techniques for defect prediction models. IEEE Trans Softw Eng. 2017;43(1):1-18.
d41d8cd98f00b204e9800998ecf8427e ; 46. Kittler J, Hatef M, Duin RPW, Matas J. On combining classifiers. IEEE Trans Pattern Anal Mach Intell. 1998;20(3):226-239.
d41d8cd98f00b204e9800998ecf8427e ; 47. Xia X, Lo D, Wang X, Yang X. Collective personalized change classification with multiobjective search. IEEE Trans Reliab. 2016;65(1):1810-1829.
d41d8cd98f00b204e9800998ecf8427e ; 50. Aha DW, Kibler D, Albert MK. Instance-based learning algorithms. Mach Learn. 1991;6(1):37-66.
d41d8cd98f00b204e9800998ecf8427e ; 53. Atkeson CG, Moore AW, Schaal S. Locally weighted learning. Artif Intell Rev. 1997;11(1-5):11-73.
d41d8cd98f00b204e9800998ecf8427e ; 56. Wang T, Zhang Z, Jing X, Zhang L. Multiple kernel ensemble learning for software defect prediction. Autom Softw Eng. 2016;23(4):1-22.
d41d8cd98f00b204e9800998ecf8427e ; 57. Wang S, Yao X. Using class imbalance learning for software defect prediction. IEEE Trans Reliab. 2013;62(2):434-443.
d41d8cd98f00b204e9800998ecf8427e ; 58. Drown DJ, Khoshgoftaar TM, Seliya N. Evolutionary sampling and software quality modeling of high-assurance systems. IEEE Trans Syst Man Cybern Part A SystHum. 2009;39(5):1097-1107.
d41d8cd98f00b204e9800998ecf8427e ; 60. Seiffert C, Khoshgoftaar TM, Van Hulse J. Improving software-quality predictions with data sampling and boosting. IEEE Trans SystMan Cybern Part A Syst Hum. 2009;39(6):1283-1294.
d41d8cd98f00b204e9800998ecf8427e ; 61. Sun Z, Song Q, Zhu X. Using coding-based ensemble learning to improve software defect prediction. IEEE Trans Syst Man Cybern Part C Appl Rev. 2012;42(6):1806-1817.
d41d8cd98f00b204e9800998ecf8427e ; 62. Jing X-Y, Wu F, Dong X, Xu B. An improved SDA based defect prediction framework for both within-project and cross-project class-imbalance problems. IEEE Trans Softw Eng. 2017;43(4):321-339.
d41d8cd98f00b204e9800998ecf8427e ; 63. Zhu M, Martinez MA. Subclass discriminant analysis. IEEE Trans Pattern Anal Mach Intell. 2006;28(8):1274-1286.
d41d8cd98f00b204e9800998ecf8427e ; 2. Kamei Y, Shihab E, Adams B, et al. A large-scale empirical study of just-in-time quality assurance. IEEE Trans Softw Eng. 2012;39(6):757-773.
d41d8cd98f00b204e9800998ecf8427e ; 6. Mockus A, Weiss DM. Predicting risk of software changes. Bell Labs Tech J. 2000;5(2):169-180.
d41d8cd98f00b204e9800998ecf8427e ; 16. McIntosh S, Kamei Y. Are fix-inducing changes a moving target? a longitudinal case study of just-in-time defect prediction. IEEE Trans Softw Eng. 2017;44(5):412-428.
d41d8cd98f00b204e9800998ecf8427e ; 20. Hall T, Beecham S, Bowes D, Gray D, Counsell S. A systematic literature review on fault prediction performance in software engineering. IEEE Trans Softw Eng. 2011;38(6):1276-1304.
d41d8cd98f00b204e9800998ecf8427e ; 22. Malhotra R. A systematic review of machine learning techniques for software fault prediction. Appl Soft Comput. 2015;27:504-518.
d41d8cd98f00b204e9800998ecf8427e ; 23. Pascarella L, Palomba F, Bacchelli A. Fine-grained just-in-time defect prediction. J Syst Softw. 2019;150:22-36.
d41d8cd98f00b204e9800998ecf8427e ; 24. Mockus A, Eick SG, Graves TL, Karr AF. On measurement and analysis of software changes. IEEE Trans Softw Eng. 1999;20:29.
d41d8cd98f00b204e9800998ecf8427e ; 28. Huang Q, Xia X, Lo D. Revisiting supervised and unsupervised models for effort-aware just-in-time defect prediction. Empir Softw Eng. 2019;24(5): 2823-2862.
d41d8cd98f00b204e9800998ecf8427e ; 29. Misirli AT, Shihab E, Kamei Y. Studying high impact fix-inducing changes. Empir Softw Eng. 2016;21(2):605-641.
d41d8cd98f00b204e9800998ecf8427e ; 31. Kamei Y, Fukushima T, McIntosh S, Yamashita K, Ubayashi N, Hassan AE. Studying just-in-time defect prediction using cross-project models. Empir Softw Eng. 2016;21(5):2072-2106.
d41d8cd98f00b204e9800998ecf8427e ; 36. Xia X, Lo D, Wang X, Yang X. Collective personalized change classification with multiobjective search. IEEE Trans Reliab. 2016;65(4):1810-1829.
d41d8cd98f00b204e9800998ecf8427e ; 37. Yang X, Yu H, Fan G, Shi K, Chen L. Local versus Global Models for Just-In-Time Software Defect Prediction. Sci Prog. 2019;2019:1-13.
d41d8cd98f00b204e9800998ecf8427e ; 40. Bergmeir C, Benıt́ ez JM. On the use of cross-validation for time series predictor evaluation. Inform Sci. 2012;191:192-213.
d41d8cd98f00b204e9800998ecf8427e ; 44. Graves TL, Karr AF, Marron JS, Siy H. Predicting fault incidence using software change history. IEEE Trans Softw Eng. 2000;26(7):653-661.
d41d8cd98f00b204e9800998ecf8427e ; 49. Lee DD, Seung HS. Learning the parts of objects by non-negative matrix factorization. Nature. 1999;401(6755):788-791.
d41d8cd98f00b204e9800998ecf8427e ; 50. Quinlan JR. Induction of decision trees. Mach Learn. 1986;1(1):81-106.
d41d8cd98f00b204e9800998ecf8427e ; 54. Matthews BW. Comparison of the predicted and observed secondary structure of T4 phage lysozyme. Biochimica et Biophys Acta (BBA)-Protein Struct. 1975;405(2):442-451.
d41d8cd98f00b204e9800998ecf8427e ; 55. Hanley JA, McNeil BJ. The meaning and use of the area under a receiver operating characteristic (ROC) curve. Radiology. 1982;143(1):29-36.
d41d8cd98f00b204e9800998ecf8427e ; 56. Menzies T, Greenwald J, Frank A. Data mining static code attributes to learn defect predictors. IEEE Trans Softw Eng. 2007;33(1):2-13.
d41d8cd98f00b204e9800998ecf8427e ; 57. Tharwat A. Classification assessment methods. Appl Comput Inf. 2020.
d41d8cd98f00b204e9800998ecf8427e ; 60. Turhan B, Menzies T, Bener AB, Di Stefano J. On the relative value of cross-company and within-company data for defect prediction. Empir Softw Eng. 2009;14(5):540-578.
d41d8cd98f00b204e9800998ecf8427e ; 61. Turhan B, Mısırlı AT, Bener A. Empirical evaluation of the effects of mixed project data on learning defect predictors. Inf Softw Technol. 2013;55(6): 1101-1118.
d41d8cd98f00b204e9800998ecf8427e ; 64. Koren Y, Bell R, Volinsky C. Matrix factorization techniques for recommender systems. IEEE Comput. 2009;8:30-37.
d41d8cd98f00b204e9800998ecf8427e ; 67. Nugroho YS, Hata H, Matsumoto K. How different are different diff algorithms in Git? Empir Softw Eng. 2020;25(1):790-823.
d41d8cd98f00b204e9800998ecf8427e ; 68. Tantithamthavorn C, McIntosh S, Hassan AE, Matsumoto K. An empirical comparison of model validation techniques for defect prediction models. IEEE Trans Softw Eng. 2017;43(1):1-18.
d41d8cd98f00b204e9800998ecf8427e ; 69. Avazpour I, Pitakrat T, Grunske L, Grundy J. Dimensions and metrics for evaluating recommendation systems. Springer; 2014:245-273.
d41d8cd98f00b204e9800998ecf8427e ; 5. Ardimento P, Aversano L, Bernardi ML, Cimitile M, Iammarino M (2021) Temporal convolutional networks for just-in-time design smells prediction using fine-grained software metrics. Neurocomput 463:454–471. 10.1016/j.neucom.2021.08.010. https://www.sciencedirect.com/science/article/pii/ S0925231221011942
d41d8cd98f00b204e9800998ecf8427e ; 8. Bai S, Kolter JZ, Koltun V (2018) An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. CoRR arXiv:1803.01271
d41d8cd98f00b204e9800998ecf8427e ; 10. Basili VR, Briand LC, Melo WL (1996) A validation of objectoriented design metrics as quality indicators. IEEE Trans Software Eng 22(10):751–761. https://doi.org/10.1109/32.544352
d41d8cd98f00b204e9800998ecf8427e ; 11. Bengio Y (2000) Gradient-based optimization of hyperparameters. Neural Comput 12(8):1889–1900. https://doi.org/10.1162/ 089976600300015187
d41d8cd98f00b204e9800998ecf8427e ; 23. Chidamber SR, Kemerer CF (1994) A metrics suite for object oriented design. IEEE Trans Software Eng 20(6):476–493. https://doi.org/10.1109/32.295895
d41d8cd98f00b204e9800998ecf8427e ; 24. Chidamber SR, Kemerer CF (1994) A metrics suite for object oriented design. IEEE Trans Softw Eng 20(6):476–493. https:// doi.org/10.1109/32.295895
d41d8cd98f00b204e9800998ecf8427e ; 36. Hochreiter S, Schmidhuber J (1997) Long short-term memory. Neural Comput 9(8):1735–1780. https://doi.org/10.1162/neco. 1997.9.8.1735
d41d8cd98f00b204e9800998ecf8427e ; 39. Jin C (2021) Cross-project software defect prediction based on domain adaptation learning and optimization. Expert Syst Appl 171(114637):1. 10.1016/j.eswa.2021.114637. https://www.scien cedirect.com/science/article/pii/S0957417421000786
d41d8cd98f00b204e9800998ecf8427e ; 40. Kamei Y, Fukushima T, McIntosh S, Yamashita K, Ubayashi N, Hassan AE (2016) Studying just-in-time defect prediction using cross-project models. Empir Softw Eng 21(5):2072–2106. https:// doi.org/10.1007/s10664-015-9400-x
d41d8cd98f00b204e9800998ecf8427e ; 41. Kamei Y, Shihab E, Adams B, Hassan AE, Mockus A, Sinha A, Ubayashi N (2013) A large-scale empirical study of just-in-time quality assurance. IEEE Trans Softw Eng 39(6):757–773. https:// doi.org/10.1109/TSE.2012.70
d41d8cd98f00b204e9800998ecf8427e ; 44. Manjula C, Florence L (2019) Deep neural network based hybrid approach for software defect prediction using software metrics. Clust Comput 22(4):9847–9863. https://doi.org/10.1007/s10586- 018-1696-z
d41d8cd98f00b204e9800998ecf8427e ; 52. Pascarella L, Palomba F, Bacchelli A (2019) Fine-grained just-intime defect prediction. J Syst Softw 150:22–36. https://doi.org/ 10.1016/j.jss.2018.12.001
d41d8cd98f00b204e9800998ecf8427e ; 54. Phan AV, Nguyen ML, Bui LT (2018) Convolutional neural networks over control flow graphs for software defect prediction. CoRR arXiv:1802.04986
d41d8cd98f00b204e9800998ecf8427e ; 58. Ramachandran P, Zoph B, Le QV (2017) Searching for activation functions. CoRR arXiv:1710.05941
d41d8cd98f00b204e9800998ecf8427e ; 61. Staudemeyer RC, Rothstein Morris E (2019) Understanding LSTM – a tutorial into Long Short-Term Memory Recurrent Neural Networks. arXiv e-prints arXiv:1909.09586
d41d8cd98f00b204e9800998ecf8427e ; 65. Varma S, Simon R (2006) Bias in error estimation when using cross-validation for model selection. BMC Bioinf 7:91. https:// doi.org/10.1186/1471-2105-7-91
d41d8cd98f00b204e9800998ecf8427e ; 66. Wang T, Zhang Z, Jing X, Zhang L (2016) Multiple kernel ensemble learning for software defect prediction. Autom Softw Eng 23(4):569–590. https://doi.org/10.1007/s10515-015-0179-1
d878c179fbeef70c7ff44efb1b7c6582 ; [8] B. Ghotra, S. McIntosh, and A. E. Hassan. Revisiting the Impact of Classification Techniques on the Performance of Defect Prediction Models. In 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering (ICSE), volume 1, pages 789{800, May 2015.
d878c179fbeef70c7ff44efb1b7c6582 ; [38] E. Shihab, Y. Kamei, B. Adams, and A. E. Hassan. Is lines of code a good measure of effort in effort-aware models? Information and Software Technology, 55(11):1981–1993, 2013.
d878c179fbeef70c7ff44efb1b7c6582 ; [6] Y. Kamei, T. Fukushima, S. McIntosh, K. Yamashita, N. Ubayashi, and A. E. Hassan. Studying Just-In-Time Defect Prediction using Cross-Project Models. Empir- ical Software Engineering, To appear, 2016.
ca5159e41edde1c39d84636151786245 ; [12] Y. Kamei, S. Matsumoto, A. Monden, K.-i. Matsumoto, B. Adams, and A. E. Hassan. Revisiting Common Bug Prediction Findings Using Effort-aware Models. In Proceedings of the 2010 IEEE International Conference on Software Maintenance, ICSM '10, pages 1{10, Washington, DC, USA, 2010. IEEE Computer Society.
ac0ff94e37e3a13e0c92e1a167720d60 ; [14] H. Khalid, M. Nagappan, E. Shihab, and A. E. Hassan. Prioritizing the Devices to Test Your App on: A Case Study of Android Game Apps. In Proceedings of the 22Nd ACM SIGSOFT International Symposium on Foundations of Software Engineering, FSE 2014, pages 610{620, New York, NY, USA, 2014. ACM.
1fc4dcc9da57b0a308326ad9be2db4cc ; [17] A. Koru, D. Zhang, and H. Liu. Modeling the Effect of Size on Defect Proneness for Open-Source Software. pages 115{124, May 2007.
72b9913e72208a8701eb0f99d41b6b36 ; [18] A. G. Koru, K. E. Emam, D. Zhang, H. Liu, and D. Mathew. Theory of relative defect proneness. Empirical Software Engineering, 13(5):473{498, Oct. 2008.
adfb110e3ded45d7221df3de5d7be81d ; [14] G. Koru, H. Liu, D. Zhang, and K. E. Emam, “Testing the theory of relative defect proneness for closed-source software,” Empirical Software Engineering, vol. 15, no. 6, pp. 577–598, 2010.
c900086c66cc198c5335bd9cbb17f17c ; [21] C. Lewis, Z. Lin, C. Sadowski, X. Zhu, R. Ou, and E. J. Whitehead Jr. Does Bug Prediction Support Human Developers? Findings from a Google Case Study. In Proceedings of the 2013 International Conference on Software Engineering, ICSE '13, pages 372{381, Piscataway, NJ, USA, 2013. IEEE Press.
7223e8673a7afd34bb486fc89a111b41 ; [26] T. Menzies, Z. Milton, B. Turhan, B. Cukic, Y. Jiang, and A. Bener. Defect prediction from static code features: current results, limitations, new approaches. Automated Software Engineering, 17(4):375{407, May 2010.
cf7a2216034ddbc62bb1b1b3d70d1272 ; [28] A. Mockus and D. M. Weiss. Predicting risk of software changes. Bell Labs Technical Journal, 5(2):169{180, Apr. 2000.
cf7a2216034ddbc62bb1b1b3d70d1272 ; [5] N. Bettenburg and A. E. Hassan. Studying the impact of social interactions on software quality. Empirical Softw. Engg., 18(2):375–431, Apr. 2013.
cf7a2216034ddbc62bb1b1b3d70d1272 ; [7] J. M. Bland and D. G. Altman. Transformations, means, and confidence intervals. BMJ, 312(7038):1079, Apr. 1996.
7deee6528038df0f25579842713d751b ; [29] A. Monden, T. Hayashi, S. Shinoda, K. Shirai, J. Yoshida, M. Barker, and K. Matsumoto. Assessing the Cost Effectiveness of Fault Prediction in Acceptance Testing. IEEE Transactions on Software Engineering, 39(10):1345{1357, Oct. 2013.
ffe3609dee8fb28bef0288730dbf1d5d ; [31] A. T. Nguyen, T. T. Nguyen, H. A. Nguyen, and T. N. Nguyen. Multi-layered Approach for Recovering Links Between Bug Reports and Fixes. In Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering, FSE '12, pages 63:1{63:11, New York, NY, USA, 2012. ACM.
b16fc4aa95080a0053114890322e30af ; [34] F. Rahman, D. Posnett, A. Hindle, E. Barr, and P. Devanbu. BugCache for Inspections: Hit or Miss? In Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering, ESEC/FSE '11, pages 322{331, New York, NY, USA, 2011. ACM.
47ecec1778f93dec87cf94e5ce8dbf62 ; [35] J. Romano, J. D. Kromrey, J. Coraggio, and J. Skowronek. Appropriate statistics for ordinal level data: Should we really be using t-test and cohen's d for evaluating group differences on the nsse and other surveys. In annual meeting of the Florida Association of Institutional Research, pages 1{33, 2006.
47ecec1778f93dec87cf94e5ce8dbf62 ; [81] X. Yang, D. Lo, X. Xia, and J. Sun. Tlel: A two-layer ensemble learning approach for just-in-time defect prediction. Information and Software Technology, 87:206–220, 2017.
d9dba1350e8eca5f2ad45e76a0a5970a ; [39] Y. Yang, Y. Zhou, H. Lu, L. Chen, Z. Chen, B. Xu, H. Leung, and Z. Zhang. Are Slice-Based Cohesion Metrics Actually Useful in Effort-Aware Post-Release Fault-Proneness Prediction? An Empirical Study. IEEE Transactions on Software Engineering, 41(4):331{357, Apr. 2015.
d7b85f12bdf36266db695411a654f73f ; [42] Y. Zhou, B. Xu, H. Leung, and L. Chen. An in-depth study of the potentially confounding effect of class size in fault prediction. ACM Trans. Softw. Eng. Methodol., 23(1):10:1{10:51, Feb. 2014.
c57583e3bbebdec533c79a5d260d2561 ; 1. Angluin, D., Laird, P.D.: Learning from noisy examples. Mach. Learn. 2(4), 343– 370 (1987)
90f9ff58826b9b835e740ad5d2a9ea2c ; 2. Arshad, A., Riaz, S., Jiao, L., Murthy, A.: Semi-supervised deep fuzzy c-mean clustering for software fault prediction. IEEE Access 6, 25675–25685 (2018)
95723926a2574fd876fd883bcebc007c ; 3. Blum, A., Mitchell, T.M.: Combining labeled and unlabeled data with co-training. In: Proceedings of COLT, pp. 92–100 (1998)
ff0f5de2bbd7ffdfd2d705eadd123987 ; 4. Chapelle, O., Scholkopf, B., Zien, A.: Semi-supervised learning. IEEE Trans. Neural Netw. 20(3), 542–542 (2006)
cc834f95a9d20e00eaf93452c680da3e ; 9. Romano, J., Kromrey, J.D., Coraggio, J., Skowronek, J., Devine, L.: Exploring methods for evaluating group differences on the NSSE and other surveys: are the t-test and Cohen’s d indices the most appropriate choices. In: Annual Meeting of the Southern Association for Institutional Research (2006)
78cd4ae4e216bee0fbb52e3e45703412 ; 10. Jiang, Y., Li, M., Zhou, Z.: Software defect detection with rocus. J. Comput. Sci. Technol. 26(2), 328–342 (2011)
c590d83b50d1155e9916d0c418fcd303 ; 13. Li, M., Zhang, H., Wu, R., Zhou, Z.: Sample-based software defect prediction with active and semi-supervised learning. Autom. Softw. Eng. 19(2), 201–230 (2012)
95b3df19054a8d7c8821a5eaacb3409f ; 14. Li, W., Huang, Z., Li, Q.: Three-way decisions based software defect prediction. Knowl.-Based Syst. 91, 263–274 (2016)
066d3dc7a902fccae54723d23c369f21 ; 15. Li, Z., Jing, X., Zhu, X.: Progress on approaches to software defect prediction. IET Softw. 12(3), 161–175 (2018)
e9308e28135a63ae7e655fb3092c9816 ; 17. Lu, H., Cukic, B., Culp, M.V.: An iterative semi-supervised approach to software fault prediction. In: PROMISE, pp. 15:1–15:10 (2011)
076898ed978e65d4c1c1a8744f64fc19 ; 18. Lu, H., Cukic, B., Culp, M.V.: Software defect prediction using semi-supervised learning with dimension reduction. In: ASE, pp. 314–317 (2012)
da938e5fd7d0dcffc02a5864c69c03d3 ; 20. Song, Q., Jia, Z., Shepperd, M.J., Ying, S., Liu, J.: A general software defectproneness prediction framework. IEEE Trans. Softw. Eng. 37(3), 356–370 (2011)
293e960c80ce48ba4fb48631a84784a7 ; 24. Zhang, Z., Jing, X., Wang, T.: Label propagation based semi-supervised learning for software defect prediction. Autom. Softw. Eng. 24(1), 47–69 (2017)
99a7148e8cefa64a89d3473b20dd7f6c ; 25. Zhou, Z., Li, M.: Tri-training: exploiting unlabeled data using three classifiers. IEEE Trans. Knowl. Data Eng. 17(11), 1529–1541 (2005)
9e32fd25e5d0e90eca9b6bfb33e88706 ; 26. Zhou, Z., Li, M.: Semi-supervised learning by disagreement. Knowl. Inf. Syst. 24(3), 415–439 (2010)
cde7d51d312c46f013a4b703a9b86745 ; [1] X. Li, Y. F. Li, M. Xie, and S. H. Ng, “Reliability analysis and optimal version-updating for open source software,” Information and Software Technology, vol. 53, no. 9, pp. 929–936, 2011.
ff987aea7844189814ce09fb7daa7052 ; [2] Y. Tian, J. Tian, and N. Li, “Reliability assessment and prediction with testing efficiency growth for open source software,” in International Conference on Software Engineering and Data Engineering, SEDE 2017, San Diego, CA, October 2-4, 2017. ACM, 2017, pp. 72–83.
274c60cffc3eec077fa5aef579bad835 ; [8] J. Tian, “Reliability measurement, analysis, and improvement for large software systems,” Advances in Computers, vol. 46, pp. 159–235, 1998.
5d68c59ab57eee538d74b2b16ea8e01c ; [9] M. R. Lyu, editor, Handbook of software reliability engineering. McGraw-Hill, New York, 1995.
7bc9d10bd427351df51db82f4c5be376 ; [26] Qinbao Song, Yuchen Guo, and Martin J. Shepperd. 2019. A Comprehensive Investigation of the Role of Imbalanced Learning for Software Defect Prediction. IEEE Transactions on Software Engineering (TSE) 45, 12 (2019), 1253–1269.
2f168e1999f499e2752cc57a5c579bc8 ; [16] M. Borg, O. Svensson, K. Berg, and D. Hansson, “SZZ unleashed: an open implementation of the SZZ algorithm - featuring example usage in a study of just-in-time bug prediction for the jenkins project,” in ACM SIGSOFT International Workshop on Machine Learning Techniques for Software Quality Evaluation, MaLTeSQuE@FSE/ESEC 2019, Tallinn, Estonia, August 27, 2019. ACM, 2019, pp. 7–12.
3e887fdd31bc851520ffd6ef84568ce4 ; [18] Y. Tian, J. Tian, and N. Li, “Cloud reliability and efficiency improvement via failure risk based proactive actions,” Journal of Systems and Software, vol. 163, p. 110524, 2020.
814a1555b868357f34d26f7818049705 ; [19] N. Li, M. Shepperd, and Y. Guo, “A systematic review of unsupervised learning techniques for software defect prediction,” Information and Software Technology, vol. 122, p. 106287, 2020.
1153ac863d4ea1a484f2a2aec43cab3a ; [20] J. Nam and S. Kim, “CLAMI: defect prediction on unlabeled datasets (T),” in IEEE/ACM International Conference on Automated Software Engineering, ASE 2015, Lincoln, NE, USA, November 9-13, 2015, M. B. Cohen, L. Grunske, and M. Whalen, Eds. IEEE Computer Society, 2015, pp. 452–463.
8a3efc0b49292d6cb688dcfeafa21cbb ; [21] J. Yang and H. Qian, “Defect prediction on unlabeled datasets by using unsupervised clustering,” in IEEE International Conference on High Performance Computing and Communications, HPCC 2016, Sydney, Australia, December 12-14, 2016. IEEE, 2016, pp. 465–472.
9ee7038140d80e723d6f387809b0bc00 ; [22] M. Yan, Y. Fang, D. Lo, X. Xia, and X. Zhang, “File-level defect prediction: Unsupervised vs. supervised models,” in ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, ESEM 2017, Toronto, ON, Canada, November 9-10, 2017, A. Bener, B. Turhan, and S. Biffl, Eds. IEEE Computer Society, 2017, pp. 344– 353.
20e96dd696a0b7bb62a2600089e1cecb ; [23] M. Yan, X. Zhang, C. Liu, L. Xu, M. Yang, and D. Yang, “Automated change-prone class prediction on unlabeled dataset using unsupervised method,” Information and Software Technology, vol. 92, pp. 1–16, 2017.
f69b6da81ebf1b35b60195af3da3f47c ; 4. Elish, K.O., Elish, M.O.: Predicting defect-prone software modules using support vector machines. The Journal of Systems and Software 81, 649–660 (2008)
252aafb67abafb8a6e33b578e9bf3809 ; 5. Fenton, N.E., Ohlsson, N.: Quantitative analysis of faults and failures in a complex software system. IEEE Transactions on Software Engineering 26(8), 797–814 (2000)
9ac82dd4623c892fe383ac06c9b3e99d ; 6. Goel, A.L., Okumoto, K.: Time dependent error detection rate model for software reliability and other performance measures. IEEE Transactions on Reliability R-28(3), 206–211 (1979)
23751337ecebf13977f4354cdec4c75d ; 9. Hassan, A.E.: Predicting Faults based on complexity of code change. In: The Proceedings of 31st Intl. Conf. on Software Engineering, pp. 78–88 (2009)
48fd0ccbfc15463e3dcc6e749f5a7db7 ; 10. Hassan, A.E., Holt, R.C.: Studying the chaos in code development. In: Proceedings of 10th Working Conference on Reverse Engineering (November 2003)
eb11b68e924da55487b7e087d92303ff ; 11. Hassan, A.E., Holt, R.C.: The chaos of software development. In: Proceedings of the 6th IEEE International Workshop on Principles of Software Evolution (September 2003)
86cdb2c0a70a0b68e9637f488086cd84 ; [12] Hassan, A. and Holt, R. 2005. The top ten list: dynamic fault prediction. Proceedings of the international conference on software maintenance 263–272.
9d17896bf7618a86e4fa84af486b6434 ; 14. Kapur, P.K., Garg, R.B., Kumar, S.: Contributions to Hardware and Software Reliability. World Scientific Publishing Co. Ltd., Singapore (1999)
8d8cb2644d122f76d6ae1b2cce4119d7 ; 15. Kapur, P.K., Garg, R.B.: A software reliability growth model for an error removal phenomenon. Software Engineering Journal 7, 291–294 (1992)
84ddc4fa80597f3422677b18f956328f ; 17. Khoshgoftaar, T.M., Allen, E.B., Jones, W.D., Hudepohl, J.P.: Data mining for predictors of software quality. International Journal of Software Engineering and Knowledge Engineering 9(5), 547–563 (1999)
04548fa962d1f23e7357678187f4ca6f ; 20. Musa, J.D., Iannino, A., Okumoto, K.: Software Reliability, Measurement, Prediction and Application. McGraw-Hill (1987)
d2cf82211573e7bc10dd502ca2406040 ; [29] Nagappan, N. and Ball, T. 2005. Static analysis tools as early indicators of pre-release defect density. Proceedings of the international conference on software engineering (New York, New York, USA), 580–586.
da9348460c56c0fac85a21f43d0010fa ; 24. Ohba, M.: Inflection S-shaped software reliability growth model. In: Osaki, S., Hotoyama, Y. (eds.) Stochastic Models in Reliability Theory. LNEMS, vol. 235, pp. 144–162. Springer, Heidelberg (1984)
fbfc1dbe341a4a9ea7c2f369d2c164d0 ; 25. Ostrand, T.J., Weyuker, E.J., Bell, R.M.: Predicting the location and number of faults in large complex systems. IEEE Transactions on Software Engineering 31(4), 340–355 (2005)
1905f23491d7b6fbde495f9a0ca22492 ; 26. Shannon, C.E.: A Mathematical Theory of Communication. The Bell System Technical Journal 27, 379–423, 623–656 (1948)
caacf04c74f6039ae318ac6e9e3f2590 ; 27. Singh, V.B.: A Study on Software Reliability Growth Modeling using Change Point and Fault Dependency. University of Delhi (2008)
4eae35f1b35977a00ebd8086c259d4c9 ; 28. The bugZilla project (2012), http://www.bugzilla.org
4eae35f1b35977a00ebd8086c259d4c9 ; 29. The Mozilla project (2012), http://www.mozilla.org
e7d6f3c4c809f71aad223904bb43d7b8 ; 30. Weisberg, S.: Applied Linear Regression. John Wiley and Sons (1980)
2ceb8f97e316c18a357c06657bf10f57 ; 31. Yamada, S., Ohba, M., Osaki, S.: S-shaped software reliability growth modelling for software error detection. IEEE Trans. on Reliability R-32 (5), 475–484 (1983)
b93e31aa4dff3e47baf38e24606c846e ; 32. Vapnik, V.: The Nature of Statistical Learning Theory. Springer, New York (1995)
9238668e20b10311bbe0f11b0b61eb4a ; 33. Xing, F., Guo, P.: Support vector regression for software reliability growth modeling and prediction. In: Wang, J., Liao, X.-F., Yi, Z. (eds.) ISNN 2005. LNCS, vol. 3496, pp. 925–930. Springer, Heidelberg (2005)
427666c3173c4dab1b0a8d0c63cee8c6 ; 34. Singh, V.B., Chaturvedi, K.K.: Entropy based bug prediction using support vector regression. In: Proceedings ISDA 2012 - 12th International Conference on Intelligent System Design and Applications, Kochi, India, November 27-29, pp. 746–751. IEEE Xplore, USA (2012)
7578e82154cdfa3fa6558b73d10a3c7e ; [1] Hoa Khanh Dam, Truyen Tran, and Aditya Ghose. 2018. Explainable Software Analytics. In Proceedings of the International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER). 53–56.
37f4d5dacc6c4ba0e3e29c5ccf0f2a92 ; [3] Jirayus Jiarpakdee, Chakkrit Tantithamthavorn, Hoa Khanh Dam, and John Grundy. 2020. An Empirical Study of Model-Agnostics Techniques for Defect Prediction Models. IEEE Transactions on Software Engineering (TSE) (2020).
2cb7b3ca2b5186b318ca09dc7ead4c87 ; Bettenburg N, Nagappan M, Hassan AE (2012) Think locally, act globally: Improving defect and effort prediction models. In: Proceedings of the 9th IEEE working conference on mining software repositories (MSR), pp 60–69. IEEE Press
e11e50c95be6f18183dd721649173139 ; [9] I. Herraiz, J. Gonz´alez-Barahona, G. Robles, and D. Germ´an, “On the prediction of the evolution of libre software projects,” in ICSM, 2007, pp. 405–414.
1d0052198cfb70c4a2bb7fcb0238c13e ; [20] L. Prechelt and A. Pepper, “Why software repositories are not used for defect-insertion circumstance analysis more often: A case study,” Information and Software Technology, vol. 56, no. 10, pp. 1377–1389, 2014.
33716faa00429932762f8952eefab52b ; [18] L. Pelayo and S. Dick, “Applying novel resampling strategies to software defect prediction,” in NAFIPS ’07, pp. 69–72.
50f9b89687b15d40282773d8847fcbeb ; [20] J. Eyolfson, L. Tan, and P. Lam, “Correlations between bugginess and time-based commit characteristics,” EMSE’14, vol. 19, no. 4, pp. 1009– 1039.
d85215b0d77d202fc364fce594c72223 ; [23] M. F. Porter, “Snowball: A language for stemming algorithms,” 2001. [Online]. Available: http://snowball.tartarus.org/texts/introduction.html
ccf1b198b3b9db71b9fce0d2232201d7 ; [12] Mark Hall, Eibe Frank, Geofrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H Witten. 2009. The WEKA data mining software: an update. ACM SIGKDD Explorations Newsletter 11, 1 (2009), 10ś18.
d3ad84327d0130da23476fd26d403eed ; [21] L. Jiang, G. Misherghi, Z. Su, and S. Glondu, “DECKARD: Scalable and accurate tree-based detection of code clones,” in ICSE, 2007, pp. 96–105.
f0f2f6f1941c09e6d106fa5b2e81988e ; [43] S. Kim and E. J. Whitehead Jr, “How long did it take to fix bugs?” in Proceedings of the 2006 international workshop on Mining software repositories. ACM, 2006, pp. 173–174.
1d68a4fe2daed1b7602df927c23a7d91 ; [19] T.-H. Chen, M. Nagappan, E. Shihab, and A. E. Hassan, “An empirical study of dormant bugs,” in Proceedings of the 11th Working Conference on Mining Software Repositories, pp. 82–91, ACM, 2014.
1c1645b57f7b0bcc6fbbb525b969c309 ; [28] G. H. John and P. Langley, “Estimating continuous distributions in bayesian classifiers,” in UAI. San Mateo: Morgan Kaufmann, 1995, pp. 338–345.
1569e13fa6f6523b01f64028448aea43 ; [32] D. W. Aha, D. Kibler, and M. K. Albert, “Instance-based learning algorithms,” Mach. Learn.(1991), vol. 6, no. 1, pp. 37–66.
835505550ca77cd886af5ae8567cc06d ; [33] J. G. Cleary and L. E. Trigg, “K*: An instance-based learner using an entropic distance measure,” in ICML’95, pp. 108–114.
bffd91d3f5728d306ce95e14db7819da ; [34] J. Friedman, T. Hastie, and R. Tibshirani, “Additive logistic regression: a statistical view of boosting,” pp. 337–407.
8eb4d6a9e30029933d5413237be74625 ; [35] C. G. Atkeson, A. W. Moore, and S. Schaal, “Locally weighted learning,” Artif. Intell. Rev.(1997), vol. 11, no. 1-5, pp. 11–73.
bc6451f5e74f3e7f30d0dd1f5e191df4 ; [36] B. Martin, “Instance-based learning: Nearest neighbor with generalization,” Master’s thesis, University of Waikato, 1995.
83883457a0b923939e11337f5c6685d8 ; [37] S. Shalev-Shwartz, Y. Singer, and N. Srebro, “Pegasos: Primal estimated sub-gradient solver for svm,” in ICML ’07, pp. 807–814.
2dac740dd24a30dc8b69695cc167bd63 ; [13] Y. Freund and L. Mason, “The alternating decision tree learning algorithm,” in ICML, 1999, pp. 124–133.
23751663624b6a7a218d438f8616c6bc ; [41] G. C¸ alikli and A. Bener, “Influence of confirmation biases of developers on software quality: an empirical study,” Software Quality Journal (2013), vol. 21, no. 2, pp. 377–416.
e5752c43fdd305bbfa12aa6d2d07e0e9 ; [42] T. J. Ostrand and E. J. Weyuker, “An industrial research program in software fault prediction,” in SE’07, pp. 21–28.
ba70a1d575648dfd9a655638aef07e04 ; [44] R. M. Bell, E. J. Weyuker, and T. J. Ostrand, “Assessing the impact of using fault prediction in industry,” in ICSTW’11, pp. 561–565.
4c43bac83c0f09ef6294114f4d600197 ; [45] N. Littlestone, “Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm,” Mach. Learn.(1988), vol. 2, no. 4, pp. 285–318.
86834753e034914ecc204a46927eb783 ; [46] Z. Sun, Q. Song, and X. Zhu, “Using coding-based ensemble learning to improve software defect prediction,” SMC’12, vol. 42, no. 6, pp. 1806– 1817.
e4433d9c2db5801ec4a4a471312a2adb ; [47] J. Wang, B. Shen, and Y. Chen, “Compressed c4.5 models for software defect prediction,” in QSIC’12, pp. 13–16.
94afdcef596a5f9ed93529845d7cb77e ; [48] J. Zheng, “Cost-sensitive boosting neural networks for software defect prediction,” Expert Systems with Applications (2000), vol. 37, no. 6, pp. 4537–4543.
dac39218a573e0f631761709b381db25 ; [19] Xiao-Yuan Jing, Shi Ying, Zhi-Wu Zhang, Shan-Shan Wu, and Jin Liu. 2014. Dictionary learning based software defect prediction. In Proceedings of the 36th International Conference on Software Engineering. ACM, 414ś423.
20d68e7ac0f6f465e2081d4c9de60e15 ; [50] R. Vivanco, Y. Kamei, A. Monden, K. Matsumoto, and D. Jin, “Using search-based metric selection and oversampling to predict fault prone modules,” in CCECE’10, pp. 1–6.
e8f7a49dd840fcdec52bd303725a9f0b ; [51] N. Chawla, A. Lazarevic, L. Hall, and K. Bowyer, “SMOTEBoost: Improving prediction of the minority class in boosting,” in PKDD’03, vol. 2838, pp. 107–119.
3ea4c72c296bbac746cad658d758c5fb ; [52] S. Wang, H. Chen, and X. Yao, “Negative correlation learning for classification ensembles,” in IJCNN’10, pp. 1–8.
3fb89c703e59c0e51fcb855d2996b2bc ; [9] D. Gray, D. Bowes, N. Davey, Y. Sun, and B. Christianson, “The misuse of the nasa metrics data program data sets for automated software defect prediction,” in Proceedings of the 15th Annual Conference on Evaluation & Assessment in Software Engineering (EASE 2011), pp. 96–103, 2011.
4a2a4f68b889395b3e44739ffbf9e5d6 ; [10] A. Mockus, D. Weiss, and P. Zhang, “Understanding and predicting effort in software projects,” in ICSE, 2003.
f09a0d3d69dea4f20f1742b9a586f132 ; [12] Google Official Blog, “Personalized search for everyone,” http://googleblog.blogspot.ca/2009/12/personalized-search-for-everyone .html, 2009.
6a40d1eccf93f3ac1bf7b3527a86c58a ; [14] J. H. Friedman, “Multivariate adaptive regression splines,” The Annals of Statistics, vol. 19, no. 1, pp. 1–67, 1991.
5ceea5fb905c27b9683908580ce33c49 ; [22] B. Raskutti, H. Ferra, and A. Kowalczyk, “Second-order features for maximizing text classification performance,” ECML, pp. 419–430, 2001.
3b9787927ecbf1b5a270ce1ff8566872 ; [24] “Snowball,” http://snowball.tartarus.org/.
b456c397e99d104a78821280b629322d ; [25] Z. Li, L. Tan, X. Wang, S. Lu, Y. Zhou, and C. Zhai, “Have things changed now? An empirical study of bug characteristics in modern open source software,” in ASID, October 2006.
f9f9afa84795c33918567df6f2261adf ; [26] G. Bougie, C. Treude, D. Germ´an, and M. Storey, “A comparative exploration of FreeBSD bug lifetimes,” in MSR, 2010, pp. 106–109.
3dc8191147d3cab4be4e041946005e60 ; [29] N. Landwehr, M. Hall, and E. Frank, “Logistic model trees,” vol. 95, no. 1-2, pp. 161–205, 2005.
e4b9cb2ff83636f9988809dd19c79936 ; [30] T. Curk, J. Demar, Q. Xu, G. Leban, U. Petrovi, I. Bratko, G. Shaulsky, and B. Zupan, “Microarray data mining with visual programming,” Bioinformatics, vol. 21, pp. 396–398, Feb. 2005.
1acfaecd5fa33df4adf349448f038e0e ; [31] D. Engler, D. Y. Chen, S. Hallem, A. Chou, and B. Chelf, “Bugs as deviant behavior: A general approach to inferring errors in systems code,” in SOSP, 2001, pp. 57–72.
7a9e7deaa1122144de4b3c832196a340 ; [32] A. Chou, J. Yang, B. Chelf, S. Hallem, and D. Engler, “An empirical study of operating systems errors,” in SOSP, 2001, pp. 73–88.
7e147d8625915f74e0aff951873f2dfa ; [42] PostgreSQL Community, “Committing with Git – PostgreSQL Wiki,” http://wiki.postgresql.org/wiki/Committing with Git, 2012.
0640b0e625604d0291b1a3fb61a732a4 ; [43] J. Anvik, L. Hiew, and G. C. Murphy, “Who should fix this bug?” in ICSE, 2006, pp. 361–370.
0201c3eacfd3528b1fec07219a66d3e3 ; [44] D. Matter, A. Kuhn, and O. Nierstrasz, “Assigning bug reports using a vocabulary-based expertise model of developers,” in MSR, 2009, pp. 131–140.
a63d660693fbc494c2c353ce0bd83cb2 ; [45] J. Park, M. Lee, J. Kim, S. Hwang, and S. Kim, “CosTriage: A costaware triage algorithm for bug reporting systems,” in AAAI, 2011.
51745064f4410c5c3db5b33d950967ee ; [46] G. Jeong, S. Kim, and T. Zimmermann, “Improving bug triage with bug tossing graphs,” in FSE, 2009, pp. 111–120.
9e37f0d50c2e01d1a0baebd3924e655c ; [47] M. Lumpe, R. Vasa, T. Menzies, R. Rush, and B. Turhan, “Learning better inspection optimization policies,” IJSEKE, vol. 22, no. 5, pp. 621– 644, 2012.
0b9f59275803f39c76685f9501c4acda ; [63] S. Shivaji, E. J. Whitehead, R. Akella, and S. Kim. Reducing features to improve code change-based bug prediction. IEEE Transactions on Software Engineering, 39(4):552–569, 2013.
95b2ff639787ce2193dbbf7a00d7f8c8 ; [49] C. Tucker, “Social Networks, Personalized Advertising, and Privacy Controls,” in WEIS, 2011.
74bfae795a87555e80f8390dc0252940 ; [65] F. Rahman and P. Devanbu, “Ownership, experience and defects: a fine-grained study of authorship,” in Proceedings of the 33rd International Conference on Software Engineering. ACM, 2011, pp. 491–500.
5a80167c139f606f2678f9850b2273bb ; [52] D. Posnett, R. DSouza, P. Devanbu, and V. Filkov, “Dual ecological measures of focus in software development,” in ICSE, 2013.
7fc5ad475dce55afc3741b99b7b475e9 ; [54] K. Muslu, Y. Brun, R. Holmes, M. D. Ernst, and D. Notkin, “Improving ide recommendations by considering global implications of existing recommendations,” in ICSE, 2012, pp. 1349–1352.
3c31ce6054cd0b9c52146b87b749c555 ; [55] Y. Ye and G. Fischer, “Supporting reuse by delivering task-relevant and personalized information,” in ICSE, 2002, pp. 513–523.
d580e483f775708faa0e6f533356f779 ; [56] D. Kim, X. Wang, S. Kim, A. Zeller, S. Cheung, and S. Park, “Which crashes should i fix first?: Predicting top crashes at an early stage to prioritize debugging efforts,” TSE, vol. 37, no. 3, pp. 430–447, 2011.
b435527c8236b84f4af481c8ed72ac9e ; [57] S. S. Kolesnikov, S. Apel, N. Siegmund, S. Sobernig, C. K¨astner, and S. Senkaya, “Predicting quality attributes of software product lines using software and network measures and sampling,” in VaMoS, 2013, p. 6.
197c0d94a935f20c55673a930372b131 ; [25] Y. Shin and L. Williams, “Can traditional fault prediction models be used for vulnerability prediction?” Empirical Software Engineering, vol. 18, no. 1, pp. 25–59, 2013.
6516c08510cfce3e423e8fc8139a0c9d ; 1. K. E. Martersteck and A. E. Spencer, Jr., " The 5ESS™ Switching System: Introduction," AT&T Tech. J., Vol. 64, No. 6, Part 2, July-Aug. 1985, pp.1305-1314.
867f15b9f4adfae8e493dcecdec24969 ; 2. K. H. An, D. A. Gustafson, and A. C. Melton, "A model for software maintenance, " Proc. of the Conf. on Soft. Maintenance, Austin, Texas, Sept. 21-24, 1987, IEEE Comp. Soc. Press, pp.57-62.
22caaaffcd6ace3591a6233ad264aee4 ; 3. V. R. Basili and B. T. Perricone, "Software Errors and Complexity: An Empirical Investigation," Commun. of the ACM, Vol. 27, No. 1, Jan. 1984, pp. 42-52.
2f4ddbe954e77df819cb0826b7374204 ; 4. L. Hatton, "Reexamining the Fault Density-Component Size Connection," IEEE Soft., Vol. 14, No. 2, Mar./Apr. 1997, pp. 89-97.
5ddd3663fbccced703bd928881e8ef73 ; 5. T. J. McCabe, "Complexity Measure," IEEE Trans. on Soft. Eng., Vol. SE-2, No. 4, July 1976, pp. 308-320.
23203c3675373f123b689205a17b00aa ; [14] Maurice Howard Halstead. 1977. Elements of software science. Vol. 7. Elsevier New York.
1946fb515c19908f51c1e3b80e7aed61 ; 7. N. F. Schneidewind and H.-M. Hoffman, "An Experiment in Software Error Data Collection and Analysis," IEEE Trans. on Soft. Eng., Vol. SE-5, No. 3, May 1979, pp. 276-286.
234a39b842f7a97e66b14efb94966e81 ; 9. V. Y. Shen, T.-J. Yu, S. M. Thebaut, and L. R. Paulsen, "Identifying Error-Prone Soft-ware—An Empirical Study," IEEE Trans. on Soft. Eng., Vol. SE-11, No. 4, Apr. 1985, pp. 317-325.
26d068f0d3f689dd205a3a099ddb240f ; 10. J. C. Munson and T. M. Khoshgoftaar, "Regression modeling of software quality: Empirical investigation," Information and Soft. Tech., Vol. 32, No. 2, Feb. 1990, pp. 106-114.
17eb41a21e1a1d4d215b9e14e101dbab ; 11. T.-J. Yu, V. Y. Shen, and H. E. Dunsmore, "An Analysis of Several Software Defect Models," IEEE Trans. on Soft. Eng., Vol. 14, No. 9, Sept. 1988, pp. 1261-1270.
78bf65e31a041784b20993fd75e047d8 ; 13. J. D. Musa, A. Iannino, and K. Okumoto, Software Reliability: Measurement, Prediction, and Application, McGraw-Hill, New York, 1990.
c084cba2b5d54f22e05066e93b22f3e5 ; 14. J. Jelinski and P. B. Moranda, "Software relia-bility research," Probabilistic Models for Software, edited by W. Freiberger, Academic Press, New York, 1972, pp. 485-502.
5e83d1030631d1afec60d3f7d7183a5f ; 15. G. J. Schick and R. W. Wolverton, "An Analysis of Competing Software Reliability Models," IEEE Trans. on Soft. Eng., Vol. SE-4, No. 2, Mar. 1978, pp. 104-120.
f1511c4f28fe9899bc739904a1581e33 ; 16. S. N. Mohanty, "Models and Measurements for Quality Assessment of Software," ACM Computing Surveys, Vol. 11, No. 3, Sept. 1979, pp. 257-275.
f3b90f9c06ed500623265a72431650cd ; 17. S. G. Eick, C. R. Loader, M. D. Long, L. G. Votta, and S. Vander Wiel, "Estimating software fault content before coding," Proc. of the 14th Intl. Conf. on Soft. Eng., Melbourne, Australia, May 11-15, 1992, pp.59-65.
481378ab373c495e68e2605dddd42656 ; 18. D. A. Christenson and S. T. Huang, "Estimating the Fault Content of Software Using the Fix-on-Fix Model," Bell Labs Tech. J, Vol. 1, No. 1, Summer 1996, pp. 130-137.
99706684b7d189ab0373d0088e42890e ; 19. A. L. Goel, "Software Reliability Models: Assumptions, Limitations, and Applicability," IEEE Trans. on Soft. Eng., Vol. SE-11, No. 12, Dec. 1985, pp. 1411-1423.
b46fbc8a02fb9da6e17f6a6b5ee67fea ; 20. P. B. Moranda, "Software quality technology," IEEE Comp., Vol. 11, No. 11, Nov. 1978, pp.72-78.
4fdff64cafb64ede3a7751f467bc7586 ; 21. A. K. Midha, "Software Configuration Manage-ment for the 21st Century," Bell Labs Tech. J., Vol. 2, No. 1, Winter 1997, pp. 154-165.
95d3a775a705deda05e5516c9f747654 ; 22. M. J. Rochkind, "The Source Code Control System," IEEE Trans. on Soft. Eng., Vol. SE-1, No. 4, Dec. 1975, pp. 364-370.
21be0634f3ca27bb394b1010eecaee8f ; 24. A. J. Albrecht and J. E. Gaffney, Jr., "Soft-ware Function, Source Lines of Code, and Development Effort Prediction: A Software Science Validation," IEEE Trans. on Soft. Eng., Vol. SE-9, No. 6, Nov. 1983, pp. 639-648.
ec714722063278ad3df27e507ced5b36 ; 26. V. R. Basili and D. M. Weiss, "Evaluating Soft-ware Development by Analysis of Changes, " IEEE Trans. on Soft. Eng., Vol. SE-11, No. 2, Feb. 1985, pp. 157-168.
47e6c1520e509ec42cfcf4c5faf2dd87 ; 27. A. Mockus, S. G. Eick, T. L. Graves, and A. F. Karr, "On Measurement and Analysis of Software Changes," Doc. No. ITD-99-36760F, BL0113590-990401-06TM, Lucent Techno-logies, Murray Hill, N. J., Apr. 1999.
b72fae8a8601bc7d7a1d7a30894aa464 ; 28. P. McCullagh and J. A. Nelder, Generalized Linear Models, 2nd ed., Chapman and Hall, New York, 1989.
b972e58b43af4730e439efaa6f14cb79 ; 29. J. M. Chambers and T. J. Hastie, eds., Statistical Models in S, Wadsworth & Brooks, Pacific Grove, Calif., 1992.
6944a33daa735b038a01d731edc1670b ; 30. A. J. Miller, Subset Selection in Regression, Chapman and Hall, London, 1990.
16190dd66966d594eadc304d72b7840c ; 32. S. G. Eick, T. L. Graves, A. F. Karr, J. S. Marron, and A. Mockus, "Does Code Decay? Assessing the Evidence from Change Management Data," IEEE Trans. on Soft. Eng. (forthcoming 2000).
2681c42aa9d6b535c3f980ab9a96c79d ; Mockus A, Votta LG (2000) Identifying reasons for software changes using historic databases. In: Proceedings of the 22th international conference on software maintenance (ICSE), pp 120–130. IEEE
b4964a178232b449c752efafe16479f3 ; 34. D. Atkins, T. Ball, T. Graves, and A. Mockus, "Using version control data to evaluate the impact of software tools," Proc. 21st Intl. Conf. on Soft. Eng., Los Angeles, Calif., May 16-22, 1999, ACM Press, pp. 324-333.
aaa177fcab822db09cad934e564c6a43 ; 35. H. Siy and A. Mockus, "Measuring domain engineering effects on software change cost," Metrics '99: Sixth Intl. Symp. on Soft. Metrics, Boca Raton, Fla., Nov. 4-6, 1999, pp. 304-311.
aa246e7c5604653c6abc0ded23ecc909 ; [47] H. Abdi, “Bonferroni and ˇsid´ak corrections for multiple comparisons,” Encyclopedia of measurement and statistics, vol. 3, pp. 103–107, 2007.
3914e2defcd73a135f3f790118d7a6f3 ; Agrawal A, Menzies T (2018) Is ”better data” better than ”better dataminers”? on the benefits of tuning smote for defect prediction. In: Proceedings of the 40th International Conference on Software Engineering, ser. ICSE ’18. Association for Computing Machinery, New York, , pp 1050–1061. [Online]. Available: https://doi.org/10.1145/3180155.3180197
d75214dff9e6bc1986ce9f71efbb7297 ; [15] Maggie Hamill and Katerina Goseva-Popstojanova. 2009. Common trends in software fault and failure data. IEEE Transactions on Software Engineering 35, 4 (2009), 484ś496.
b47a5ba5b819eb39fde6b0a53d127b9c ; [44] J. Han, J. Pei, and M. Kamber, Data mining: concepts and techniques. Elsevier, 2011.
0b6959a7498631213d70335f5d15b6fd ; [49] J. L. Hintze and R. D. Nelson, “Violin plots: a box plot-density trace synergism,” The American Statistician, vol. 52, no. 2, pp. 181–184, 1998.
f7685351e6d4347a0be9daf0f5be5c45 ; Huang Q, Shihab E, Xia X, Lo D, Li S (2018) Identifying self-admitted technical debt in open source projects using text mining. Empir Softw Eng 23(1):418–451
f4bfb2d6c43c60344b12e9a0bf7b40ed ; [17] P. S. Kochhar, X. Xia, D. Lo, and S. Li, “Practitioners’ expectations on automated fault localization,” in Proceedings of the 25th International Symposium on Software Testing and Analysis. ACM, 2016, pp. 165– 176.
eff0668fdf2d381bd09bae9d228a9ccc ; [26] T. Menzies and J. S. Di Stefano, “How good is your blind spot sampling policy,” in High Assurance Systems Engineering, 2004. Proceedings. Eighth IEEE International Symposium on. IEEE, 2004, pp. 129–138.
5eaae4cdd6c05ee8ed6a10f2aa1f6f0f ; Nagappan N, Ball T, Murphy B (2006a) Using historical in-process and product metrics for early estimation of software failures. In: 17th International symposium on software reliability engineering, 2006.  ISSRE’06. IEEE, pp 62–74
cdda2e9388f629336a9b7cf1c388acd9 ; [56] E. C. Neto, D. A. da Costa, and U. Kulesza. The impact of refactoring changes on the szz algorithm: An empirical study. In Proceedings of the 25th IEEE International Conference on Software Analysis, Evolution and Reengineering, pages 380–390. IEEE, 2018.
52755635241b5c22c6fb39f5deef80e6 ; [31] T. J. Ostrand, E. J. Weyuker, and R. M. Bell, “Where the bugs are,” in ACM SIGSOFT Software Engineering Notes, vol. 29, no. 4. ACM, 2004, pp. 86–96.
55a38697365f358bf14fd41a9aa61de7 ; [20] E. Shihab, A. Ihara, Y. Kamei, W. M. Ibrahim, M. Ohira, B. Adams, A. E. Hassan, and K.-i. Matsumoto, “Studying re-opened bugs in open source software,” Empirical Software Engineering, vol. 18, no. 5, pp. 1005–1042, 2013.
0035e1bb9c11102593cafe5e579f6460 ; Thongmak M, Muenchaisri P (2003) Predicting faulty classes using design metrics with discriminant analysis. In: Software engineering research and practice, pp 621–627
da6dd1a3148691ead87952bd16024f96 ; [21] H. Valdivia Garcia and E. Shihab, “Characterizing and predicting blocking bugs in open source projects,” in Proceedings of the 11th working conference on mining software repositories. ACM, 2014, pp. 72–81.
cba064839fe2fb0cbc810c0be4afc2fe ; [45] X. Xia, L. Bao, D. Lo, and S. Li, “automated debugging considered harmful considered harmful: A user study revisiting the usefulness of spectra-based fault localization techniques with professionals using real bugs from large systems,” in Software Maintenance and Evolution (ICSME), 2016 IEEE International Conference on. IEEE, 2016, pp. 267–278.
ab74a0c97eecf09e8a8b97249353edaa ; [42] X. Xia, D. Lo, X. Wang, and X. Yang, “Collective personalized change classification with multiobjective search,” IEEE Transactions on Reliability, vol. 65, no. 4, pp. 1810–1829, 2016.
793ef2ade6deca12865a91a72e830330 ; [3] F. Xing, P. Guo, and M. R. Lyu, “A novel method for early software quality prediction based on support vector machine,” in Proceedings of the 16th IEEE International Symposium on Software Reliability Engineering, 2005. ISSRE 2005. IEEE, 2005, pp. 10–pp.
bb03f012668f5758ad18ce5cac917d48 ; [4] T. M. Khoshgoftaar and N. Seliya, “Comparative assessment of software quality classification techniques: An empirical case study,” Empirical Software Engineering, vol. 9, no. 3, pp. 229–257, 2004.
d6225559aa77873ed7af207b12e89338 ; [9] J. Nam, “Survey on software defect prediction,” Department of Compter Science and Engineerning, The Hong Kong University of Science and Technology, Tech. Rep, 2014.
40bffa42be26420e6776bb3d0d2bc3f2 ; [9] N. Fenton and M. Neil. 1999. A Critique of Software Defect Prediction Models. Transactions on Software Engineering 25, 5 (1999), 675–689. https://doi.org/10. 1109/32.815326
06aca2e2b2f1ecad21b668567eaff612 ; [12] S. Amasaki, “On applicability of cross-project defect prediction method for multi-versions projects,” in Proceedings of the 13th International Conference on Predictive Models and Data Analytics in Software Engineering. ACM, 2017, pp. 93–96.
878d22d4128efb2a28c2d65de7e56ecd ; [13] L. L. Minku and X. Yao, “Can cross-company data improve performance in software effort estimation?” in Proceedings of the 8th International Conference on Predictive Models in Software Engineering. ACM, 2012, pp. 69–78.
9b2599eb0acf7c207c77bbedaf401158 ; [14] M. A. Kabir, J. W. Keung, K. E. Benniny, and M. Zhang, “Assessing the significant impact of concept drift in software defect prediction,” in Proceedings of the IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC), vol. 1. IEEE, 2019, pp. 53– 58.
f5d0c4d0f7b98bfbe318e5e993fb4414 ; [16] K. E. Bennin, J. W. Keung, and A. Monden, “On the relative value of data resampling approaches for software defect prediction,” Empirical Software Engineering, vol. 24, no. 2, pp. 602–636, 2019.
c463477ad7b885b65fe5408eb18851b7 ; [17] T. M. Khoshgoftaar, L. A. Bullard, and K. Gao, “Attribute selection using rough sets in software quality classification,” International Journal of Reliability, Quality and Safety Engineering, vol. 16, no. 01, pp. 73–89, 2009.
ba00367464a58c1351b36306c1c54ff1 ; [20] T. Chen and C. Guestrin, “Xgboost: A scalable tree boosting system,” in Proceedings of the 22nd ACM sigkdd international conference on knowledge discovery and data mining. ACM, 2016, pp. 785–794.
85c392d41380c1ad10d59c58bf465f1e ; [21] T. Chen, T. He, M. Benesty, V. Khotilovich, and Y. Tang, “Xgboost: extreme gradient boosting,” R package version 0.4-2, pp. 1–4, 2015.
70e156f789760b2d6a26e153bd63a770 ; [22] D. Nielsen, “Tree boosting with xgboost-why does xgboost win” every” machine learning competition?” Master’s thesis, NTNU, 2016.
e64c8c0fd1d9e1ef99e9f3ce8eae0a6b ; [1] Amritanshu Agrawal and Tim Menzies. 2017. "Better Data" is Better than "Better Data Miners" (Beneits of Tuning SMOTE for Defect Prediction). CoRR abs/1705.03697 (2017). http://arxiv.org/abs/1705.03697
4037bd9873c58f0ce92f5fdf182e9746 ; [2] Fumio Akiyama. 1971. An example of software system debugging. In IFIP Congress (1), Vol. 71. 353ś359.
61d9c9c19e377a32a6f9d86c0eb5752c ; [7] Wei Fu, Tim Menzies, and Xipeng Shen. 2016. Tuning for software analytics: Is it really necessary? Information and Software Technology 76 (2016), 135ś146.
a6edd699482f357e99b57beafdbf7150 ; [8] Wei Fu, Vivek Nair, and Tim Menzies. 2016. Why is diferential evolution better than grid search for tuning defect predictors? arXiv preprint arXiv:1609.02613 (2016).
98fbe6e90d3e62f6a668f1a9331c5a05 ; [11] Philip J Guo, Thomas Zimmermann, Nachiappan Nagappan, and Brendan Murphy. 2010. Characterizing and predicting which bugs get ixed: an empirical study of Microsoft Windows. In Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 1, Vol. 1. ACM, 495ś504.
df586398a52e24fb1ded5a9f319eb740 ; [17] Qiao Huang, Xin Xia, and David Lo. 2017. Supervised vs unsupervised models: a holistic look at efort-aware just-in-time defect prediction. In 2017 IEEE International Conference on Software Maintenance and Evolution. IEEE.
5e51fd2ddaf75c1a3bbcc7269a6070e4 ; [20] Dennis Kafura and Geereddy R. Reddy. 1987. The use of software complexity metrics in software maintenance. IEEE Transactions on Software Engineering 3 (1987), 335ś343.
d1ddd65ca955ebe249b82d49e9ed4096 ; [22] Taghi M Khoshgoftaar and Edward B Allen. 2001. Modeling software quality with. Recent Advances in Reliability and Quality Engineering 2 (2001), 247.
ad68216c588b60f6014bc2b0b7e2d149 ; [23] Taghi M Khoshgoftaar and Naeem Seliya. 2003. Software quality classiication modeling using the SPRINT decision tree algorithm. International Journal on Artiicial Intelligence Tools 12, 03 (2003), 207ś225.
6db4345b98c030aa704b1e28fc026565 ; [24] Taghi M Khoshgoftaar, Xiaojing Yuan, and Edward B Allen. 2000. Balancing misclassiication rates in classiication-tree models of software quality. Empirical Software Engineering 5, 4 (2000), 313ś330.
3cf1abe21b824118f034008018f96499 ; [25] Sunghun Kim, E James Whitehead Jr, and Yi Zhang. 2008. Classifying software changes: Clean or buggy? IEEE Transactions on Software Engineering 34, 2 (2008), 181ś196.
aa9f1953b19f81f484697aac937333a9 ; [27] Ekrem Kocaguneli, Tim Menzies, Ayse Bener, and Jacky W Keung. 2012. Exploiting the essential assumptions of analogy-based efort estimation. IEEE Transactions on Software Engineering 38, 2 (2012), 425ś438.
1db0402181b54a897d072c88ef536d85 ; [29] Taek Lee, Jaechang Nam, DongGyun Han, Sunghun Kim, and Hoh Peter In. 2011. Micro interaction metrics for defect prediction. In Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering. ACM, 311ś321.
107b155636e15c8789d9785c7e3e58cc ; [30] Stefan Lessmann, Bart Baesens, Christophe Mues, and Swantje Pietsch. 2008. Benchmarking classiication models for software defect prediction: A proposed framework and novel indings. IEEE Transactions on Software Engineering 34, 4 (2008), 485ś496.
14bd24dfa9c1111cdcdac95ff6af2f31 ; [31] Jinping Liu, Yuming Zhou, Yibiao Yang, Hongmin Lu, and Baowen Xu. 2017. Code churn: A neglected metric in efort-aware Just-In-Time defect prediction. In Empirical Software Engineering and Measurement, 2017 ACM/IEEE International Symposium on. IEEE.
7aca4f1ac6a0af61ed20d4f7f0057d5a ; [34] Thilo Mende and Rainer Koschke. 2010. Efort-aware defect prediction models. In 2010 14th European Conference on Software Maintenance and Reengineering. IEEE, 107ś116.
9fbf93822ff9d05030376461f5fe09b3 ; [37] Ayse Tosun Misirli, Ayse Bener, and Resat Kale. 2011. Ai-based software defect predictors: Applications and beneits in a case study. AI Magazine 32, 2 (2011), 57ś68.
493b7337c6595e118468b7266916ddc9 ; [39] Akito Monden, Takuma Hayashi, Shoji Shinoda, Kumiko Shirai, Junichi Yoshida, Mike Barker, and Kenichi Matsumoto. 2013. Assessing the cost efectiveness of fault prediction in acceptance testing. IEEE Transactions on Software Engineering 39, 10 (2013), 1345ś1357.
fee35813c9e7fe4c84fd6053f074bffa ; [40] Raimund Moser, Witold Pedrycz, and Giancarlo Succi. 2008. A comparative analysis of the eiciency of change metrics and static code attributes for defect prediction. In Proceedings of the 30th International Conference on Software Engineering. ACM, 181ś190.
17b33925877e32dd212ef1aa772bd5a0 ; [41] Nachiappan Nagappan and Thomas Ball. 2005. to predict system defect density. In Proceedings of the 27th International Conference on Software Engineering. IEEE, 284ś292.
dae3853f7809b0fc20199898455ecda2 ; [46] Corina S Pasareanu, Peter C Mehlitz, David H Bushnell, Karen Gundy-Burlet, Michael Lowry, Suzette Person, and Mark Pape. 2008. Combining unit-level symbolic execution and system-level concrete execution for testing NASA software. In Proceedings of the 2008 International Symposium on Software Testing and Analysis. ACM, 15ś26.
be6023a6dccadfcf5394a0994d0767df ; [47] Foyzur Rahman, Sameer Khatri, Earl T Barr, and Premkumar Devanbu. 2014. Comparing static bug inders and statistical prediction. In Proceedings of the 36th International Conference on Software Engineering. ACM, 424ś434.
8aa5cb86f8c860636e11119d2851e8b3 ; [48] Jeanine Romano, Jefrey D Kromrey, Jesse Coraggio, Jef Skowronek, and Linda Devine. 2006. Exploring methods for evaluating group diferences on the NSSE and other surveys: Are the t-test and CohenâĂŹsd indices the most appropriate choices. In Annual Meeting of the Southern Association for Institutional Research.
48394bd10f457bc29f92a49f5a3773a8 ; [49] Forrest Shull, Ioana Rus, and Victor Basili. 2001. Improving software inspections by using reading techniques. In Proceedings of the 23rd International Conference on Software Engineering. IEEE, 726ś727.
52499e86ad4ee3c2052b7d7bcd4ca619 ; [52] Maurice V Wilkes. 1985. Memoirs ofa Computer Pioneer. Cambridge, Mass., London (1985).
22bcf7d434b6f484f2cef72a446dbaa1 ; [53] David H Wolpert. 2002. The supervised learning no-free-lunch theorems. In Soft Computing and Industry. Springer, 25ś42.
666d9b8a712e2dcc9722986127a28621 ; [54] Yibiao Yang, Yuming Zhou, Jinping Liu, Yangyang Zhao, Hongmin Lu, Lei Xu, Baowen Xu, and Hareton Leung. 2016. Efort-aware just-in-time defect prediction: simple unsupervised models could be better than supervised models. In Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering. ACM, 157ś168.
ee112269b16bb752059a1adf62d60e54 ; [55] Zuoning Yin, Ding Yuan, Yuanyuan Zhou, Shankar Pasupathy, and Lakshmi Bairavasundaram. 2011. How do ixes become bugs?. In Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering. ACM, 26ś36.
5787083cf0151f82aac79800098d5a33 ; [1] L.Wang, X. Sun, J.Wang, Y. Duan, and B. Li, “Construct bug knowledge graph for bug resolution,” in Proc. IEEE/ACM 39th Int. Conf. Softw. Eng. Companion, 2017, pp. 189–191.
a6ec3c1484bb8d3af119d3bfed5b7491 ; [4] X. Kong, L. Zhang, W. E. Wong, and B. Li, “Experience report: How do techniques, programs, and tests impact automated program repair?,” in Proc. 26th Int. Symp. Softw. Rel. Eng., 2015, pp. 194–204.
cdc086573d4223cb56e80b2f330ce66a ; [18] Stuart McIlroy, Nasir Ali, and Ahmed E Hassan. 2016. Fresh apps: an empirical study of frequently-updated mobile apps in the Google play store. Empirical Software Engineering (EMSE) 21, 3 (2016), 1346–1370.
0b294c7d4f723f45d405417b9701d649 ; [6] M. Nayebi, B. Adams, and G. Ruhe, “Release practices for mobile appswhat do users and developers think?,” in Proc. 23rd Int. Conf. Softw. Anal., Evol., Reengineering, vol. 1, 2016, pp. 552–562.
cc628432043834a9d480d8a40ca11fde ; [8] M. Jureczko and D. Spinellis, “Using object-oriented design metrics to predict software defects,” Models and Methods of System Dependability. Wrocław, Poland: Oficyna Wydawnicza Politechniki Wrocławskiej, pp. 69–81, 2010.
29044533948fbe54eca795b9b20ef429 ; [31] Zhou Xu, Shuai Li, Jun Xu, Jin Liu, Xiapu Luo, Yifeng Zhang, Tao Zhang, Jacky Keung, and Yutian Tang. 2019. LDFR: Learning deep feature representation for software defect prediction. Journal of Systems and Software (JSS) 158 (2019), 110402.
0495eb27756f7bca00b048042cb63fca ; [47] Meng Yan, Xin Xia, Yuanrui Fan, Ahmed E Hassan, David Lo, and Shanping Li. 2020. Just-In-Time Defect Identification and Localization: A Two-Phase Framework. IEEE Transactions on Software Engineering (2020).
9127c2d4b27b58ab6f472da0150c011d ; [48] Meng Yan, Xin Xia, Yuanrui Fan, David Lo, Ahmed E Hassan, and Xindong Zhang. 2020. Effort-aware just-in-time defect identification in practice: a case study at Alibaba. In Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 1308ś1319. https://doi.org/10.1145/3368089.3417048
8dbcfb8f0fdb887bd3c4db69a8de22c6 ; [16] Z. Zhou and J. Feng, “Deep forest: Towards an alternative to deep neural networks,” in Proc. 26th Int. Joint Conf. Artif. Intell., 2017, pp. 3553–3559.
a51145db4c7f60292380b9983a78fbdb ; [3] M. Kondo, D. M. German, O. Mizuno, and E.-H. Choi, “The impact of context metrics on just-in-time defect prediction,” Empirical Software Engineering, vol. 25, no. 1, pp. 890–939, 2020.
dc5a0accbe98637f9ec514bb8a9cbf6d ; [24] T. Zhou, X. Sun, X. Xia, B. Li, and X. Chen, “Improving defect prediction with deep forest,” Inf. Softw. Technol., vol. 114, pp. 204–216, 2019.
eb9c151650464d81f4b52b67a32636a5 ; [25] W. Zheng, S. Mo, X. Jin, Y. Qu, Z. Xie, and J. Shuai, “Software defect prediction model based on improved deep forest and autoencoder by forest,” in Proc. 31st Int. Conf. Softw. Eng. Knowl. Eng., 2019, pp. 419–540.
7f28dec80384fa5a3e36f232e5ebae43 ; [27] X. Jing, F.Wu, X. Dong, F. Qi, and B. Xu, “Heterogeneous cross-company defect prediction by unified metric representation and CCA-based transfer learning,” in Proc. 10th Joint Meeting Found. Softw. Eng., 2015, pp. 496– 507.
cade8b577421383f5d84d8cfc2f8b8b9 ; Zhang F, Zheng Q, Zou Y, Hassan AE (2016) Cross-project defect prediction using a connectivity-based unsupervised classifier. In: Proceedings of the 38th international conference on software engineering (ICSE), pp 309–320. ACM
2ecbb6cc66c0970a9124d75b9bbf73cb ; [33] Z. Li, X.-Y. Jing, F. Wu, X. Zhu, B. Xu, and S. Ying, “Cost-sensitive transfer kernel canonical correlation analysis for heterogeneous defect prediction,” Automated Softw. Eng., vol. 25, no. 2, pp. 201–245, 2018.
d47537300df9d2fada1613d891ddda40 ; [41] Z. Xu, J. Xuan, J. Liu, and X. Cui,“MICHAC: Defect prediction via feature selection based on maximal information coefficient with hierarchical agglomerative clustering,” in Proc. 23rd Int. Conf. Softw. Anal., Evol., Reengineering, vol. 1, 2016, pp. 370–381.
e0f8ed37d1092b72e7b31d1c278129c9 ; 21. Xu, Z., et al.: The impact of feature selection on defect prediction performance: an empirical comparison. In: Proceedings of the 27th IEEE International Symposium on Software Reliability Engineering (ISSRE). (IEEE), pp. 309–320 (2016)
259ad5a1f7aac013f3477634570de9f4 ; [43] Z. Xu, J. Liu, X. Luo, and T. Zhang, “Cross-version defect prediction via hybrid active learning with kernel principal component analysis,” in Proc. 25th Int. Conf. Softw. Anal., Evol., Reengineering., 2018, pp. 209–220.
6fa4f544c0c38e76ca7f91fb7bd17d3b ; [32] Zhou Xu, Jin Liu, Xiapu Luo, Zijiang Yang, Yifeng Zhang, Peipei Yuan, Yutian Tang, and Tao Zhang. 2019. Software defect prediction based on kernel PCA and weighted extreme learning machine. Information and Software Technology (IST) 106 (2019), 182–200.
4e5d8676421fa7992c3eb1544402fb0e ; [45] S. Wold, K. Esbensen, and P. Geladi, “Principal component analysis,” Chemometrics Intell. Lab. Syst., vol. 2, no. 1–3, pp. 37–52, 1987.
234f916cbc3211ca6aa2bfc422e53d06 ; 14. Schölkopf, B., Smola, A., Müller, K.R.: Kernel principal component analysis. In: International conference on artificial neural networks. (Springer), pp. 583–588 (1997)
5452d9413f199b5b47b5faa3db244aba ; [47] S. T. Roweis and L. K. Saul, “Nonlinear dimensionality reduction by locally linear embedding,” Science, vol. 290, no. 5500, pp. 2323–2326, 2000.
fcff5ac7836681671bfe8f125aaf947c ; [48] J. B. Tenenbaum, V. De Silva, and J. C. Langford, “A global geometric framework for nonlinear dimensionality reduction,” Science, vol. 290, no. 5500, pp. 2319–2323, 2000.
915a13085531cc9266e52c7a8133c2ea ; [49] M. A. Hall, “Correlation-based feature selection of discrete and numeric class machine learning,” in Proc. 17th Int. Conf. Mach. Learn., 2000, pp. 359–366.
4feac6f4c5b05fe73b5bedbf9ff7f44c ; [50] M. Dash, H. Liu, and H. Motoda, “Consistency based feature selection,” in Proc. 4th Pacific-Asia Conf. Knowl. Discovery Data Mining. Berlin, Germany: Springer, 2000, pp. 98–109.
5f4ee53bb01842ca76afa8bb7c18fcdf ; [11] F. Rahman, S. Khatri, E. T. Barr, and P. Devanbu, “Comparing static bug finders and statistical prediction,” in Proceedings of the 36th International Conference on Software Engineering, ser. ICSE 2014. New York, NY, USA: ACM, 2014, pp. 424–434. [Online]. Available: http://doi.acm.org/10.1145/2568225.2568269
4bf23aa8488a1c7ef52891ea3519416d ; [12] J. Zheng, L. Williams, N. Nagappan, W. Snipes, J. P. Hudepohl, and M. A. Vouk, “On the value of static analysis for fault detection in software,” IEEE Transactions on Software Engineering, vol. 32, no. 4, pp. 240–253, April 2006.
6906c50ce48c2503e702fff82caba732 ; [4] P. Devanbu, T. Zimmermann, and C. Bird, “Belief & evidence in empirical software engineering,” in Proceedings of the International Conference on Software Engineering (ICSE). IEEE, 2016, pp. 108–119.
1924c944d7f013bf3ce916a5b1df6a0d ; [14] S. Panichella, V. Arnaoudova, M. D. Penta, and G. Antoniol, “Would static analysis tools help developers with code reviews?” in 2015 IEEE 22nd International Conference on Software Analysis, Evolution and Reengineering (SANER), vol. 00, March 2015, pp. 161–170.
b81b5217663770409667f0bdef645e78 ; [15] L.-P. Querel and P. C. Rigby, “Warningsguru: Integrating statistical bug models with static analysis to provide timely and specific bug warnings,” in Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ser. ESEC/FSE 2018. New York, NY, USA: Association for Computing Machinery, 2018, p. 892–895. [Online]. Available: https://doi.org/10.1145/3236024.3264599
6f26220912da644109780efb9508a139 ; [16] Y. Fan, D. Alencar da Costa, D. Lo, A. E. Hassan, and L. Shanping, “The impact of mislabeled changes by szz on just-in-time defect prediction,” IEEE Transactions on Software Engineering, 2020.
cff36f19e3d8efd21bf6aa1411cd14c0 ; [19] S. Herbold, A. Trautsch, F. Trautsch, and B. Ledel, “Issues with szz: An empirical study of the state of practice of defect prediction data collection,” Submitted to: Empirical Software Engineering, 2020. [Online]. Available: https://arxiv.org/abs/1911.08938
f5738d835ea12b1f0b4f926689fde4b7 ; [21] S. Herbold, “On the costs and profit of software defect prediction,” IEEE Transactions on Software Engineering, pp. 1–1, 2019.
44eca008bdf8ed588ede824e1949f50c ; [28] S. Hosseini, B. Turhan, and D. Gunarathna, “A systematic literature review and meta-analysis on cross project defect prediction,” IEEE Transactions on Software Engineering, vol. PP, no. 99, pp. 1–1, 2017.
cf9f3fde7326f1d8e64205f0e07a3695 ; [31] E. Kreyszig, Advanced Engineering Mathematics: Maple Computer Guide, 8th ed. New York, NY, USA: John Wiley & Sons, Inc., 2000.
cf9f3fde7326f1d8e64205f0e07a3695 ; [45] N. Fenton and J. Bieman, Software Metrics: A Rigorous and Practical Approach, Third Edition, 3rd ed. Boca Raton, FL, USA: CRC Press, Inc., 2014.
5de29b9363779fe544dbfd4df8ed8805 ; [33] S. Herbold, “Autorank: A python package for automated ranking of classifiers,” Journal of Open Source Software, vol. 5, no. 48, p. 2173, 2020. [Online]. Available: https://doi.org/10.21105/joss.02173
17b3cb26037c39db3e1d36323e896c57 ; [35] J. W. Tukey, “Comparing individual means in the analysis of variance,” Biometrics, vol. 5, no. 2, pp. 99–114, 1949. [Online]. Available: http://www.jstor.org/stable/3001913
26c7c7a7a63711005da5eaf147e2198f ; [36] M. Friedman, “A comparison of alternative tests of significance for the problem of m rankings,” The Annals of Mathematical Statistics, vol. 11, no. 1, pp. 86–92, 1940.
fe66f604e26f308672164a88c0fbd856 ; [37] P. Nemenyi, “Distribution-free multiple comparison,” Ph.D. dissertation, Princeton University, 1963.
b3eefd0466052d8f1a2b2cad48968cea ; [38] J. Cohen, Statistical power analysis for the behavioral sciences. L. Erlbaum Associates, 1988.
bb1e611a5e0667b3024426c9144bbd39 ; [39] N. Cliff, “Dominance statistics: Ordinal analyses to answer ordinal questions.” Psychological Bulletin, vol. 114, no. 3, p. 494, 1993.
bd6c40d849f1064c3b4a499dbb9660fd ; [40] H. Abdi, “Bonferroni and Sidak corrections for multiple comparisons,” in Encyclopedia of Measurement and Statistics. Sage, Thousand Oaks, CA, 2007, pp. 103–107.
faeb255e3a855aa80433f0f541b7b421 ; [41] F. Trautsch, S. Herbold, P. Makedonski, and J. Grabowski, “Addressing problems with replicability and validity of repository mining studies through a smart data platform,” Empirical Software Engineering, Aug. 2017.
a75ce1ad8e4874e9b48779fa9864616c ; [42] D. Spadini, M. Aniche, and A. Bacchelli, “PyDriller: Python framework for mining software repositories,” in Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering - ESEC/FSE 2018. New York, New York, USA: ACM Press, 2018, pp. 908–911. [Online]. Available: http://dl.acm.org/citation.cfm?doid=3236024.3264598
72ce60f7ba5735b58e48c0c301bdacf8 ; [46] C. Wohlin, P. Runeson, M. Höst, M. C. Ohlsson, B. Regnell, and A. Wesslén, Experimentation in Software Engineering: An Introduction. Norwell, MA, USA: Kluwer Academic Publishers, 2000.
8a249da67f7628af614ec101f6cded61 ; [16] L. C. Briand, W. L. Melo, and J. Wust, “Assessing the applicability of fault-proneness models across object-oriented software projects,” IEEE Transactions on Software Engineering, vol. 28, no. 7, pp. 706–720, 2002.
a79df07ae8a87bd8e6346d43c10be8d7 ; Jiang Y, Cukic B, Menzies T (2008) Can data transformation help in the detection of fault-prone modules? In: Proc. Workshop on Defects in Large Software Systems (DEFECTS’08), pp 16–20
2c2d2b7ed910f06557671e6fb72c87b7 ; Kampstra P (2008) Beanplot: A boxplot alternative for visual comparison of distributions. J Stat Softw,Code Snippets 28(1):1–9
dfc592e5a814dab9c30e2da6e4209135 ; McIntosh S, Nagappan M, Adams B, Mockus A, Hassan AE (2014) A large-scale empirical study of the relationship between build technology and build maintenance. Empirical Software Engineering. doi:10.1.1/jpb001. http://link.springer.com/article/10.1007
a3d2509eb154f33e72c1de0a2b69ae82 ; Menzies T, Turhan B, Bener A, Gay G, Cukic B, Jiang Y (2008) Implications of ceiling effects in defect predictors. In: Proc. Int’l Conf. on Predictive Models in Softw. Eng. (PROMISE’10), pp 47–54
0a27d4b50c3462419eee977bcc206081 ; Menzies T, Butcher A, Marcus A, Zimmermann T, Cok D (2011) Local vs. global models for effort estimation and defect prediction. In: Proc. Int’l Conf. on Automated Software Engineering (ASE’11), pp 343–351
bcc0f2245da0d1b697ace231051e8361 ; Minku LL, Yao X (2014) How to make best use of cross-company data in software effort estimation? In: Proc. Int’l Conf. on Software Engineering (ICSE’14), pp 446–456
6e44350b0cb874d8e9ca001a46d67e10 ; Mockus A (2009) Amassing and indexing a large sample of version control systems: Towards the census of public source code history. In: Proc. Int’l Working Conf. on Mining Software Repositories (MSR’09), pp 11–20
8f582296f14fd2503863cc2c7a661d14 ; Sliwerski J, Zimmermann T, Zeller A (2005) When do changes induce fixes? In: Proc. Int’l Working Conf. on Mining Software Repositories (MSR’05), pp 1–5
acdd4c2610db72a03d6c0f5f37a3780b ; [58] B. Turhan, A. Tosun, and A. Bener, “Empirical evaluation of mixed-project defect prediction models,” in 37th EUROMICRO Conference on Software Engineering and Advanced Applications (SEAA). IEEE, 2011, pp. 396– 403.
13886fea3aea6bf9d240c79b48b531cd ; Zhang F, Mockus A, Zou Y, Khomh F, Hassan AE (2013) How does context affect the distribution of software maintainability metrics? In: Proc. Int’l Conf. on Software Maintenance (ICSM’13), pp 350–359
be066412c1666d709aa449587f667603 ; [51] C. Tantithamthavorn, “Towards a better understanding of the impact of experimental components on defect prediction modelling,” in Proceedings of the 38th International Conference on Software Engineering Companion. ACM, 2016, pp. 867–870.
d5f87e561d966868bbab14d6268a347d ; Boughorbel S, Jarray F, El-Anbari M (2017) Optimal classifier for imbalanced data using matthews correlation coefficient metric. PloS One 12(6):e0177,678
873a62c412f3d687fc20d7eb589a891d ; Bowes D, Hall T, Gray D (2012) Comparing the performance of fault prediction models which report multiple performance measures: recomputing the confusion matrix. In: Proceedings of the 8th international conference on predictive models in software engineering, pp 109–118. ACM
e55b1682d994fa0c5094c58ad08e096c ; Chicco D (2017) Ten quick tips for machine learning in computational biology. BioData Mining 10(1):35
a1eee5fce8bc8c62903638de433fe049 ; Farrar DE, Glauber RR (1967) Multicollinearity in regression analysis: the problem revisited. Rev Econ Stat 49(1):92–107
6c7058208c9011baa1e871ea109e86f5 ; Han J, Moraga C (1995) The influence of the sigmoid function parameters on the speed of backpropagation learning. In: Proceedings of the international workshop on artificial neural networks, pp 195–201. Springer
6e51a5ec56441819e7fc5db4c04a7083 ; Hindle A, Godfrey MW, Holt RC (2008) Reading beside the lines: Indentation as a proxy for complexity metric. In: Proceedings of the 16th international conference on program comprehension (ICPC), pp 133–142. IEEE
7776a82caa87c42a894ddb77130d1b16 ; Ho TK (1995) Random decision forests. In: Proceedings of the 3rd international conference on document analysis and recognition, vol 1, pp 278–282. IEEE
2d5af4f3194b3aa9ba2cf088152b5f3f ; Karunanithi N (1993) A neural network approach for software reliability growth modeling in the presence of code churn. In: Proceedings of the 4th international symposium on software reliability engineering, pp 310–317. IEEE
275950db19d27d5ec20b8b15990d6592 ; Khoshgoftaar TM, Allen EB, Goel N, Nandi A, McMullan J (1996) Detection of software modules with high debug code churn in a very large legacy system. In: Proceedings of the 7th international symposium on software reliability engineering, pp 364–371. IEEE
35471821c78a6f2a149aca9de0bf18b5 ; Khoshgoftaar TM, Szabo RM (1994) Improving code churn predictions during the system test and maintenance phases. In: Proceedings of the international conference on software maintenance (ICSM), pp 58–67. IEEE
1dccee77c76c5d1af2c37ebd5fb4ce3d ; Kim S, Whitehead Jr E J (2006) How long did it take to fix bugs? In: Proceedings of the 2006 international workshop on Mining software repositories (MSR), pp 173–174. ACM
f8c084a7db174fea1d90033454d3c056 ; McDonald JH (2014) Handbook of biological statistics, 3rd edn. Sparky House Publishing, Baltimore
823b62e0aa45b34abc835e595f87a03d ; Microsoft (2016) Overview of c++ statements. https://docs.microsoft.com/ja-jp/cpp/cpp/overview-of-cppstatements
a780d8a2fe736cdf3a31ac08e431b3ed ; Ohlsson MC, Von Mayrhauser A, McGuire B, Wohlin C (1999) Code decay analysis of legacy software through successive releases. In: Proceedings of the aerospace conference, proceedings, pp 69–81. IEEE
c37b9db60583c524ae3f12199d7da233 ; Oram A, Wilson G (2010) Making software: What really works, and why we believe it. ” O’Reilly Media Inc.”
a0909cf403bf27e7386af3858c02ddf3 ; Quinlan R (1993) C4.5: Programs for machine learning. Morgan Kaufmann Publishers
bea232947cefbb6ff212f5895e3bcd0f ; Rice ME, Harris GT (2005) Comparing effect sizes in follow-up studies: Roc area, cohen’s d, and r. Law Hum Behav 29(5):615–620
2cf066a0fa288aedebd0b92ae6c7217e ; Romanski P, Kotthoff L (2018) Fselector
050e9c239624bc1dae683c4a82ef06cc ; Sliwerski J., Zimmermann T, Zeller A (2005) When do changes induce fixes? In: Proceedings of the 2th international workshop on mining software repositories (MSR), 4, pp 1–5. ACM
863c1cb990654523f2cd8dc55a28d088 ; Stevenson A, Lindberg CA (2010) New Oxford American dictionary. Oxford University Press, Oxford
b836f081900d35b196300423b6a4c805 ; Thomas WS (2015) lscp: A lightweight source code preprocesser
82b12ca5b74c8f8bb6220476f553c7a8 ; Zwillinger D, Kokoska S (1999) CRC standard probability and statistics tables and formulae. CRC Press
c6cc84c4cd61b0775e1ba8df727f6114 ; [6] C. Bird, P. C. Rigby, E. T. Barr, D. J. Hamilton, D. M. German, and P. Devanbu. The promises and perils of mining git. In Proceedings of the 2009 6th IEEE International Working Conference on Mining Software Repositories (MSR), pages 1–10, 2009.
e45c491fedf24070b608b225f9784cef ; [14] V.Kovalenko, F. Palomba, and A. Bacchelli, “Mining file histories: Should we consider branches?” in Proc. 33rd ACM/IEEE Int. Conf. Automated Softw. Eng., 2018, pp. 202–213.
c8d8e67c330c1bd534ba367bccf9dacb ; [15] T. Dhaliwal, F. Khomh, Y. Zou, and A. E. Hassan, “Recovering commit dependencies for selective code integration in software product lines,” in Proc. 28th IEEE Int. Conf. Softw. Maintenance, 2012, pp. 202–211.
92c487bdb6c0eeea236e5671272958b5 ; [11] Yuanrui Fan, Xin Xia, Daniel Alencar da Costa, David Lo, Ahmed E Hassan, and Shanping Li. 2019. The impact of changes mislabeled by SZZ on just-in-time defect prediction. IEEE Transactions on Software Engineering (2019). https: //doi.org/10.1109/TSE.2019.2929761
38e409baf833d8e58913d1c57f6b77c3 ; [21] P. Domingos and M. Pazzani, “On the optimality of the simple Bayesian classifier under zero-one loss,” Mach. Learn., vol. 29, no. 2, pp. 103–130, Nov. 1997.
e9a015cf2aeb0d825127243a087cf754 ; [33] J. Huang and C. X. Ling. Using auc and accuracy in evaluating learning algorithms. IEEE Transactions on knowledge and Data Engineering, 17(3):299–310, 2005.
a24290e8e334c869c41cfef672dc487b ; [27] H. Li, H. Xu, C. Zhou, X. Lu, and Z. Han, “Joint optimization strategy of computation offloading and resource allocation in multi-access edge computing environment,” IEEE Trans. Veh. Technol., vol. 69, no. 9, pp. 10214–10226, Sep. 2020.
faa0aa10ff277ab4370deac42ad18783 ; [30] S. McIntosh andY. Kamei, “[Journal first] are fix-inducing changes a moving target?: A longitudinal case study of just-in-time defect prediction,” in Proc. IEEE/ACM 40th Int. Conf. Softw. Eng., May 2018, pp. 560–560.
75eb566a5f83bc62865b36d14201dc93 ; [47] A. Bachmann, C. Bird, F. Rahman, P. Devanbu, and A. Bernstein, “The missing links: bugs and bug-fix commits,” in Proceedings of the 18th ACM SIGSOFT international symposium on Foundations of software engineering, pp. 97–106, ACM, 2010.
0d60bd1236ce96f49c447f0776de6da9 ; [37] T. Mende, “Replication of defect prediction studies: Problems, pitfalls and recommendations,” in Proc. 6th Int. Conf. Predictive Models Softw. Eng., T. Menzies and G. Koru, Eds. Timisoara, Romania: ACM, Sep. 12–13, 2010, p. 5.
50177be0b3f08125cd7a02dcc5a81949 ; [2] A. Bacchelli, M. Lanza, and R. Robbes. Linking e-mails and source code artifacts. In Proceedings of the 32Nd ACM/IEEE International Conference on Software Engineering - Volume 1, ICSE ’10, pages 375– 384, New York, NY, USA, 2010. ACM.
1ceaefc7745fc09f48d61773378901ff ; [40] M. Sasaki, S. Matsumoto, and S. Kusumoto, “Integrating source code search into git client for effective retrieving of change history,” in Proc. IEEE Workshop Mining Analyzing Interact. Hist., Mar. 2018, pp. 1–5.
84b628a156a1c55aba345281f3100d39 ; [41] F. Qiu et al., “JITO: A tool for just-in-time defect identification and localization,” in Proc. 28th ACMJoint Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng., P. Devanbu, M. Cohen, and T. Zimmermann, Eds. 2020, pp. 1586–1590.
33b1497b168c4d03dfe803565d1a5309 ; [44] J. H. Zar, “Spearman rank correlation,” in Encyclopedia of Biostatistics, vol. 7. New Jersey, NY, USA: Wiley, 2005.
8662e7b4b251520f438fc525307cc8a2 ; [58] R. L. Plackett. Karl pearson and the chi-squared test. International Statistical Review/Revue Internationale de Statistique, pages 59–72, 1983.
0d708ec2d4cb839a4e370251cd6d524c ; [46] F. E. H. Jr, “RMS: Regression modeling strategies,” R Package Version 5.1-3, 2019.
cb8f0564e0d6a23292d1e04f27dd987c ; [48] J. Jiarpakdee, C. Tantithamthavorn, and A. E. Hassan, “The impact of correlated metrics on the interpretation of defect models,” IEEE Trans. Softw. Eng., vol. 47, no. 2, pp. 320–331, Feb. 2021.
e75e10f8736ba770e7d393e70efd71ea ; [52] H. Abdi, “The Bonferonni and Sid´ak corrections for multiple comparisons,” Encyclopedia Meas. Statist., vol. 3, pp. 103–107, 2007.
683126b8c6f616ea66337ff449c6cc98 ; [58] B. Adams, “On software release engineering,” ICSE Technical Briefing, 2012.
fd21027c84a6f27f67cacab40fb66a88 ; [21] M. Galar, A. Fernandez, E. Barrenechea, H. Bustince, and F. Herrera, “A review on ensembles for the class imbalance problem: bagging-, boosting-, and hybridbased approaches,” IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews), vol. 42, no. 4, pp. 463–484, 2011.
53448804735f70a3bbc16514928dbf81 ; [61] Y. S. Nugroho, H. Hata, and K. Matsumoto, “How different are different diff algorithms in git?,” Empir. Softw. Eng., vol. 25, no. 1, pp. 790–823, 2020.
c819184b3e56ed438ae09ad2ce46ed0a ; [62] G. Soares, R. Gheyi, and T. Massoni, “Automated behavioral testing of refactoring engines,” IEEE Trans. Softw. Eng., vol. 39, no. 2, pp. 147–162, Feb. 2013.
033d57653042f1ccd85fdd734ca79429 ; [1] A. Bacchelli and C. Bird. Expectations, outcomes, and challenges of modern code review. In Proc. of the 2013 Intl. Conf. on Software Engineering (ICSE), pages 712–721, 2013.
d4b5a303eaa3dfa9f9d9c19e80359e76 ; [4] G. Bavota and B. Russo. Four eyes are better than two: On the impact of code reviews on software quality. In Proc. ICSME, pages 81–90. IEEE, 2015.
95f526bf05de52070f7c420acc8e19dd ; [8] B. W. Boehm and P. N. Papaccio. Understanding and controlling software costs. IEEE Trans. Softw. Eng., 14(10):1462–1477, Oct. 1988.
b7e53893bcbbe545d281227f12d5c9ee ; [10] M. D’Ambros, M. Lanza, and R. Robbes. Evaluating defect prediction approaches: A benchmark and an extensive comparison. Empirical Softw. Engg., 17(4-5):531–577, Aug. 2012.
37d69a982bcf893606718867b29866ed ; [11] B. Efron and R. Tibshirani. Cross-validation and the bootstrap: Estimating the error rate of a prediction rule. Technical report, Stanford University, 1995.
ad33110f220a93a3021f61315c8b61eb ; [13] D. Galin. Software Quality Assurance: From Theory to Implementation. Pearson, June 2003.
5683593a1369d378d7d6310a91ce412c ; [14] J. M. Gonzalez-Barahona, G. Robles, and D. Izquierdo-Cortazar. The metricsgrimoire database collection. In 12th Working Conference on Mining Software Repositories (MSR), pages 478–481, May 2015.
5683593a1369d378d7d6310a91ce412c ; [20] M. Fowler, K. Beck, J. Brant, W. Opdyke, and D. Roberts. Refactoring: improving the design of existing code. Addison-Wesley Professional, 1999.
154fc8bd5c283a925c4435d4a37238fb ; [15] D. Graziotin, X. Wang, and P. Abrahamsson. Happy software developers solve problems better: psychological measurements in empirical software engineering. PeerJ, page e289, 3 2014.
cc98488900e33d8cf7f644f16a3ddf5e ; [16] E. Guzman, D. Az´ocar, and Y. Li. Sentiment analysis of commit comments in github: An empirical study. In Proceedings of the 11th Working Conference on Mining Software Repositories, MSR 2014, pages 352–355, New York, NY, USA, 2014. ACM.
b3b32a2d422265cd25c3323ed0157f81 ; [5] G. Bavota, B. De Carluccio, A. De Lucia, M. Di Penta, R. Oliveto, and O. Strollo. When does a refactoring induce bugs? an empirical study. In 2012 IEEE 12th International Working Conference on Source Code Analysis and Manipulation, pages 104–113. IEEE, 2012.
1c087ed69043234f9f793f4f61bdea6a ; [26] S. McIntosh, Y. Kamei, B. Adams, and A. E. Hassan. The impact of code review coverage and code review participation on software quality: A case study of the qt, vtk, and itk projects. In Proc. of the 11th Working Conf. on Mining Software Repositories (MSR), pages 192–201, 2014.
e60a95f3f443e37f5a47210d9b340a05 ; [27] N. Mishra and C. K. Jha. Article: Classification of opinion mining techniques. International Journal of Computer Applications, 56(13):1– 6, October 2012. Published by Foundation of Computer Science, New York, USA.
018e69377b363fde905d8a57ba421de5 ; [28] A. Mockus, R. T. Fielding, and J. D. Herbsleb. Two case studies of open source software development: Apache and mozilla. ACM Trans. Softw. Eng. Methodol., 11(3):309–346, July 2002.
52fbf5b1e03d4a4d06203215cc319318 ; [31] A. Murgia, P. Tourani, B. Adams, and M. Ortu. Do developers feel emotions? an exploratory analysis of emotions in software artifacts. In Proceedings of the 11th Working Conference on Mining Software Repositories, MSR 2014, pages 262–271, New York, NY, USA, 2014. ACM.
2b6994f44d85aa478e3758f1bf7c2c6d ; [33] M. Ortu, B. Adams, G. Destefanis, P. Tourani, M. Marchesi, and R. Tonelli. Are bullies more productive? empirical study of affectiveness vs. issue fixing time. In Proceedings of the 12th IEEE Working Conference on Mining Software Repositories (MSR), Florence, Italy, May 2015.
69738f80622119ee19199fa319188ba8 ; [34] M. Ortu, G. Destefanis, M. Kassab, S. Counsell, M. Marchesi, and R. Tonelli. Would you mind fixing this issue? an empirical analysis of politeness and attractiveness in software developed using agile boards. In XP2015, Helnsiki, page in press. Springer, 2015.
edf3a1da11a19abd5b4d4d2aaf5a7987 ; [36] P. C. Rigby and C. Bird. Convergent contemporary software peer review practices. In Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2013, pages 202–212, New York, NY, USA, 2013. ACM.
5020926e4096add2caffea6b0204f17c ; [41] M. Thelwall. Heart and soul: Sentiment strength detection in the social web with sentistrength (summary book chapter). In press.
1feea25ecb958229287f885aebe7c49b ; [43] M. Thelwall, K. Buckley, G. Paltoglou, D. Cai, and A. Kappas. Sentiment in short strength detection informal text. J. Am. Soc. Inf. Sci. Technol., 61(12):2544–2558, Dec. 2010.
c870b2704129b52d1e28f245d31e029d ; [44] P. Tourani, Y. Jiang, and B. Adams. Monitoring sentiment in open source mailing lists -– exploratory study on the apache ecosystem. In Proceedings of the 2014 Conference of the Center for Advanced Studies on Collaborative Research (CASCON), Toronto, ON, Canada, November 2014.
1d35998e6772a00350106a459c6bb1c8 ; [1] Activemq/amq-1381. https://issues.apache.org/jira/browse/ AMQ-1381. Accessed: 2018-09-18.
3e5fbfd775346d17a4788ecaa6252d86 ; [7] T. F. Bissyande, F. Thung, S. Wang, D. Lo, L. Jiang, and L. Reveillere. Empirical evaluation of bug linking. In Proceedings of the 17th European Conference on Software Maintenance and Reengineering, pages 89–98. IEEE, 2013.
517591cf1ee31306c1b6115d3fe77e6e ; [10] G. Canfora, A. D. Lucia, M. D. Penta, R. Oliveto, A. Panichella, and S. Panichella. Defect prediction as a multiobjective optimization problem. Software Testing, Verification and Reliability, 25(4):426–459, 2015.
bf8d8a280e3ddbc8ceb6b21f64738ac1 ; [11] C. Catal. Software fault prediction: A literature review and current trends. Expert systems with applications, 38(4):4626–4636, 2011.
3f8185b6daabbf1fa9b5899ba684c51b ; [14] D. A. da Costa. Refactoring-aware szz (ra-szz) implementation. https://github.com/danielcalencar/ra-szz, 2019.
1057792d4be8b9c6cf7b64c224fea2c1 ; [16] S. Davies, M. Roper, and M. Wood. Comparing text-based and dependence-based approaches for determining the origins of bugs. Journal of Software: Evolution and Process, 26(1):107–139, 2014.
5b072438650613068156f851b5a2c459 ; [18] B. Efron and R. J. Tibshirani. An introduction to the bootstrap. CRC press, 1994.
2582e5db2d4060317b37f838e1675215 ; [23] E. Giger, M. D’Ambros, M. Pinzger, and H. C. Gall. Method-level bug prediction. In Proceedings of the 6th international symposium on Empirical software engineering and measurement, pages 171–180. ACM, 2012.
d531cfb00004f66a76d73d7f3b7d93a4 ; [27] F. E. Harrell. Regression modeling strategies: with applications to linear models, logistic regression, and survival analysis. Springer, 2001.
3e8a8c5ae757ae70ca7c5a0dd2deacaa ; [47] M. Majka. naivebayes: High Performance Implementation of the Naive Bayes Algorithm, 2019. R package version 0.9.3.
ded807d0b7fadb52d229ec04ef06a8c9 ; [31] K. Herzig, S. Just, and A. Zeller. The impact of tangled code changes on defect prediction models. Empirical Software Engineering, 21(2):303–336, 2016.
210ab9e731c9c36c2c38db15c28a8d1c ; [32] D. W. Hosmer Jr, S. Lemeshow, and R. X. Sturdivant. Applied logistic regression, volume 398. John Wiley & Sons, 2013.
f348fae6f0baecb85837369fa09f1f11 ; [41] P. S. Kochhar, F. Thung, and D. Lo. Automatic fine-grained issue report reclassification. In Proceedings of the 19th International Conference on Engineering of Complex Computer Systems, pages 126– 135. IEEE, 2014.
ba3729e06072c1097ad77904caff32c0 ; [46] A. Liaw and M. Wiener. Classification and regression by randomforest. R News, 2(3):18–22, 2002.
ede54a2cb2965ea09707632e704f6729 ; [48] H. B. Mann and D. R. Whitney. On a test of whether one of two random variables is stochastically larger than the other. The annals of mathematical statistics, pages 50–60, 1947.
dfddb9648ef993984e87f90cb6d7d08a ; [57] T. J. Ostrand, E. J. Weyuker, and R. M. Bell. Where the bugs are. In ACM SIGSOFT Software Engineering Notes, volume 29, pages 86–96. ACM, 2004.
1211b3be41df20d64a43839dd4d3e180 ; [60] G. K. Rajbahadur, S.Wang, Y. Kamei, and A. E. Hassan. The impact of using regression models to build defect classifiers. In Proceedings of the 14th International Conference on Mining Software Repositories, pages 135–145. IEEE, 2017.
eb6573afb1c3e1549a1d4c1ca0ade247 ; [62] E. Shihab, Z. M. Jiang,W. M. Ibrahim, B. Adams, and A. E. Hassan. Understanding the impact of code and process metrics on postrelease defects: a case study on the eclipse project. In Proceedings of the 4th International Symposium on Empirical Software Engineering and Measurement, page 4. ACM, 2010.
55f64b00e8f9c02a336aa40267744ccc ; [64] D. Silva and M. T. Valente. Refdiff: detecting refactorings in version histories. In Proceedings of the 14th International Conference on Mining Software Repositories, pages 269–279. IEEE, 2017.
15de3ec5e8df52a3259929560409cf24 ; [67] G. Soares, R. Gheyi, D. Serey, and T. Massoni. Making program refactoring safer. IEEE software, 27(4):52–57, 2010.
390e2527d633fab97209c3d23a3571cb ; [70] C. Tantithamthavorn and A. E. Hassan. An experience report on defect modelling in practice: Pitfalls and challenges. In Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice, pages 286–295. ACM, 2018.
60f9aff7c7e70e457c34d74d583053ed ; [71] C. Tantithamthavorn, A. E. Hassan, and K. Matsumoto. The impact of class rebalancing techniques on the performance and interpretation of defect prediction models. arXiv preprint arXiv:1801.10269, 2018.
60f9aff7c7e70e457c34d74d583053ed ; [14] E. Shihab, A. Ihara, Y. , Kamei, W. M. Ibrahim, M. Ohira, B. Adams, A. E. Hassan, and K. Matsumoto. Studying re-opened bugs in open source software. Em- pirical Software Engineering, 18(5):1005{1042, 2012.
821aca70a5dae0331513487a2e4c5a7c ; [75] S. Wang, D. Lo, and X. Jiang. Understanding widespread changes: A taxonomic study. In Proceedings of the 17th European Conference on Software Maintenance and Reengineering, pages 5–14. IEEE, 2013.
50821af35ca7f34f9dec8c20fdbcaf6b ; Williams C, Spacco J (2008) Szz revisited: Verifying when changes induce fixes. In: Proceedings of the 2008 Workshop on Defects in Large Software Systems, ser. DEFECTS ’08. ACM, New York, pp 32–36
f709730c241757200d107eb3fe9e4d2b ; [78] C. C. Williams and J. W. Spacco. Branching and merging in the repository. In Proceedings of the 5th international working conference on Mining software repositories, pages 19–22. ACM, 2008.
49e783043e056b6c2794ea8ab741ac80 ; [79] X. Xia, L. Bao, D. Lo, P. S. Kochhar, A. E. Hassan, and Z. Xing. What do developers search for on the web? Empirical Software Engineering, 22(6):3149–3185, 2017.
57b887d8ea12aff10edfbdb69d59284f ; [85] T. Zimmermann, S. Kim, A. Zeller, and E. J. Whitehead Jr. Mining version archives for co-changed lines. In Proceedings of the 3rd international workshop on Mining software repositories, pages 72–75. ACM, 2006.
c483f6ce851c9ecd9fb835ff7551737c ; [1] Kamei, Y., Fukushima, T., Mcintosh, S., et al.: ‘Studying just-in-time defect prediction using cross-project models’, Empir. Softw. Eng., 2016, 21, (5), pp. 2072–2106
c483f6ce851c9ecd9fb835ff7551737c ; [2] Huang, Q., Xia, X., Lo, D.: ‘Revisiting supervised and unsupervised models for effort-aware just-in-time defect prediction’, Empir. Softw. Eng., 2018, 24, (5), pp. 2823–2862
c483f6ce851c9ecd9fb835ff7551737c ; [3] Yang, X., Lo, D., Xia, X., et al.: ‘TLEL: a two-layer ensemble learning approach for just-in-time defect prediction’, Inf. Softw. Technol., 2017, 87, pp. 206–220
c483f6ce851c9ecd9fb835ff7551737c ; [4] Kamei, Y., Shihab, E., Adams, B., et al.: ‘A large-scale empirical study of just-in-time quality assurance’, IEEE Trans. Softw. Eng., 2013, 39, (6), pp. 757–773
c483f6ce851c9ecd9fb835ff7551737c ; [10] Mockus, A., Weiss, D.M.: ‘Predicting risk of software changes’, Bell Labs Tech. J., 2000, 5, (2), pp. 169–180
c483f6ce851c9ecd9fb835ff7551737c ; [15] Li, J., Struzik, Z., Zhang, L., et al.: ‘Feature learning from incomplete EEG with denoising autoencoder’, Neurocomputing, 2015, 165, pp. 23–31
c483f6ce851c9ecd9fb835ff7551737c ; [16] Ferles, C., Papanikolaou, Y., Naidoo, K.J.: ‘Denoising autoencoder selforganizing map (DASOM)’, Neural Netw., 2018, 105, pp. 112–131
c483f6ce851c9ecd9fb835ff7551737c ; [17] Vincent, P.: ‘A connection between score matching and denoising autoencoders’, Neural Comput., 2011, 23, (7), pp. 1661–1674
c483f6ce851c9ecd9fb835ff7551737c ; [18] Wang, M., Wu, Z., Sun, X., et al.: ‘Trust-aware collaborative filtering with a denoising autoencoder’, Neural Process. Lett., 2019, 49, (2), pp. 835–849
c483f6ce851c9ecd9fb835ff7551737c ; [29] Koru, A.G., Zhang, D., Emam, K.E., et al.: ‘An investigation into the functional form of the size-defect relationship for software modules’, IEEE Trans. Softw. Eng., 2009, 35, (2), pp. 293–304
c483f6ce851c9ecd9fb835ff7551737c ; [30] Purushothaman, R., Perry, D.E.: ‘Toward understanding the rhetoric of small source code changes’, IEEE Trans. Softw. Eng., 2005, 31, (6), pp. 511–526
c483f6ce851c9ecd9fb835ff7551737c ; [31] Graves, T.L., Karr, A.F., Marron, J.S., et al.: ‘Predicting fault incidence using software change history’, IEEE Trans. Softw. Eng., 2000, 26, (7), pp. 653–661
c483f6ce851c9ecd9fb835ff7551737c ; [32] Shin, Y., Meneely, A., Williams, L., et al.: ‘Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities’, IEEE Trans. Softw. Eng., 2011, 37, (6), pp. 772–787
c483f6ce851c9ecd9fb835ff7551737c ; [34] Chawla, N.V., Bowyer, K.W., Hall, L.O., et al.: ‘SMOTE: synthetic minority over-sampling technique’, J. Artif. Intell. Res., 2002, 16, pp. 321–357
c483f6ce851c9ecd9fb835ff7551737c ; [37] Xia, X., Lo, D., Wang, X., et al.: ‘Collective personalized change classification with multiobjective search’, IEEE Trans. Reliab., 2016, 65, (4), pp. 1–20
c483f6ce851c9ecd9fb835ff7551737c ; [38] Huang, Q., Shihab, E., Xia, X., et al.: ‘Identifying self-admitted technical debt in open source projects using text mining’, Empir. Softw. Eng., 2017, 23, pp. 418–451
c483f6ce851c9ecd9fb835ff7551737c ; [39] Shiha, E., Ihara, A., Kamei, Y., et al.: ‘Studying re-opened bugs in open source software’, Empir. Softw. Eng., 2013, 18, (5), pp. 1005–1042
7b8b965ad4bca0e41ab51de7b31363a1 ; [5] Zhang, Y., Chan, W., Jaitly, N.: ‘Very deep convolutional networks for end-toend speech recognition’. 2017 IEEE Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), New Orleans, LA, USA, September 2017
8fa14cdd754f91cc6554c9e71929cce7 ; [6] Karpathy, A., Li, F.: ‘Deep visual-semantic alignments for generating image descriptions’. Proc. IEEE Conf. on Computer Vision and Pattern Recognition, Boston, MA, USA, June 2015
83878c91171338902e0fe0fb97a8c47a ; [7] Grefenstette, E., Blunsom, P.: ‘A convolutional neural network for modelling sentences’. The 52nd Annual Meeting of the Association for Computational Linguistics, Baltimore, Maryland, June 2014
c4b12c788d52a4ea109e98f5758529ae ; [8] Shen, Y., He, X., Gao, J., et al.: ‘Learning semantic representations using convolutional neural networks for web search’. Proc. 23rd Int. Conf. on World Wide Web, Seoul, South Korea, July 2014
c4b12c788d52a4ea109e98f5758529ae ; [9] Vincent, P., Larochelle, H., Bengio, Y., et al.: ‘Extracting and composing robust features with denoising autoencoders’. 25th Int. Conf. on Machine Learning, Helsinki, Finland, July 2008
c4b12c788d52a4ea109e98f5758529ae ; [11] Yang, X., Lo, D., Xia, X., et al.: ‘Deep learning for just-in-time defect prediction’. Proc. Int. Conf. on Software Quality, Reliability and Security, Washington, DC, USA, August 2015
c4b12c788d52a4ea109e98f5758529ae ; [12] Fukushima, T., Kamei, Y., McIntosh, S., et al.: ‘An empirical study of just-intime defect prediction using cross-project models’. Proc. 11th Working Conf. on Mining Software Repositories, Hyderabad, India, May 2014
c4b12c788d52a4ea109e98f5758529ae ; [13] Shihab, E., Hassan, A.E., Adams, B., et al.: ‘An industrial study on the risk of software changes’. Proc. ACM SIGSOFT 20th Int. Symp. on the Foundations of Software Engineering, Cary, North Carolina, USA, November 2012
c4b12c788d52a4ea109e98f5758529ae ; [14] Hoang, T., Dam, H.K., Kamei, Y., et al.: ‘DeepJIT: an end-to-end deep learning framework for just-in-time defect prediction’. IEEE Int. Working Conf. on Mining Software Repositories (MSR), Montreal, QC, Canada, May 2019
c4b12c788d52a4ea109e98f5758529ae ; [20] Lam, A.N., Nguyen, A.T., Nguyen, H.A., et al.: ‘Combining deep learning with information retrieval to localize buggy files for bug reports’. Proc. Int. Conf. on Automated Software Engineering, Lincoln, NE, USA, November 2015
c4b12c788d52a4ea109e98f5758529ae ; [21] Huo, X., Li, M., Zhou, Z.H., et al.: ‘Learning unified features from natural and programming languages for locating buggy source code’. Proc. Int. Joint Conf. Artificial Intelligence, NY, USA, July 2016
c4b12c788d52a4ea109e98f5758529ae ; [22] Gu, X., Zhang, H., Zhang, D., et al.: ‘Deep API learning’. Proc. ACM SIGSOFT Int. Symp. on Foundations of Software Engineering, Seattle, WA, USA, November 2016
c4b12c788d52a4ea109e98f5758529ae ; [23] Junjie, W., Qiang, C., Song, W., et al.: ‘Domain adaptation for test report classification in crowdsourced testing’. Proc. Int. Conf. on Software Engineering, Buenos Aires, Argentina, May 2017
c4b12c788d52a4ea109e98f5758529ae ; [24] Xu, B., Ye, D., Xing, Z., et al.: ‘Predicting semantically linkable knowledge in developer online forums via convolutional neural network’. Proc. Int. Conf. on Automated Software Engineering, Austin, TX, USA, August 2016
c4b12c788d52a4ea109e98f5758529ae ; [33] Yin, Z., Yuan, D., Zhou, Y., et al.: ‘How do fixes become bugs?’. Proc. 19th ACM SIGSOFT Symp. and the 13th European Conf. on Foundations of Software Engineering, ESEC/FSE, Szeged, Hungary, September 2011
c4b12c788d52a4ea109e98f5758529ae ; [36] Liu, J., Zhou, Y., Yang, Y., et al.: ‘Code churn: a neglected metric in effortaware just-in-time defect prediction’. ACM/IEEE Int. Symp. on Empirical Software Engineering & Measurement, Abu Dhabi, United Arab Emirates, December 2019
c4b12c788d52a4ea109e98f5758529ae ; [40] Yang, Y., Zhou, Y., Liu, J., et al.: ‘Effort-aware just-in-time defect prediction: simple unsupervised models could be better than supervised models’. ACM Sigsoft Int. Symp. on Foundations of Software Engineering, Bochum, Germany, March 2016
2db95e8e1a9267b7a1188556b2013b33 ; [19] Wang, S., Liu, T., Tan, L.: ‘Automatically learning semantic features for defect prediction’. Proc. Int. Conf. on Software Engineering, Austin, TX, USA, May 2016
363b122c528f54df4a0446b6bab05515 ; [25] Guo, J., Cheng, J., Cleland-Huang, J.: ‘Semantically enhanced software traceability using deep learning techniques’. Proc. Int. Conf. on Software Engineering, Buenos Aires, Argentina, May 2017
9e3669d19b675bd57058fd4664205d2a ; [26] Nagappan, N., Ball, T., Zeller, V.: ‘Mining metrics to predict component failures’. Proc. Int. Conf. on Software Engineering, 2006, Shanghai, China, May 2006
0cc175b9c0f1b6a831c399e269772661 ; [27] Hassan, A.E.: ‘Predicting faults using the complexity of code changes’. Proc. Int. Conf. on Software Engineering, Vancouver, BC, Canada, May 2009
627fcdb6cc9a5e16d657ca6cdef0a6bb ; [28] Nagappan, N., Ball, T.: ‘Use of relative code churn measures to predict system defect density’. Proc. Int. Conf. on Software Engineering, St. Louis, Missouri, USA, May 2005
e358efa489f58062f10dd7316b65649e ; [35] Fu, W., Menzies, T.: ‘Revisiting unsupervised learning for defect prediction’. Joint Meeting on Foundations of Software Engineering. Paderborn, Germany, September 2017
2f7e937a715d80e94483c5971a62f0c7 ; [37] Tao Zhang, He Jiang, Xiapu Luo, and Alvin TS Chan. 2016. A literature review of research in bug resolution: Tasks, challenges and future directions. Comput. J. 59, 5 (2016), 741–773.
57a65089b694ba973b9f78eafe72b1fd ; [30] Zhou Xu, Shuai Li, Yutian Tang, Xiapu Luo, Tao Zhang, Jin Liu, and Jun Xu. 2018. Cross version defect prediction with representative data via sparse subset selection. In Proceedings of the 26th International Conference on Program Comprehension (ICPC). 132–143.
41825111749f53268d45549ab6a4fb3d ; [69] Z. Xu et al., “Cross project defect prediction via balanced distribution adaptation based transfer learning,” J. Comput. Sci. Technol., vol. 34, no. 5, pp. 1039–1062, 2019.
8e27ef1d7acea0b2f8eb0073048a0763 ; [24] Giuseppe Scanniello, Carmine Gravino, Andrian Marcus, and Tim Menzies. 2013. Class level fault prediction using software clustering. In Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 640–645.
d4827f2d735d5645441a40f5d01858e9 ; 9. Catolino, G.: Just‐in‐time bug prediction in mobile applications: the domain matters! In: Proceedings of the 4th IEEE/ACM International Conference on Mobile Software Engineering and Systems (MOBILESoft). (IEEE), pp. 201–202 (2017)
74831c963648870b1b982f924b8cadef ; 11. Liu, F., et al.: Software defect prediction model based on pca‐isvm. Computer Simulation. 31(3), 397–401 (2014)
0ac76594d232d51c1e5a1170649a9edb ; 12. Cao, H., Qin, Z., Feng, T.: A novel pca‐bp fuzzy neural network model for software defect prediction. Adv. Sci. Lett. 9(1), 423–428 (2012)
61f7218bba212d7d67791c5338094b01 ; 15. Kim, K.I., Franz, M.O., Scholkopf, B.: Iterative kernel principal component analysis for image modeling. IEEE Trans. Pattern Anal. Mach. Intell. 27(9), 1351–1366 (2005)
b20f7b9513d2dd48e69b151fd01703d7 ; 16. Schölkopf, B., Smola, A., Müller, K.R.: Nonlinear component analysis as a kernel eigenvalue problem. Neural Comput. 10(5), 1299–1319 (1998)
df6fa8a58350a1df7e7fa83b956c3b3c ; [1] Yuri Sousa Aurelio, Gustavo Matheus de Almeida, Cristiano Leite de Castro, and Antonio Padua Braga. 2019. Learning from imbalanced data sets with weighted cross-entropy function. Neural Processing Letters 50, 2 (2019), 1937–1949.
b88b0f0e96e5d640febb94ed0f8b0453 ; 20. Zhao, K., et al.: Just‐in‐time defect prediction for android apps via imbalanced deep learning model. In: Proceedings of the 36th Annual ACM Symposium on Applied Computing. pp. 1447–1454. (2021)
dc4e6797d05d6bf72fdeadee81df3f42 ; 22. Liu, S., et al.: A feature selection framework for software defect prediction. In: Proceedings of the 38th IEEE Annual Computer Software and Applications Conference (COMPSAC). (IEEE), pp. 426–435 (2014)
ce64c549f1af1b76ddeba8c4ed86ed6c ; 24. Chen, X., et al.: Applying feature selection to software defect prediction using multi‐objective optimization. In: Proceedings of the 41st IEEE Annual Computer Software and Applications Conference (COMPSAC). (IEEE), 2, pp. 54–59 (2017)
f0b6aac5284c82337c1fea14862f30bc ; 25. Ghotra, B., McIntosh, S., Hassan, A.E.: A large‐scale study of the impact of feature selection techniques on defect classification models. In: Proceedings of the 14th IEEE/ACM International Conference on Mining Software Repositories (MSR). (IEEE), pp. 146–157 (2017)
1f1188d3e455c5adb38d5f89b0dd8684 ; 26. Ni, C., et al.: A cluster based feature selection method for cross‐project software defect prediction. J. Comput. Sci. Technol. 32(6), 1090–1107 (2017)
72c069c011302675f4710e8db2f7f16e ; 28. Liu, M., Miao, L., Zhang, D.: Two‐stage cost‐sensitive learning for software defect prediction. IEEE Trans. Reliab. 63(2), 676–686 (2014)
76a899d498d151a4303b8d32047d9600 ; [25] Michael J. Siers and Md Zahidul Islam. 2015. Software defect prediction using a cost sensitive decision forest and voting, and a potential solution to the class imbalance problem. Information Systems 51 (2015), 62–71.
1ac72200f4738d6393a084b8b809da77 ; 30. Bennin, K.E., et al.: The significant effects of data sampling approaches on software defect prioritization and classification. In: 2017 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM). (IEEE), pp. 364–373 (2017)
ea92b67e7d6bae45842fd4d11f6eab9f ; 31. Bennin, K.E., Keung, J., Monden, A.: Impact of the distribution parameter of data sampling approaches on software defect prediction models. In: 2017 24th Asia‐Pacific Software Engineering Conference (APSEC). (IEEE), pp. 630–635 (2017)
2c0a004146342f0604a622a72760b361 ; [20] Marco Ortu, Giuseppe Destefanis, Stephen Swift, and Michele Marchesi. 2016. Measuring high and low priority defects on traditional and mobile open source software. In Proceedings of the 7th International Workshop on Emerging Trends in Software Metrics. 1–7.
fcfd099df857dfb7f4aa2a65961c425f ; [12] Foutse Khomh, Brian Chan, Ying Zou, Anand Sinha, and Dave Dietz. 2011. Predicting post-release defects using pre-release field testing results. In Proceedings of the 27th IEEE International Conference on Software Maintenance (ICSM). IEEE, 253–262.
6183eebb792264a833dbe90c4a7d99ec ; [23] Riccardo Scandariato and James Walden. 2012. Predicting vulnerable classes in an android application. In Proceedings of the 4th International Workshop on Security Measurements and Metrics. 11–16.
b5f35b60afd7a3669f47d167d3e3d83b ; 44. Kaur, A., Kaur, K., Kaur, H.: An investigation of the accuracy of code and process metrics for defect prediction of mobile applications. In: Proceedings of the 4th International Conference on Reliability, Infocom Technologies and Optimization. (IEEE), pp. 1–6 (2015)
b9290f80ad874935644e8cfbf7594aba ; [22] Michael Yoseph Ricky, Fredy Purnomo, and Budi Yulianto. 2016. Mobile application software defect prediction. In 2016 IEEE Symposium on Service-Oriented System Engineering. IEEE, 307–313.
4bdf5e75046f2f878c94ad8883c4cd80 ; [16] Ruchika Malhotra. 2016. An empirical framework for defect prediction using machine learning techniques with Android software. Applied Soft Computing 49 (2016), 1034–1050.
3a72e0a1d35cb24e912127db620182a2 ; [21] Anh Viet Phan, Minh Le Nguyen, and Lam Thu Bui. 2017. Convolutional neural networks over control flow graphs for software defect prediction. In Proceedings of the 29th IEEE International Conference on Tools with Artificial Intelligence (ICTAI). IEEE, 45–52.
f473ab0f9a06f12599cd062c14adcd43 ; [40] C. Manjula and L. Florence, “Deep neural network based hybrid approach for software defect prediction using software metrics,” Cluster Comput., vol. 22, no. 4, pp. 9847–9863, 2019.
b9954672331355c7852963ff49ddbb8c ; 52. Li, S.Z., et al. Kernel machine based learning for multi‐view face detection and pose estimation. In: Proceedings of the 8th IEEE International Conference on Computer Vision. ICCV 2001. (IEEE), 2, pp. 674–679 (2001)
0dac827792bafb166ea1d98078e64523 ; 53. Huang, J., Yan, X.: Relevant and independent multi‐block approach for plant‐wide process and quality‐related monitoring based on kpca and svdd. ISA (Instrum. Soc. Am.) Trans. 73, 257–267 (2018)
02079ecbe8c71b07fed4526fd59f2d3c ; 54. Li, W., et al.: On improving the accuracy with auto‐encoder on conjunctivitis. Appl. Soft Comput. 81, 105489 (2019)
8be6003d744462c97514ee427ca8aeb8 ; [55] Z. Xu et al., “TSTSS: A two-stage training subset selection framework for cross version defect prediction,” J. Syst. Softw., vol. 154, pp. 59–78, 2019.
fc62bbc0cafd1cd1fd52e6905534430e ; [6] Lan Guo, Yan Ma, Bojan Cukic, and Harshinder Singh. 2004. Robust prediction of fault-proneness by random forests. In Proceedings of the 15th International Symposium on Software Reliability Engineering (ISSRE). IEEE, 417–428.
a0c3ff94d70954aae5068e65c1a97e25 ; [2] Cagatay Catal and Banu Diri. 2009. Investigating the effect of dataset size, metrics sets, and feature selection techniques on software fault prediction problem. Information Sciences 179, 8 (2009), 1040–1058.
c24acb74387259df7c30c60c8239bab0 ; [28] Xin Xia, David Lo, Shane McIntosh, Emad Shihab, and Ahmed E Hassan. 2015. Cross-project build co-change prediction. In Proceedings of the 22nd IEEE International Conference on Software Analysis, Evolution, and Reengineering (SANER). IEEE, 311–320.
237424e4b9cc19dc30b1fa7935543051 ; [15] Kalai Magal R and Shomona Gracia Jacob. 2015. Improved Random Forest Algorithm for Software Defect Prediction through Data Mining Techniques. International Journal of Computer Applications 117, 23 (2015), 18–22.
f51a0ebb4dc028e19946bc09683d2f25 ; [9] Md Zahidul Islam and Helen Giggins. 2011. Knowledge Discovery through SysFor - a Systematically Developed Forest of Multiple Decision Trees. In Proceedings of the 9th Australasian Data Mining Conference, AusDM. 195–204.
26412db6df484b8b7845a0360950f593 ; [14] Jinyan Li and Huiqing Liu. 2003. Ensembles of Cascading Trees. In Proceedings of the 3rd IEEE International Conference on Data Mining (ICDM). 585–588.
639ed4f7b0ac731b3a0a19a893646a71 ; [8] Hong Hu, Jiuyong Li, Hua Wang, Grant Daggard, and Mingren Shi. 2006. A maximally diversified multiple decision tree algorithm for microarray data classification. In Proceedings of the 2006 Workshop on Intelligent Systems for Bioinformatics, Vol. 73. 35–38.
718d1aba60afb3dfb1039231080d29ad ; [2] Liang Cai, Yuan-Rui FAN, Meng Yan, and Xin Xia. 2019. Just-in-time software defect prediction: literature review. Journal of Software 30, 5 (2019), 1288–1307.
920ef5c597a0ca70167389c3919e8193 ; [4] Yuchen Guo, Martin J. Shepperd, and Ning Li. 2018. Bridging effort-aware prediction and strong classification: a just-in-time software defect prediction study. In Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings, ICSE. ACM, Gothenburg, Sweden, 325–326.
91f162b7a5146f4681455aae837f0ddf ; [7] Enio G Jelihovschi, José Cláudio Faria, and Ivan Bezerra Allaman. 2014. ScottKnott: a package for performing the Scott-Knott clustering algorithm in R. TEMA (São Carlos) 15, 1 (2014), 3–17.
d98ff26eeeaeece4a32099563a018351 ; [12] Tim Menzies, Andrew Butcher, Andrian Marcus, Thomas Zimmermann, and David R. Cok. 2011. Local vs. global models for effort estimation and defect prediction. In 26th IEEE/ACM International Conference on Automated Software Engineering ASE. IEEE Computer Society, KS, USA, 343–351.
aea08be8e2ec1b7dd1314963c2d4e191 ; [14] Anh Tuan Nguyen, Tung Thanh Nguyen, Hoan Anh Nguyen, and Tien N. Nguyen. 2012. Multi-layered approach for recovering links between bug reports and fixes. In ACM SIGSOFT Symposium on the Foundations of Software Engineering. ACM, NC, USA, 63.
597e466b1d2a07057b0db783613127dc ; [15] Jacek Sliwerski, Thomas Zimmermann, and Andreas Zeller. 2005. When do changes induce fixes? ACM SIGSOFT Software Engineering Notes 30, 4 (2005), 1–5.
c089118e65a1120ed0846509b5f63b9e ; [16] Rainer Storn and Kenneth V. Price. 1997. Differential evolution - a simple and efficient heuristic for global optimization over continuous spaces. Journal of Global Optimization 11, 4 (1997), 341–359.
5d3c576dbc2f3c1ee6258dcde481d6b0 ; [18] Elaine J. Weyuker, Thomas J. Ostrand, and Robert M. Bell. 2010. Comparing the effectiveness of several modeling methods for fault prediction. Empirical Software Engineering 15, 3 (2010), 277–295.
bb19a3e98378d7f0ca83bbc07163f542 ; [20] Xingguang Yang, Huiqun Yu, Guisheng Fan, Kai Shi, and Liqiong Chen. 2019. Local versus global models for just-in-time software defect prediction. Scientific Programming 2019 (2019), 2384706:1–2384706:13.
9c49ed2f43de7b88f8b55bb2f81b906e ; [21] Xingguang Yang, Huiqun Yu, Guisheng Fan, Kang Yang, and Kai Shi. 2019. An Empirical Study on Progressive Sampling for Just-in-Time Software Defect Prediction. In Proceedings of the 7th International Workshop on Quantitative Approaches to Software Quality, Vol. 2511. CEUR-WS.org, Putrajaya, Malaysia, 12–18.
25a44e7b5cf16687c82fde8e5f1a3561 ; [4] S. Herbold, “CrossPare: A Tool for Benchmarking Cross-Project Defect Predictions,” in Proc. of ASEW ’15. IEEE, 2015, pp. 90–96.
ce4803f545bcd726f3bbb855c82e8529 ; [5] L. Pascarella, F. Palomba, and A. Bacchelli, “Re-evaluating methodlevel bug prediction,” in Proc. of International Conference on Software Analysis, Evolution and Reengineering, 2018, pp. 592–601.
379efea2e3741d407f9be908b89a0586 ; [28] Weiwei Li,Wenzhou Zhang, Xiuyi Jia, and Zhiqiu Huang. 2020. Effort-Aware semi- Supervised just-in-Time defect prediction. Information and Software Technology 126 (2020), 106364. https://doi.org/10.1016/j.infsof.2020.106364
5d434c20fdefc6e6da0666f7037d3626 ; [15] K. Zhu, N. Zhang, S. Ying, and D. Zhu, “Within-project and crossproject just-in-time defect prediction based on denoising autoencoder and convolutional neural network,” IET Software, vol. 14, no. 3, pp. 185–195, 2020.
a1bf439b919b147ba98348cb1588ab4e ; [72] S. Tabassum, L. L. Minku, D. Feng, G. G. Cabral, and L. Song, “An investigation of cross-project learning in online just-in-time software defect prediction,” in 2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE). IEEE, 2020, pp. 554–565.
6b985e6c1f57f1bd7b2af93136b6489c ; [20] H. Jahanshahi, D. Jothimani, A. Bas¸ar, and M. Cevik, “Does chronology matter in jit defect prediction? a partial replication study,” in Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering, 2019, p. 90–99.
9c970088de1215b8c9cd18a3fad8138e ; [21] S. Amasaki, K. Kawata, and T. Yokogawa, “Improving Cross-Project Defect Prediction Methods with Data Simplification,” in Proc. of SEAA ’15. IEEE, 2015, pp. 96–103.
528ceb819cfee73ecd4442f09adc8a92 ; [22] C.-C. A. Erika and K. Ochimizu, “Towards logistic regression models for predicting fault-prone code across software projects,” in Proc. of ESEM ’09. IEEE, 2009, pp. 460–463.
bab0baed83ea07ad5ec3194841224d01 ; [24] S. Herbold, “Training data selection for cross-project defect prediction,” in Proc. of PROMISE ’13. ACM, 2013, pp. 6:1–6:10.
c45bb6ebe5237842314e863c9f7e8d95 ; [25] K. Kawata, S. Amasaki, and T. Yokogawa, “Improving relevancy filter methods for cross-project defect prediction,” in Proc. of ACIT-CSI ’15, 2015, pp. 2–7.
d9884b2a6c1de959ffc1ba60864e7502 ; [27] Y. Ma, G. Luo, X. Zeng, and A. Chen, “Transfer learning for crosscompany software defect prediction,” Information and Software Technology, vol. 54, no. 3, pp. 248–256, 2012.
cdde6eac70ca2e2d5e8bc25fa2f64eac ; [28] J. Nam and S. Kim, “CLAMI: Defect Prediction on Unlabeled Datasets,” in Proc. of ASE ’15. IEEE, 2015, pp. 452–463.
eb0de4fbb031298017c81039c51559d9 ; [30] F. Peters and T. Menzies, “Privacy and utility for defect prediction: experiments with MORPH,” in Proc. of ICSE ’12. IEEE, 2012, pp. 189–199.
afb49506d75bb031d99e3c2d316ba095 ; [31] F. Peters, T. Menzies, L. Gong, and H. Zhang, “Balancing Privacy and Utility in Cross-Company Defect Prediction,” IEEE Transactions on Software Engineering, vol. 39, no. 8, pp. 1054–1068, 2013.
45daa63b2a67a1bdccfc0cc5165431c8 ; [32] P. He, B. Li, X. Liu, J. Chen, and Y. Ma, “An empirical study on software defect prediction with a simplified metric set,” Information and Software Technology, vol. 59, pp. 170–190, 2015.
f82b57760aa6f53b45dad3272f1a130e ; [33] F. Peters, T. Menzies, and L. Layman, “LACE2: Better Privacy- Preserving Data Sharing for Cross Project Defect Prediction,” in Proc. of ICSE ’15. IEEE, 2015, pp. 801–811.
696efcd0a27cfec11586ce128c57cfcd ; [35] D. Ryu, J.-I. Jang, and J. Baik, “A hybrid instance selection using nearest-neighbor for cross-project defect prediction,” Journal of Computer Science and Technology, vol. 30, no. 5, pp. 969–980, 2015.
b855295585909c11829431405469b8b0 ; [37] S. Uchigaki, S. Uchida, K. Toda, and A. Monden, “An Ensemble Approach of Simple Regression Models to Cross-Project Fault Prediction,” in Proc. of SNPD ’12. IEEE, 2012, pp. 476–481.
78bf0ab160e6af373578848ca62ae41c ; [40] ——, “Combined classifier for cross-project defect prediction: an extended empirical study,” Frontiers of Computer Science, vol. 12, no. 2, pp. 280–296, 2018.
1a5a1739620c5b3dfc27346cb9ef4ccb ; [43] T. M. Khoshgoftaar, P. Rebours, and N. Seliya, “Software quality analysis by combining multiple projects and learners,” Software Quality Journal, vol. 17, no. 1, pp. 25–49, 2009.
057f0de5257a7283749321b8e333b6fd ; [44] T. Menzies, A. Butcher, A. Marcus, T. Zimmermann, and D. Cok, “Local versus global models for effort estimation and defect prediction,” in Proc. of ASE ’11. IEEE, 2011, pp. 343–351.
bb4250b9313dda03a02024179f0c75d3 ; [1] “Ai fairness 360,” https://aif360.mybluemix.net/, accessed: 2021-05-1.
c1a1fecb6c706a73d13d78a530bf4b1c ; [2] “Open stack data set,” https://docs.openstack.org/wallaby/?_ga=2.205840979. 1124305833.1619313296-1069099767.1617679651, accessed: 2020-07-1.
0fbc1bc8e7b00464f7eb4049a015479a ; [3] “Openstack,” https://www.openstack.org/, accessed: 2021-05-1.
e85823b4e7db1064f4301e1c74978199 ; [4] “Qt,” https://www.qt.io/, accessed: 2021-05-1.
45974ac92fffd1b7ef0a271396aa0c93 ; [5] “What-if tool,” https://pair-code.github.io/what-if-tool/, accessed: 2021-05-1.
4646eb7540e9f7ff9b78e80344d654fb ; [6] A. Aggarwal, P. Lohia, S. Nagar, K. Dey, and D. Saha, “Black box fairness testing of machine learning models,” in Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2019, pp. 625–635.
4d5dac819335131050c0ce360f6cefa9 ; [7] H. Altae-Tran, B. Ramsundar, A. S. Pappu, and V. Pande, “Low data drug discovery with one-shot learning,” ACS central science, vol. 3, no. 4, pp. 283–293, 2017.
3bb33974af53e32951a068302b252916 ; [8] S. Barocas, M. Hardt, and A. Narayanan, “Fairness and machine learning: Limitations and opportunities,” 2018.
c31dc52fc6cc71a5514bf38cd49f9777 ; [9] K. E. Bennin, K. Toda, Y. Kamei, J. Keung, A. Monden, and N. Ubayashi, “Empirical evaluation of cross-release effort-aware defect prediction models,” in 2016 IEEE International Conference on Software Quality, Reliability and Security (QRS). IEEE, 2016, pp. 214–221.
2171e7b4eddd0e0de47aabc25180fb53 ; [10] A. Bernstein, J. Ekanayake, and M. Pinzger, “Improving defect prediction using temporal features and non linear models,” in Ninth international workshop on Principles of software evolution: in conjunction with the 6th ESEC/FSE joint meeting. ACM, 2007, pp. 11–18.
fe297a41a058dd2b7b14588553235665 ; [12] S. Biswas and H. Rajan, “Do the machine learning models on a crowd sourced platform exhibit bias? an empirical study on model fairness,” in Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2020, pp. 642–653.
6615098ab3148af948ca87375c3bab68 ; [13] J. M. Bland and D. G. Altman, “Multiple significance tests: the bonferroni method,” Bmj, vol. 310, no. 6973, p. 170, 1995.
b581037aa5a2dba320480611e3dbe8ec ; [14] J. Bromley, I. Guyon, Y. LeCun, E. Säckinger, and R. Shah, “Signature verification using a" siamese" time delay neural network,” Advances in neural information processing systems, vol. 6, pp. 737–744, 1993.
58610c34f0aeff099af6a2cf98005248 ; [15] J. Chakraborty, S. Majumder, Z. Yu, and T. Menzies, “Fairway: a way to build fair ml software,” in Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2020, pp. 654–665.
0f3cd31d1e34698c101cfbecd8a9ee34 ; [16] J. Chakraborty, K. Peng, and T. Menzies, “Making fair ml software using trustworthy explanation,” in 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 2020, pp. 1229–1233.
5cde956d38656a6ccda7a662c6ca58d8 ; [17] J. Chakraborty, T. Xia, F. M. Fahid, and T. Menzies, “Software engineering for fairness: A case study with hyperparameter optimization,” arXiv preprint arXiv:1905.05786, 2019.
d6fb188230343d8175d87271da48ef26 ; [22] A. Ghazikhani, H. S. Yazdi, and R. Monsefi, “Class imbalance handling using wrapper-based random oversampling,” in 20th Iranian Conference on Electrical Engineering (ICEE2012). IEEE, 2012, pp. 611–616.
f977bad70fcc2c16d407383c2ea8fc10 ; [21] E. Giger, M. Pinzger, and H. C. Gall, “Comparing fine-grained source code changes and code churn for bug prediction,” in Proceedings of the 8th Working Conference on Mining Software Repositories, ser. MSR ’11. New York, NY, USA: ACM, 2011, pp. 83–92. [Online]. Available: http://doi.acm.org/10.1145/1985441.1985456
5c792a8a2fdd8e1fdee1ba1845aec351 ; [26] D. Gray, D. Bowes, N. Davey, Y. Sun, and B. Christianson, “Reflections on the nasa mdp data sets,” IET software, vol. 6, no. 6, pp. 549–558, 2012.
52361f2ac2aba523c530be49676cd16a ; [27] F. Harel-Canada, L.Wang, M. A. Gulzar, Q. Gu, and M. Kim, “Is neuron coverage a meaningful measure for testing deep neural networks?” in Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2020, pp. 851–862.
22f27ad645d46326d1a0348617ff1e90 ; [30] K. Herzig and N. Nagappan, “Empirically detecting false test alarms using association rules,” in 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, vol. 2. IEEE, 2015, pp. 39–48.
bbe0a307746f5315c94ebc4b86168319 ; [19] Thong Hoang, Hong Jin Kang, David Lo, and Julia Lawall. 2020. CC2Vec: Distributed representations of code changes. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering. 518ś529. https://doi.org/10. 1145/3377811.3380361
2429b43f37c7c1f4dfd479a67a447489 ; [41] C. Khanan, W. Luewichana, K. Pruktharathikoon, J. Jiarpakdee, C. Tantithamthavorn, M. Choetkiertikul, C. Ragkhitwetsagul, and T. Sunetnanta, “Jitbot: An explainable just-in-time defect prediction bot,” in 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 2020, pp. 1336–1339.
10ad02c76147469e1adbd7da0c4790fc ; [46] G. Koch, R. Zemel, and R. Salakhutdinov, “Siamese neural networks for one-shot image recognition,” in ICML deep learning workshop, vol. 2. Lille, 2015.
2c650fc86fd951a08d59da8da6a34b4e ; [47] S. Kotsiantis, D. Kanellopoulos, P. Pintelas et al., “Handling imbalanced datasets: A review,” GESTS International Transactions on Computer Science and Engineering, vol. 30, no. 1, pp. 25–36, 2006.
a59dd99e34d38e83f9eea4d776f3f5a1 ; [48] N. Kumar, A. Berg, P. N. Belhumeur, and S. Nayar, “Describable visual attributes for face verification and image search,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 33, no. 10, pp. 1962–1977, 2011.
0fa3f165b155e53f6dea72f7c68aab17 ; [49] C. Le Goues, M. Dewey-Vogt, S. Forrest, and W. Weimer, “A systematic study of automated program repair: Fixing 55 out of 105 bugs for $8 each,” in Software Engineering (ICSE), 2012 34th International Conference on. IEEE, 2012, pp. 3–13.
9033c5dc719eea66a8d7754556b20ea6 ; [53] S. Liu, X. Chen, W. Liu, J. Chen, Q. Gu, and D. Chen, “Fecar: A feature selection framework for software defect prediction,” in 2014 IEEE 38th Annual Computer Software and Applications Conference. IEEE, 2014, pp. 426–435.
96b887f39d2f207b581adeb35d379731 ; [54] V. López, A. Fernández, S. García, V. Palade, and F. Herrera, “An insight into classification with imbalanced data: Empirical results and current trends on using data intrinsic characteristics,” Information sciences, vol. 250, pp. 113–141, 2013.
d2e673a312d6160e892969ad9dcec820 ; [55] R. Malhotra and S. Kamal, “An empirical study to investigate oversampling methods for improving software defect prediction using imbalanced data,” Neurocomputing, vol. 343, pp. 120–140, 2019.
51eaa313d22e6742a5b6c818879ebbda ; [57] N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan, “A survey on bias and fairness in machine learning,” arXiv preprint arXiv:1908.09635, 2019.
adda8e2629720389b6a2a6f0c1904db8 ; [58] I. Melekhov, J. Kannala, and E. Rahtu, “Siamese network features for image matching,” in 2016 23rd International Conference on Pattern Recognition (ICPR). IEEE, 2016, pp. 378–383.
589af8208728ffc56e6043b69b0a38e7 ; [60] M. Motwani, S. Sankaranarayanan, R. Just, and Y. Brun, “Do automated program repair techniques repair hard and important bugs?” Empirical Software Engineering, vol. 23, no. 5, pp. 2901–2947, 2018.
5b682f0622229886456f0a863ff8b6e2 ; [62] P. Neculoiu, M. Versteegh, and M. Rotaru, “Learning text similarity with siamese recurrent networks,” in Proceedings of the 1stWorkshop on Representation Learning for NLP, 2016, pp. 148–157.
2c4221b45541232c9b0d980a84d35147 ; [40] C. Pornprasit and C. Tantithamthavorn, “JITLine: A Simpler, Better, Faster, Finer-grained Just-In-Time Defect Prediction,” in Proceedings of the International Conference on Mining Software Repositories (MSR), 2021, p. To Appear.
e181aeef73d08c6bb90994cc2f8917d8 ; [64] L. Qiao and Y.Wang, “Effort-aware and just-in-time defect prediction with neural network,” PloS one, vol. 14, no. 2, p. e0211359, 2019.
b79219f857b96ac94a3f022aef9472f8 ; [67] A. Rajkomar, M. Hardt, M. D. Howell, G. Corrado, and M. H. Chin, “Ensuring fairness in machine learning to advance health equity,” Annals of internal medicine, vol. 169, no. 12, pp. 866–872, 2018.
61034644947efe677c63f150ef782ced ; [68] Z. A. Rana, M. M. Awais, and S. Shamail, “Impact of using information gain in software defect prediction models,” in International Conference on Intelligent Computing. Springer, 2014, pp. 637–648.
688d5c862d6fbe1a084fcad7a38e4fb6 ; [69] J. Romano, J. D. Kromrey, J. Coraggio, and J. Skowronek, “Appropriate statistics for ordinal level data: Should we really be using t-test and cohen’sd for evaluating group differences on the nsse and other surveys,” in annual meeting of the Florida Association of Institutional Research, vol. 177, 2006.
013f0828e02ba2766fb8964dfb8a9c7a ; [71] N. Seliya and T. M. Khoshgoftaar, “The use of decision trees for cost-sensitive classification: an empirical study in software quality prediction,” Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, vol. 1, no. 5, pp. 448–459, 2011.
dbe23999599835bd5a189d5fc79a9233 ; [74] Y. Tian, Z. Zhong, V. Ordonez, G. Kaiser, and B. Ray, “Testing dnn image classifiers for confusion & bias errors,” in Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, 2020, pp. 1122–1134.
52ae5ba5ee8676f4b99ca7ddb4108a2e ; [75] F. Tramer, V. Atlidakis, R. Geambasu, D. Hsu, J.-P. Hubaux, M. Humbert, A. Juels, and H. Lin, “Fairtest: Discovering unwarranted associations in data-driven applications,” in 2017 IEEE European Symposium on Security and Privacy (EuroS&P). IEEE, 2017, pp. 401–416.
f5ed017c66d9d36094d971d170d55e62 ; [76] M. Veale and R. Binns, “Fairer machine learning in the real world: Mitigating discrimination without collecting sensitive data,” Big Data & Society, vol. 4, no. 2, p. 2053951717743530, 2017.
ba343fc7ecdb971b0895942a722b4f1c ; [77] A. Wang, A. Narayanan, and O. Russakovsky, “Revise: A tool for measuring and mitigating bias in visual datasets,” in European Conference on Computer Vision. Springer, 2020, pp. 733–751.
a7e18a8ad97282e7a4829587768ca3e6 ; [78] Q. Wang, J. Gao, and Y. Yuan, “Embedding structured contour and location prior in siamesed fully convolutional networks for road detection,” IEEE Transactions on Intelligent Transportation Systems, vol. 19, no. 1, pp. 230–241, 2017.
451c298cb35c76b6fbe3c2372e1f3dce ; [80] Y. Wang, Q. Yao, J. T. Kwok, and L. M. Ni, “Generalizing from a few examples: A survey on few-shot learning,” ACM Computing Surveys (CSUR), vol. 53, no. 3, pp. 1–34, 2020.
89f7cc4b2dbfa2b4023a48f2b7e6f276 ; [81] K. Q.Weinberger, J. Blitzer, and L. K. Saul, “Distance metric learning for large margin nearest neighbor classification,” in Advances in neural information processing systems, 2006, pp. 1473–1480.
482f2fbaecf99fdb0172d6cc93a2e06a ; [82] M. Wen, R. Wu, and S.-C. Cheung, “How well do change sequences predict defects? sequence learning from software changes,” IEEE Transactions on Software Engineering, vol. 46, no. 11, pp. 1155–1175, 2018.
30149faf0dae8869b7fe508abff8e36f ; [85] Y. Yao, M. Xu, Y. Wang, D. J. Crandall, and E. M. Atkins, “Unsupervised traffic accident detection in first-person videos,” arXiv preprint arXiv:1903.00618, 2019.
da289b9008ce6a1eb13bc7b8966c85ac ; [87] L. Zhao, Z. Shang, L. Zhao, A. Qin, and Y. Y. Tang, “Siamese dense neural network for software defect prediction with small data,” IEEE Access, vol. 7, pp. 7663–7677, 2018.
d2be5e0002a869070329a32c85bc75d7 ; 3. Ostrand TJ,Weyuker EJ, Bell RM.Where the bugs are. In: Proceedings of the 2004 ACMSIGSOFT International Symposium on Software Testing and Analysis; 2004; Boston, MA.
a05855bc4fc6a089d0d388b4922e8f9e ; 4. Pan K, Kim S, Whitehead Jr EJ. Bug classification using program slicing metrics. Paper presented at: Sixth IEEE InternationalWorkshop on Source Code Analysis and Manipulation; 2006; Philadelphia, PA.
b31b4e11dfec6a3ec3f77ddaf74f75bf ; 5. Walia GS, Carver JC, Nagappan N. The effect of the number of inspectors on the defect estimates produced by capture-recapture models. In: Proceedings of the 30th International Conference on Software Engineering; 2008; Leipzig, Germany.
cc5dbab7a7006bc02f60cf47145df64c ; 8. Walia GS, Carver JC. Evaluation of capture-recapture models for estimating the abundance of naturally-occurring defects. In: Proceedings of the Second ACM-IEEE International Symposium on Empirical Software Engineering and Measurement; 2008; Kaiserslautern, Germany.
645894bd72e22b5ef4038ee21bb67276 ; 26. Kim S, Whitehead EJ Jr, Zhang Y. Classifying software changes: Clean or buggy? IEEE Trans Softw Eng. 2008;34(2):181-196.
e1c63cfaa929eb9ebd951b5f5ed3a44a ; 12. Jiang T, Tan L, Kim S. Personalized defect prediction. In: Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering; 2014; Silicon Valley, CA.
535d33a0dd1fb21113d8bb88b21eb0e5 ; 13. Duda RO, Hart PE. Pattern Classification and Scene Analysis. New York, NY:Wiley; 1973.
225be914d53aa205276c8f0c9d5971cd ; 14. Joachims T. Text categorization with support vector machines: learning with many relevant features. In: Machine Learning: ECML-98: 10th European Conference on Machine Learning Chemnitz, Germany, April 21-23, 1998 Proceedings. Berlin, Germany: Springer Berlin Heidelberg; 1998:137-142.
1e258357b86b9a2689fb496bb5548078 ; 15. Tan M, Tan L, Dara S, Mayeux C. Online defect prediction for imbalanced data. Paper presented at: IEEE/ACM 37th IEEE International Conference on Software Engineering; 2015; Florence, Italy.
ec1c999bd8686a1eaed1d3e1b4976afd ; 17. Yang X, Lo D, Xia X, Sun J. TLEL: a two-layer ensemble learning approach for just-in-time defect prediction. Inf Softw Technol. 2017;87:206-220.
07959e1d6dba799b02261a6c175ab12c ; 19. Li C. Classifying imbalanced data using a bagging ensemble variation (BEV). In: Proceedings of the 45th Annual Southeast Regional Conference; 2007; Winston-Salem, NC.
51420cf6ccb99bb0dc6ddb27c28342e2 ; 20. Guo H, Viktor HL. Learning from imbalanced data sets with boosting and data generation: the databoost-IM approach. ACM SIGKDD Explor Newsl. 2004;6(1):30-39.
267042f5038e852201b8c46dda42b1b3 ; 22. Freund Y, Schapire RE. Experiments with a new boosting algorithm. In: Proceedings of the Thirteenth International Conference on International Conference on Machine Learning; 1996; Bari, Italy.
610169f97df2330b9f3975de71ad6f36 ; 23. Sadowski C, Lewis C, Lin Z, Zhu X,Whitehead Jr EJ. An empirical analysis of the fixcache algorithm. In: Proceedings of the 8thWorking Conference on Mining Software Repositories; 2011; Honolulu, HI.
623a91d758c654b4365a92f110573553 ; 24. S´ liwerski J, Zimmermann T, Zeller A. When do changes induce fixes? In: Proceedings of the 2005 International Workshop on Mining Software Repositories; 2005; St. Louis, MO.
d8249a3b7522b3752c99880e8ecf396d ; 25. Kim S, Zimmermann T, Whitehead Jr EJ, Zeller A. Predicting faults from cached history. In: Proceedings of the 29th International Conference on Software Engineering; 2008; New York, NY.
3431de06b6f7a2ff428c2911b008b9af ; 26. Rahman F, Devanbu P. How, and why, process metrics are better. Paper presented at: 35th International Conference on Software Engineering; 2013; San Francisco, CA.
66a68c8227b3beb32e4389aaaaadbf32 ; 28. Lessmann S, Baesens B, Mues C, Pietsch S. Benchmarking classification models for software defect prediction: a proposed framework and novel findings. IEEE Trans Softw Eng. 2008;34(4):485-496.
33f608938b43d3cb31ddd87b73fc6d96 ; 29. Zimmermann T, Premraj R, Zeller A. Predicting defects for eclipse. In: Proceedings of the Third International Workshop on Predictor Models in Software Engineering; 2007; Minneapolis, MN.
7f7cb80429d097d8ffe57870bba50c64 ; 30. Understand static code analysis tool; 2014. https://scitools.com/
347a71856f8ffbd601eb6ce63e648d31 ; 31. Yang X, Lo D, Xia X, Zhang Y, Sun J. Deep learning for just-in-time defect prediction. Paper presented at: IEEE International Conference on Software Quality, Reliability and Security; 2015; Vancouver, Canada.
00bed98118cbf5f520135d1bf532fa3c ; 32. Yang Y, Zhou Y, Liu J, et al. Effort-aware just-in-time defect prediction: simple unsupervised models could be better than supervised models. In: Proceedings of the 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering; 2016; Seattle, WA.
6c955f54e9517a12aef961744f573701 ; 34. John GH, Kohavi R, Pfleger K. Irrelevant features and the subset selection problem. In: Proceedings of the 11th International Conference on Machine Learning; 1994; San Francisco, CA.
b3b579980c5a83afa232f3686ab4488c ; 36. Hall MA. Correlation-Based Feature Selection for Machine Learning. [PhD thesis]. Hamilton, New Zealand: The University of Waikato; 1999.
0637a9f18f17cf4dd512f56bcdb96a37 ; 38. Quinlan JR. C4. 5: Programs for Machine Learning. San Francisco, CA: Morgan Kaufmann Publishers Inc; 1993.
e3e48e94ee1a0528f8d961086a1bae67 ; 40. Lewis C, Lin Z, Sadowski C, Zhu X, Ou R,Whitehead Jr EJ. Does bug prediction support human developers? Findings from a Google case study. In: Proceedings of the 2013 International Conference on Software Engineering; 2013; San Francisco, CA.
f515c8b635b44558931f1203e3005556 ; 59. Menzies T, Dekhtyar A, Distefano J, Greenwald J. Problems with Precision: A Response to" comments on'data mining static code attributes to learn defect predictors'". IEEE Trans Softw Eng. 2007;33(9):637-640.
c6c57d09da5b6198b91bf41fc7c21caf ; 42. Rahman F, Posnett D, Devanbu P. Recalling the imprecision of cross-project defect prediction. In: Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering; 2012; Cary, NC.
f2c4ef92f80493279d887e061b4d4c56 ; 43. Xia X, Lo D, Pan SJ, Nagappan N, Wang X. Hydra: massively compositional model for cross-project defect prediction. IEEE Trans Softw Eng. 2016;42(10):977-998.
7b5cb226b84617f9d4ade0acfc0f2b65 ; 48. Huang Q, Xia X, Lo D. Supervised vs unsupervised models: a holistic look at effort-aware just-in-time defect prediction. Paper presented at: IEEE International Conference on Software Maintenance and Evolution; 2017; Shanghai, China.
197241ccb9eedbefa003a0f147df5c31 ; 49. John GH, Langley P. Estimating continuous distributions in Bayesian classifiers. In: Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence; 1995; Montréal, Canada.
0d71a38ff85e6d135a1832c9afee872b ; 51. Cleary JG, Trigg LE. K*: an instance-based learner using an entropic distance measure. In: Proceedings of the Twelfth International Conference on Machine Learning; 1995; Tahoe City, CA.
99f9f50affd3cc37d380c6b586a5f9bd ; 52. Friedman J, Hastie T, Tibshirani R. Additive logistic regression: a statistical view of boosting (with discussion and a rejoinder by the authors). Ann Stat. 2000;28(2):337-407.
81cafbb9102a2da5414b78370604fc3e ; 54. Martin B. Instance-Based Learning: Nearest Neighbor With Generalization Thesis. [MS thesis]. Hamilton, New Zealand: The University of Waikato; 1995.
76eadb9a1be35c9b003065dcc8cc8141 ; 55. Shalev-Shwartz S, Singer Y, Srebro N, Cotter A. Pegasos: primal estimated sub-gradient solver for SVN. In: Proceedings of the 24th International Conference on Machine Learning; 2007; Corvalis, OR.
0ae9b1438c749ac4688be2ee098d1b8b ; 59. Holland JH. Adaptation in Natural and Artificial Systems: An Introductory Analysis With Applications to Biology, Control, and Artificial Intelligence. Ann Arbor, MI: The University of Michigan Press; 1975.
a5ce00e865763ef4ef35f5053dad31bc ; [1] P. Bellini, I. Bruno, P. Nesi, and D. Rogai, “Comparing faultproneness estimation models,” in Proc. of 10th IEEE International Conference on Engineering of Complex Computer Systems, 2005, pp. 205–214.
5ba87e9a9ba982e59e139d187638ffa6 ; [3] N. Seliya, T. M. Khoshgoftaar, and S. Zhong, “Analyzing software quality with limited fault-proneness defect data,” in Proc. of 9th IEEE International Symposium on High-Assurance Systems Engineering, 2005, pp. 89–98.
5fa9db2e335ef69a4eeb9fe7974d61f4 ; [7] (2015, Mar.) FindbugsTM- find bugs in java programs. [Online]. Available: http://findbugs.sourceforge.net/
5fa9db2e335ef69a4eeb9fe7974d61f4 ; [8] (2015, Mar.) igrigorik/bugspots github. [Online]. Available: https://github.com/igrigorik/bugspots
b69ce8069d855422e198512605e25fc5 ; [1] Bhattacharya, P. and Neamtiu, I. 2011. Bug-fix time prediction models: can we do better? Proceeding of the international conference on mining software repositories (New York, New York, USA), 207– 210.
d1c9618480fd1caf8d9151d299988902 ; [2] Briand, L. et al. 1999. A unified framework for coupling measurement in object-oriented systems. IEEE Transactions on Software Engineering. 25, 1 (1999), 91–121. DOI:https://doi.org/10.1109/32.748920.
5adab681400e5bfab8ca9370f18c42c8 ; [3] Bultena, B. and Ruskey, F. 1998. An Eades-McKay algorithm for well-formed parentheses strings. Information Processing Letters. 68, 5 (1998), 255–259.
d7158f9e3bd2f1c462fa9e0d84b7783f ; [4] Chen, T.-h. et al. 2014. An Empirical Study of Dormant Bugs Categories and Subject Descriptors. Proceedings of the international conference on mining software repository 82–91.
fda39181ecf216656a19d6a642dfb5a1 ; [6] Cordy, J.R. and Roy, C.K. 2011. The NiCad Clone Detector. Proceedings of the international conference on program comprehension 219–220.
e19423ea690c17cfddf2eb1ee5c8ef19 ; [7] Dallmeier, V. et al. 2009. Generating Fixes from Object Behavior Anomalies. Proceedings of the international conference on automated software engineering 550–554.
5ba0a4697f8a769ca73e3bb89540dc1c ; [8] Ducasse, S. et al. 1999. A Language Independent Approach for Detecting Duplicated Code. Proceedings of the international conference on software maintenance 109–118.
46423be5f8d017098fb8a9c75b229ede ; [10] Girvan, M. and Newman, M.E.J. 2002. Community structure in social and biological networks. Proceedings of the National Academy of Sciences. 99, 12 (Jun. 2002), 7821–7826. DOI:https://doi.org/10. 1073/pnas.122653799.
7aa0177654946910f7dbc1ed52b3e1ff ; [15] Hunt, J.W. and Szymanski, T.G. 1977. A fast algorithm for computing longest common subsequences. Communications of the ACM. 20, 5 (May 1977), 350–353. DOI:https://doi.org/10.1145/359581. 359603.
ae838d36cdc34d150807b546f54a8578 ; [16] Johnson, J.H. 1993. Identifying redundancy in source code using fingerprints. Proceedings of the conference of the centre for advanced studies on collaborative research 171–183.
36f6ef8b2d6f22f1822a17d6cb7a2d29 ; [17] Johnson, J.H. 1994. Visualizing textual redundancy in legacy source. Proceedings of the conference of the centre for advanced studies on collaborative research 32.
53262097662fe2d0f14e82afa9ddc356 ; [19] Kapser, C. and Godfrey, M.W. 2003. Toward a Taxonomy of Clones in Source Code: A Case Study. International workshop on evolution of large scale industrial software architectures 67–78.
9da078b4d710d90b1ae8da364479f556 ; [20] Kim, D. et al. 2013. Automatic patch generation learned from human-written patches. Proceedings of the international conference on software engineering 802–811.
3241d7f9c6822007831348c2531b77c9 ; [23] Kpodjedo, S. et al. 2010. Design evolution metrics for defect prediction in object oriented systems. Empirical Software Engineering. 16, 1 (Dec. 2010), 141–175. DOI:https://doi.org/10.1007/ s10664-010-9151-7.
aa300b5fbe957fc484dce560b9d1d467 ; [25] Le, X.-B.D. et al. 2015. Should fixing these failures be delegated to automated program repair? Proceedings of the international symposium on software reliability engineering 427–437.
cf4f312ed1d63a31b55e58f649cd382d ; [27] Manber, U. 1994. Finding similar files in a large file system. Proceedings of the usenix winter 1–10.
198621682dfe53233dd70c1d3356a993 ; [28] Marcus, A. and Maletic, J. 2001. Identification of high-level concept clones in source code. Proceedings international conference on automated software engineering 107–114.
aa286c68cc3899d0cf83234de59f7c07 ; [32] Newman, M.E.J. and Girvan, M. 2004. Finding and evaluating community structure in networks. Physical Review E. 69, 2 (Feb. 2004), 026113. DOI:https://doi.org/10.1103/PhysRevE.69.026113.
149983130f12065f8827a1c6170b3f26 ; [34] Pan, K. et al. 2008. Toward an understanding of bug fix patterns. Empirical Software Engineering. 14, 3 (Aug. 2008), 286–315. DOI:https://doi.org/10.1007/s10664-008-9077-5.
aea19fbfcd8be41d913d5d1a1f2481aa ; [37] Roy, C. and Cordy, J. 2008. NICAD: Accurate Detection of Near- Miss Intentional Clones Using Flexible Pretty-Printing and Code Normalization. 2008 16th iEEE international conference on program comprehension 172–181.
2d5fbbb50a8215acefbc49f7c4d36115 ; [38] Roy, C.K. 2009. Detection and Analysis of Near-Miss Software Clones. Queen’s University.
03ea422f6922eedc632b2d40a4561aac ; [40] Subramanyam, R. and Krishnan, M. 2003. Empirical analysis of CK metrics for object-oriented design complexity: implications for software defects. IEEE Transactions on Software Engineering. 29, 4 (Apr. 2003), 297–310. DOI:https://doi.org/10.1109/TSE.2003.1191795.
6908a0aaf9ebcec36a43268f13739696 ; [42] Tao, Y. et al. 2014. Automatically generated patches as debugging aids: a human study. Proceedings of the international symposium on foundations of software engineering 64–74.
898503ddd8cb661b79fea82850d37cba ; [44] Tin Kam Ho 1998. The random subspace method for constructing decision forests. IEEE Transactions on Pattern Analysis and Machine Intelligence. 20, 8 (1998), 832–844. DOI:https://doi.org/10.1109/ 34.709601.
c852c0b37bccdbce6508cc14517bb30d ; [45] Wettel, R. and Marinescu, R. 2005. Archeology of code duplication: recovering duplication chains from small duplication fragments. Proceedings of the seventh international symposium on symbolic and numeric algorithms for scientific computing 63–71.
35f854255eae1a01dd35d7e18287d902 ; [1] 2020. Eclipse JDT adn Eclipse Platform. Website. https://git.eclipse.org/r/.
702589e56c761c751b93b66d6f044ceb ; [2] 2020. Gerrit Code ReviewWebsite. Website. https://www.gerritcodereview.com/.
605a467f437860fb01aad3aa7b3886c8 ; [3] 2020. Golang Code Review Website. Website. https://go-review.googlesource. com/.
d4ba7a31a6afcb2d23b2a42a9cd15aca ; [4] 2020. OpenStack Code Review Website. Website. https://review.opendev.org/.
554362b7c233c966502f06625fc0ac27 ; [5] 2020. QT Code Review Website. Website. https://codereview.qt-project.org/.
526d98625ef3777c7355167b4b43af34 ; [10] Geanderson Esteves, Eduardo Figueiredo, Adriano Veloso, Markos Viggiato, and Nivio Ziviani. 2020. Understanding machine learning software defect predictions. Automated Software Engineering 27, 3 (2020), 369ś392.
b5d65ea1eeb18fa6a26f6f67f13546a4 ; [12] John Fox. 1997. Applied regression analysis, linear models, and related methods. Sage Publications, Inc.
4ebc45bef3ca089c4fa50315b7320756 ; [16] Steffen Herbold, Alexander Trautsch, Fabian Trautsch, and Benjamin Ledel. 2019. Issues with SZZ: An empirical assessment of the state of practice of defect prediction data collection. arXiv preprint arXiv:1911.08938 (2019).
67fb168bdc4e49b83703a341f07f8338 ; [36] Hung Viet Pham, Shangshu Qian, Jiannan Wang, Thibaud Lutellier, Jonathan Rosenthal, Lin Tan, Yaoliang Yu, and Nachiappan Nagappan. 2020. Problems and Opportunities in Training Deep Learning Software Systems: An Analysis of Variance. In 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 771ś783.
d25033ceca44a00c1d66352cad58abff ; [24] Gema Rodríguez-Pérez, Gregorio Robles, and Jesús M. González-Barahona. 2018. Reproducibility and credibility in empirical software engineering: A case study based on a systematic literature review of the use of the SZZ algorithm. Information and Software Technology 99 (2018), 164 – 176. https: //doi.org/10.1016/j.infsof.2018.03.009
62add074353a76871a41d14be5b29374 ; [39] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. 2017. Grad-cam: Visual explanations from deep networks via gradient-based localization. In Proceedings of the IEEE international conference on computer vision. 618ś626.
b8b7ced2ee7c619382d4e60c68805594 ; [40] Asaf Shabtai, Yuval Elovici, and Lior Rokach. 2012. A survey of data leakage detection and prevention solutions. Springer Science & Business Media.
1604dfca88ea08233835b3ec36231730 ; [41] Jacek Śliwerski, Thomas Zimmermann, and Andreas Zeller. 2005. When do changes induce fixes? ACM sigsoft software engineering notes 30, 4 (2005), 1ś5.
89752cd3f0536094420627f8ab38e33e ; [42] Sadia Tabassum, Leandro L Minku, Danyi Feng, George G Cabral, and Liyan Song. [n.d.]. An Investigation of Cross-Project Learning in Online Just-In-Time Software Defect Prediction. ([n. d.]).
a7890ef5c7df6420fb25fdb9e8db6ea3 ; [52] Steven Young, Tamer Abdou, and Ayse Bener. 2018. A replication study: justin- time defect prediction with ensemble learning. In Proceedings of the 6th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering. 42ś47. https://doi.org/10.1145/3194104.3194110
3be65dcb46bc2335a0cd8db68f259d85 ; [53] Motahareh Bahrami Zanjani, Huzefa Kagdi, and Christian Bird. 2015. Automatically recommending peer reviewers in modern code review. IEEE Transactions on Software Engineering 42, 6 (2015), 530ś543.
15184a5bb530e9e961b654ef521e2ddc ; 1. Hall GA, Munson JC. Software evolution: code delta and code churn. J Syst Softw. 2000;54(2):111-118.
e1671797c52e15f763380b45e841ec32 ; 4. Qiao L, Wang Y. Effort-aware and just-in-time defect prediction with neural network. PLoS ONE. 2019;14(2):e0211359.
2ec2bb073d6fa995993ac791bd3eed7c ; 5. Yu X, Bennin KE, Liu J, Keung JW, Yin X, Xu Z. An Empirical Study of Learning to Rank Techniques for Effort-Aware Defect Prediction. In: 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER); 2019: 298–309.
d190c4639d046ee2f9a136ec5828b06a ; 7. Czerwonka J, Das R, Nagappan N, Tarvo A, Teterev A. Crane: Failure prediction, change analysis and test prioritization in practice–experiences from windows. In: 2011 Fourth IEEE International Conference on Software Testing, Verification and Validation; 2011: 357–366.
f3c68bab26311d714a69d5b616d763e4 ; 8. Tan M, Tan L, Dara S, Mayeux C. Online defect prediction for imbalanced data. In: 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering. 2015: 99–108.
bd6336cb550dd454ea8b5a35a1bab86d ; 10. Yan M, Xia X, Fan Y, Lo D, Hassan AE, Zhang X. Effort-aware just-in-time defect identification in practice: a case study at Alibaba. In: Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 2020: 1308–1319.
90c5ff35b462bd981687b00160b6d9bc ; 11. Tantithamthavorn C, Hassan AE. An experience report on defect modelling in practice: Pitfalls and challenges. In: Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice. 2018: 286–295.
ce803e2b74dbd7c111a890a27f6128f5 ; 12. Marijan D, Gotlieb A. Industry-Academia research collaboration in software engineering: The Certus model. Inf Softw Technol. 2021;132:106473.
b13b38558bcf5a9b0ef5800417aee5d1 ; 13. Kamei Y, Shihab E. Defect prediction: Accomplishments and future challenges. In: 2016 IEEE 23rd international conference on software analysis, evolution, and reengineering (SANER). 2016: 33–45.
3aae80fde96b427cd3293497195c57cb ; 14. Kang J, Ryu D, Baik J. Predicting just-in-time software defects to reduce post-release quality costs in the maritime industry. Softw: Pract Exp. 2021; 51(4):748-771.
1f1a12a2d1577a7165e30ebb2c25b9d7 ; 15. Khanan C, Luewichana W, Pruktharathikoon K, et al. JITBot: An Explainable Just-In-Time Defect Prediction Bot. In: 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE). 2020: 1336–1339.
217ec95b448cdbea45c23547d534f556 ; 17. Bangash AA, Sahar H, Hindle A, Ali K. On the Time-Based Conclusion Stability of Software Defect Prediction Models. CoRR 2019.
d9b8929e7ec376473794ab5174b24e93 ; 18. Eken B, Atar R, Sertalp S, Tosun A. Predicting Defects with Latent and Semantic Features from Commit Logs in an Industrial Setting. In: 2019 34th IEEE/ACM International Conference on Automated Software Engineering Workshop (ASEW). 2019: 98–105.
833cbd8008989d2117854fb4afa9ff65 ; 19. Cabral GG, Minku LL, Shihab E, Mujahid S. Class imbalance evolution and verification latency in just-in-time software defect prediction. In: 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). 2019: 666–676.
5ed37bef7c05e685759125a04b862c2e ; 21. Radjenovic D, Hericko M, Torkar R, Živkovic A. Software fault prediction metrics: A systematic literature review. Inf Softw Technol. 2013;55(8):1397- 1418.
23a303977b57a2c96bda2c0d681a685a ; 25. Shihab E, Hassan AE, Adams B, Jiang ZM. An industrial study on the risk of software changes. In: Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering. 2012: 1–11.
1b6c989ba27cb0a549900d6e58d51188 ; 27. Ghotra B, McIntosh S, Hassan AE. Revisiting the impact of classification techniques on the performance of defect prediction models. In:. 1 of 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering. IEEE. 2015: 789–800.
23abbec780b8cf8e233d8ba5ae331254 ; 30. Pornprasit C, Tantithamthavorn C. JITLine: A Simpler, Better, Faster, Finer-grained Just-In-Time Defect Prediction. arXiv preprint arXiv:2103.07068 2021.
e5fc3d44f0b33b93f30c165643012d48 ; 32. Catolino G, Di Nucci D, Ferrucci F. Cross-project just-in-time bug prediction for mobile apps: an empirical assessment. In: 2019 IEEE/ACM 6th International Conference on Mobile Software Engineering and Systems (MOBILESoft). 2019: 99–110.
eebda289b4b0d8e08bd36230e10a84ea ; 33. Barnett JG, Gathuru CK, Soldano LS, McIntosh S. The relationship between commit message detail and defect proneness in java projects on github. In: 2016 IEEE/ACM 13th Working Conference on Mining Software Repositories (MSR). 2016: 496–499.
32cb6abce0fd6ba940e30fbea70f8d59 ; 34. Yang X, Lo D, Xia X, Zhang Y, Sun J. Deep learning for just-in-time defect prediction. In: 2015 IEEE International Conference on Software Quality, Reliability and Security. IEEE; 2015: 17–26.
21c6f34d416f61526caec62e0d35dcd1 ; 35. Hoang T, Dam HK, Kamei Y, Lo D, Ubayashi N (2019) Deepjit: an end-to-end deep learning framework for just-in-time defect prediction. In 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), pp 34–45. IEEE
c59350679eb05e100ccbb378d5edfde6 ; 38. Jiang T, Tan L, Kim S. Personalized defect prediction. In: Automated Software Engineering (ASE), 2013 IEEE/ACM 28th International Conference on. 2013: 279–289.
f801c97078e393cc8ff9cc463306a485 ; 39. Young S, Abdou T, Bener A. A replication study: just-in-time defect prediction with ensemble learning. In: Proceedings of the 6th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering. 2018: 42–47.
0de5a42128fe566d245a1277e8e5806d ; 41. Shalev-Shwartz S, Ben-David S. Understanding machine learning: From theory to algorithms. Cambridge University Press; 2014.
3fdeba9384590ee2416d63a0c52aa41c ; 42. Kim S, Whitehead Jr EJ. How long did it take to fix bugs?. In: Proceedings of the 2006 international workshop on Mining software repositories. 2006: 173–174.
7fa3b767c460b54a2be4d49030b349c7 ; 43. Śliwerski J, Zimmermann T, Zeller A. When do changes induce fixes? In: No. 4 in ACM sigsoft software engineering notes. ACM; 2005:1-5.
8e4bc57901c8aec3bcd288edb9b7a8c6 ; 45. Matsumoto S, Kamei Y, Monden A, Matsumoto K, Nakamura M. An analysis of developer metrics for fault prediction. In: Proceedings of the 6th International Conference on Predictive Models in Software Engineering. ACM. 2010: 18.
fac2d66dafe5f969a4089b5d21a5f816 ; 46. Nagappan N, Ball T. Use of relative code churn measures to predict system defect density. In: Software Engineering, 2005. ICSE 2005. Proceedings. 27th International Conference on. 2005: 284–292.
8efa630591222b639f90d2bfc1d811a0 ; 47. D'Ambros M, Lanza M, Robbes R. An extensive comparison of bug prediction approaches. In: 2010 7th IEEE Working Conference on Mining Software Repositories (MSR 2010). 2010: 31–41.
2bcc6730c2bbab606c0693282175424c ; 48. Nagappan N, Ball T, Zeller A. Mining metrics to predict component failures. In: Proceedings of the 28th international conference on Software engineering. 2006: 452–461.
768a1b10dd46fed38dfa2c6176cd2011 ; 51. Murphy KP. Machine learning: a probabilistic perspective. MIT Press; 2012.
e20813e75221c7ac2198d7add192bdc1 ; [34] E. Alpaydin, Introduction to machine learning. MIT press, 2009.
990fdafa5a2ccb84e05b554d34531f27 ; 58. Davis J, Goadrich M. The relationship between Precision-Recall and ROC curves. In: Proceedings of the 23rd international conference on Machine learning. 2006: 233–240.
6c0c6f145f4bf5da8d9d8832843c7457 ; 62. Chawla NV, Bowyer KW, Hall LO, Kegelmeyer WP. SMOTE: synthetic minority over-sampling technique. J Artif Intell Res. 2002;16:321-357.
0f40054b234829d75ad56a1e2087ebcd ; 63. Guillamet D, Vitrià J. Non-negative matrix factorization for face recognition. In: Catalonian Conference on Artificial Intelligence. Berlin, Heidelberg: Springer; 2002:336-344.
557843cd2e0b2430794b65f9898f1917 ; 65. Borg M, Svensson O, Berg K, Hansson D. SZZ Unleashed: An Open Implementation of the SZZ Algorithm - Featuring Example Usage in a Study of Just-in-time Bug Prediction for the Jenkins Project. In: MaLTeSQuE 2019. ACM; 2019: 7–12.
dced2d2278125cf844c3b267ac21e53d ; 66. Fan Y, Xia X, Costa DDA, Lo D, Hassan AE, Li S. The Impact of Changes Mislabeled by SZZ on Just-in-Time Defect Prediction. IEEE Trans Softw Eng. 2019.
01a0df48fc820a5a965082f0d85c168a ; 70. Northcutt C, Jiang L, Chuang I. Confident learning: Estimating uncertainty in dataset labels. J Artif Intell Res. 2021;70:1373-1411.
063db632a46fed3ce53eaf9df7ea392c ; [3] Francis X. Diebold and Roberto S. Mariano. 1995. Comparing Predictive Accuracy. Journal of Business & Economic Statistics 13, 3 (1995), 253–263. https://doi.org/10.1080/07350015.1995.10524599 arXiv:https://amstat.tandfonline.com/doi/pdf/10.1080/07350015.1995.10524599
94ee31c852978dbf96eed92c4a1278c3 ; [5] Tilmann Gneiting and Adrian E Raftery. 2007. Strictly Proper Scoring Rules, Prediction, and Estimation. J. Amer. Statist. Assoc. 102, 477 (2007), 359–378. https://doi.org/10.1198/016214506000001437 arXiv:https://doi.org/10.1198/016214506000001437
850841c9fc6202082145e1afc8856802 ; [8] David J. Hand. 2009. Measuring Classifier Performance: A Coherent Alternative to the Area Under the ROC Curve. Mach. Learn. 77, 1 (Oct. 2009), 103–123. https://doi.org/10.1007/s10994-009-5119-5
d83c0bed0071cd7bbdaa1d7df4c6c5da ; [11] Malley JD, Kruppa J, Dasgupta A, Malley KG, and Ziegler A. 2012. Probability machines: consistent probability estimation using nonparametric learning machines. Methods of Information in Medicine 51, 1 (2012), 74–81.
ab4ec5d2d2addcc088c97bbdfda35f39 ; [15] S. Kim, E. J. Whitehead, Jr., and Y. Zhang. 2008. Classifying Software Changes: Clean or Buggy? IEEE Transactions on Software Engineering 34, 2 (March 2008), 181–196. https://doi.org/10.1109/TSE.2007.70773
a444790a7c497e5a7e4c6115bff3a10c ; [23] Foyzur Rahman, Daryl Posnett, Israel Herraiz, and Premkumar Devanbu. 2013. Sample Size vs. Bias in Defect Prediction. In Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering (ESEC/FSE 2013). ACM, New York, NY, USA, 147–157. https://doi.org/10.1145/2491411.2491418
c33a79ddc7495da3178336f909e782c0 ; [25] Shaoqing Ren, X. Cao, YichenWei, and J. Sun. 2015. Global refinement of random forest. In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 723–730. https://doi.org/10.1109/CVPR.2015.7298672
88a4eeb9ac1d361693f54791b0831034 ; [26] Carolin Strobl, Anne-Laure Boulesteix, Achim Zeileis, and Torsten Hothorn. 2007. Bias in random forest variable importance measures: illustrations, sources and a solution. BMC Bioinformatics 8, 25 (Oct. 2007), 1–25.
5488cc99a22c6150d13b3967e2a7d295 ; [7] S. Jiang,Y.Wu, andY. Fu, “Deep bi-directional cross-triplet embedding for cross-domain clothing retrieval,” in Proc. 24th ACMInt. Conf. Multimedia, 2016, pp. 52–56.
bd1cf62b4858e5ebb84cb41bf8dde454 ; [13] P. Tourani and B. Adams, “The impact of human discussions on just-intime quality assurance: An empirical study on openstack and eclipse,” in Proc. 23rd Int. Conf. Softw. Anal. Evol. Reengineering, 2016, vol. 1, pp. 189–200.
ab0057a5e54dc3851046278d4708c1fb ; [22] E. Shihab, Y. Kamei, B. Adams, and A. E. Hassan, “Is lines of code a good measure of effort in effort-aware models?” Inf. Softw. Technol., vol. 55, no. 11, pp. 1981–1993, 2013.
49d21ef5b21f99d52fb491c5d57c5f49 ; [24] Y.Yang et al., “An empirical study on dependence clusters for effort-aware fault-proneness prediction,” in Proc. 31st Int. Conf. Automated Softw. Eng., 2016, pp. 296–307.
39ed7734f435c9f8d9fb8c2807dc1e1d ; [25] K. E. Bennin, J. Keung, A. Monden, Y. Kamei, and N. Ubayashi, “Investigating the effects of balanced training and testing datasets on effort-aware fault prediction models,” in Proc. 40th Annu. Comput. Softw. Appl. Conf., 2016, vol. 1, pp. 154–163.
8f067faac8f405fb979b80ee07903ed9 ; [26] W. Ma, L. Chen, Y. Yang, Y. Zhou, and B. Xu, “Empirical analysis of network measures for effort-aware fault-proneness prediction,” Inf. Softw. Technol., vol. 69, pp. 50–70, 2016.
42f3e1ea1be97c3d1fd0729c637e965f ; [28] X. Yu, K. E. Bennin, J. Liu, J. W. Keung, X. Yin, and Z. Xu, “An empirical study of learning to rank techniques for effort-aware defect prediction,” in Proc. 26th Int. Conf. Softw. Anal., Evol. Reengineering, 2019, pp. 298–309.
446a7d9148fde3b12345946a450ed1c8 ; [29] S. Albahli, “A deep ensemble learning method for effort-aware just-in-time defect prediction,” Future Internet, vol. 11, no. 12, pp. 1–13, 2019.
ea241eb7488297011baa0860dee272bf ; [37] N. Gayatri, S. Nickolas, and A. Reddy, “A frame work for business defect predictions in mobiles,” Int. J. Comput. Appl., vol. 975, pp. 39–44, 2013.
aaf14e8b362be8d1148eccc6355553ee ; [38] Y. Fan, X. Cao, J. Xu, S. Xu, and H. Yang, “High-frequency keywords to predict defects for android applications,” in Proc. 42nd Annu. Comput. Softw. Appl. Conf., 2018, vol. 2, pp. 442–447.
7fe3b1284d2414eb78016b26bbc457a3 ; [41] L. Qiao, X. Li, Q. Umer, and P. Guo, “Deep learning based software defect prediction,” Neurocomputing, vol. 385, pp. 100–110, 2020.
5721dfc6e4298ede91d707c33ef94ca4 ; [42] A. Hasanpour, P. Farzi, A. Tehrani, and R. Akbari, “Software defect prediction based on deep learning models: Performance study,” 2020, arXiv:2004.02589.>
c85a032af831c6b47d023ac2240f6b82 ; [46] H. K.Damet al., “A deep tree-based model for software defect prediction,” 2018, arXiv:1802.00921.
8c01f4a154deadcf65fff328ae4adcb6 ; [48] D. Chen, X. Chen, H. Li, J. Xie, and Y. Mu, “DeepCPDP: Deep learning based cross-project defect prediction,” IEEE Access, vol. 7, pp. 184 832– 184848, 2019.
9b773d8d33c4657949dfbf1502b3cdbd ; [49] G. Fan, X. Diao, H. Yu, K. Yang, and L. Chen, “Deep semantic feature learning with embedded static metrics for software defect prediction,” in Proc. 26th Asia-Pacific Softw. Eng. Conf., 2019, pp. 244–251.
5aa9921d468a03bd9a33c8430cae47a5 ; [50] S. Jiang, Y. Wu, and Y. Fu, “Deep bidirectional cross-triplet embedding for online clothing shopping,” ACMTrans. Multimedia Comput.,Commun. Appl., vol. 14, no. 1, pp. 1–22, 2018.
992bf878ecef025ac6967d34e0211ac5 ; [56] J. Nam,W. Fu, S. Kim, T. Menzies, and L. Tan, “Heterogeneous defect prediction,” IEEE Trans. Softw. Eng., vol. 44, no. 9, pp. 874–896, Sep. 2018.
af4a41fcf9e4c4856bccaf787747151b ; [61] S. Herbold, A. Trautsch, and J. Grabowski, “A comparative study to benchmark cross-project defect prediction approaches,” IEEE Trans. Softw. Eng., vol. 44, no. 9, pp. 811–833, Sep. 2018.
470ee7828ca0419aa3a972854fe65f17 ; [65] X. Yu, P. Zhou, J. Zhang, and J. Liu, “A data filtering method based on agglomerative clustering,” in Proc. 29th Int. Conf. Softw. Eng. Knowl. Eng., 2017, pp. 392–397.
deaf2f58be92568d5785a7fca22a17b1 ; [66] P. He, B. Li, and Y. Ma, “Towards cross-project defect prediction with imbalanced feature sets,” 2014, arXiv:1411.4228.
6a065adad516004e3cdcf0d8e2780d68 ; [68] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang, “Domain adaptation via transfer component analysis,” Trans. Neural Netw., vol. 22, no. 2, pp. 199–210, 2011.
4e36aae0ec997b606e9978c5b2fb9522 ; [70] M. Long, J.Wang, G. Ding, J. Sun, and P. S. Yu, “Transfer feature learning with joint distribution adaptation,” in Proc. 14th Int. Conf. Comput. Vis., 2013, pp. 2200–2207.
155ca1eb144a62c0dec8b64c3492a97c ; [73] D. Di Nucci, F. Palomba, and A. De Lucia, “Evaluating the adaptive selection of classifiers for cross-project bug prediction,” in Proc. 6th Int. Workshop Realizing Artif. Intell. Synergies Softw. Eng., 2018, pp. 48–54.
520efb1a8d3abc76c684999e73e73db3 ; [75] Z. Xu et al., “Identifying crashing fault residence based on cross project model,” in Proc. 30th Int. Symp. Softw. Rel. Eng., 2019, pp. 183–194.
a1447d339ee98989c8202207a0837d81 ; [76] H. Chen, X.-Y. Jing, Z. Li, D. Wu, Y. Peng, and Z. Huang, “An empirical study on heterogeneous defect prediction approaches,” IEEE Trans. Softw. Eng., 2020, doi: 10.1109/TSE.2020.2968520.
9dc6c8f11c66c9bcc6f52d09d64baac1 ; [77] R. Ferenc, P. Gyimesi, G. Gyimesi, Z. Tóth, and T. Gyimóthy, “An automatically created novel bug dataset and its validation in bug prediction,” J. Syst. and Softw., vol. 169, 2020, Art. no. 110691.
9b2872b367be279618320fa283be0a64 ; [4] D. Sharma and P. Chandra, “Efficient fault prediction using exploratory and causal techniques,” in 2018 Second World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4). IEEE, 2018, pp. 193–197.
00fb5210210296573647fa98ad89a7cf ; [8] J. Sola and J. Sevilla, “Importance of input data normalization for the application of neural networks to complex industrial problems,” IEEE Transactions on nuclear science, vol. 44, no. 3, pp. 1464–1468, 1997.
6b9e626599aa9a6b5d9189b3f59bb460 ; [10] Y. A. Alshehri, K. Goseva-Popstojanova, D. G. Dzielski, and T. Devine, “Applying machine learning to predict software fault proneness using change metrics, static code metrics, and a combination of them,” in SoutheastCon 2018. IEEE, 2018, pp. 1–7.
dde4cda90c27ef7ab57baac23631fc3b ; [11] K. Beck, M. Fowler, and G. Beck, “Bad smells in code,” Refactoring: Improving the design of existing code, vol. 1, pp. 75–88, 1999.
d7950ce3e15dffb513efd14c1ad053ce ; [12] G. Catolino, F. Palomba, F. A. Fontana, A. De Lucia, A. Zaidman, and F. Ferrucci, “Improving change prediction models with code smellrelated information,” Empirical Software Engineering, vol. 25, no. 1, pp. 49–95, 2020.
ce887aaa6d5ab27837c758a99dc69117 ; [13] K. Muthukumaran, A. Choudhary, and N. B. Murthy, “Mining github for novel change metrics to predict buggy files in software systems,” in 2015 International Conference on Computational Intelligence and Networks. IEEE, 2015, pp. 15–20.
b5e6c0b01f1c2373b2f09abe8fd2aba2 ; [14] A. Bacchelli, M. D’Ambros, and M. Lanza, “Are popular classes more defect prone?” in International Conference on Fundamental Approaches to Software Engineering. Springer, 2010, pp. 59–73.
965775e6b5a3f578ff40b91e01638d63 ; Bryant RE, O’Hallaron DR (2015) Computer Systems: A Programmer’s Perspective, 3rd ed. Pearson
8134b84030cca5285ed0e0b31ba06f10 ; Catolino G (2017) Just-in-time bug prediction in mobile applications: The domain matters! pp 05
9e23bb492a5795ae22d466e8f2e68eea ; Chen J, ShangW(2017) An exploratory study of performance regression introducing code changes. In: 2017 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp 341–352
b21757ab65399adf310880b3989f3c05 ; Chen T.-H., Shang W, Jiang ZM, Hassan AE, Nasser M, Flora P (2014) Detecting performance anti-patterns for applications developed using object-relational mapping. In: Proceedings of the 36th International Conference on Software Engineering, ser. ICSE 2014. Association for Computing Machinery, New York, pp 1001–1012. [Online]. Available: https://doi.org/10.1145/2568225.2568259
af237db58d33b4637f61f674e0418cf9 ; Chen J, Shang W, Shihab E (2020) Perfjit: Test-level just-in-time prediction for performance regression introducing commits. IEEE Trans Softw Eng:1–1
2b1a99c76abea28e411f3e8b79a79eac ; Davies S, Roper M, Wood M (2014) Comparing text-based and dependence-based approaches for determining the origins of bugs. J Softw Evol Process 26:01
6c3bac8fdb681a15e75cfcd722fc0c02 ; Ding Z, Chen J, Shang W (2020) Towards the use of the readily available tests from the release pipeline as performance tests. are we there yet? In: 42nd International Conference on Software Engineering, Seoul
ff0757d2e3fbdf36d43473043ea9ca6a ; [5] T. Fawcett, “An Introduction to ROC analysis”, Pattern Recognition Letters, 26, 2006, pp. 861–874
71a4755c150901c365eefc94ad3f0fd1 ; Hamill M, Goseva-Popstojanova K (2014) Exploring the missing link: An empirical study of software fixes. Softw Test Verif Reliab 24(8):684–705. [Online]. Available: https://doi.org/10.1002/stvr.1518
b4cec1136a99367f99040cde368d2846 ; Jin G, Song L, Shi X, Scherpelz J, Lu S (2012) Understanding and detecting real-world performance bugs. SIGPLAN Not. 47(6):77–88 Jpace jpace/diffj [Online]. Available: https://github.com/jpace/diffj
e3e89d4b57cdde507afeb9dc9cc0784c ; LaToza TD, Venolia G, DeLine R (2006) Maintaining mental models: A study of developer work habits. In: Proceedings of the 28th International Conference on Software Engineering, ser. ICSE ’06. ACM, New York, pp 492–501
0d90a85941cd19cba6b48e331f72f4b6 ; Li H, Shang W, Zou Y, Hassan AE (2018) Towards just-in-time suggestions for log changes (journalfirst abstract). In: 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp 467–467
2774141cd6b05f9e3bd9934ec500f351 ; McDonald JH (2014) Handbook of biological statistics. sparky house publishing Baltimore. MD 3:186–189
509f713c3cd50900ff488a63566c1e7f ; McHughM(2012) Interrater reliability: The kappa statistic, Biochemia medica : ˇc,asopis Hrvatskoga druˇstva medicinskih biokemiˇcara / HDMB, vol 22, pp 276–82, 10
c444f378e21c6fd2644837491fa430e1 ; Molyneaux I (2009) The Art of Application Performance Testing: Help for Programmers and Quality Assurance, 1st ed. O’Reilly Media, Inc.
58b21a134b22a29d4c7f0925d5974fce ; Nayrolles M, Hamou-Lhadj A (2018) Clever: Combining code metrics with clone detection for just-in-time fault prevention and resolution in large industrial projects, pp 03
799beaa5d90d7b219177bc258badc448 ; Neto E, Costa D, Kulesza U (2018) The impact of refactoring changes on the szz algorithm: An empirical study, pp 03
a82b662bacb9118f0360344a23ab1f4d ; Nistor A, Jiang T, Tan L (2013) Discovering, reporting, and fixing performance bugs. in: 2013 10th working conference on mining software repositories (MSR), pp 237–246
14304cd02108ac25d6fa9ca5970ac73f ; Ohira M, Kashiwa Y, Yamatani Y, Yoshiyuki H, Maeda Y, Limsettho N, Fujino K, Hata H, Ihara A, Matsumoto K (2015), A dataset of high impact bugs: Manually-classified issue reports. In: 2015 IEEE/ACM 12th Working Conference on Mining Software Repositories (pp. 518-521). IEEE.
8f4134a7eb9160b5826629e328745085 ; Radu A, Nadi S (2019) A dataset of non-functional bugs. In: Proceedings of the 16th International Conference on Mining Software Repositories, ser. MSR ’19. IEEE Press, Piscataway, pp 399–403
1c745545e27654210ab619be0d429d58 ; Rodrıguez-Perez G., Nagappan M, Robles G (2020) Watch out for extrinsic bugs! a case study of their impact in just-in-time bug prediction models on the openstack project. IEEE Transactions on Software Engineering
fe1888799112b79da79451f84c7a94ed ; Sawilowsky SS (2009) New effect size rules of thumb. J Modern Appl Stat Methods 8(2):26
558434a931eb3eae3de4df5c1b574dde ; Syer MD, Shang W, Jiang ZM, Hassan AE (2017) Continuous validation of performance test workloads. Autom Softw Engg 2(1):189–231. [Online]. Available: https://doi.org/10.1007/s10515-016-0196-8
7b3993ec77f0b815a93fa53004f3f756 ; Tabassum S (2020) An investigation of cross-project learning in online just-in-time software defect prediction, pp 06
1f2e4cd87a1429ee2a60db7342ad2b79 ; Tsakiltsidis S, Miranskyy A, Mazzawi E (2016) On automatic detection of performance bugs. In: 2016 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW), pp 132–139
311db8863fed51b21177efd0bee25e7a ; Zaman S, Adams B, Hassan AE (2011) Security versus performance bugs: A case study on firefox. In: Proceedings of the 8thWorking Conference on Mining Software Repositories, ser. MSR ’11. ACM, New York, pp 93–102
842a105695b0a38f144674e37e17de6e ; Zaman S, Adams B, Hassan AE (2012) A qualitative study on performance bugs, 2012 9th IEEE Working Conference on Mining Software Repositories (MSR), pp 199–208
00b69d3422e2db6957ad12cff3a9ec66 ; [7] Guo Haixiang, Li Yijing, Jennifer Shang, Gu Mingyun, Huang Yuanyue, and Gong Bing. 2017. Learning from class-imbalanced data: Review of methods and applications. Expert Systems with Applications 73 (2017), 220–239.
f0b40f316a6bb9443ce017cf1bf76a72 ; [29] Zhou Xu, Li Li, Meng Yan, Jin Liu, Xiapu Luo, John Grundy, Yifeng Zhang, and Xiaohong Zhang. 2020. A comprehensive comparative study of clustering-based unsupervised defect prediction models. Journal of Systems and Software (JSS) (2020), 110862.
7561185d29cc867588aa09da6a241b9a ; [36] Jingxiu Yao and Martin Shepperd. 2020. Assessing software defection prediction performance: why using the Matthews correlation coefficient matters. In Proceedings of the 24th Evaluation and Assessment in Software Engineering (EASE). 120–129.
d289927649e847ee36f694f7ecb78ffb ; 1. Ackerman LBA, Lewski F (1989) Software inspections: an effective verification process. IEEE Softw 6:31–36. https://doi. org/10.1109/52.28121
44cc026eca4028b6bbec35aabc3457ec ; 2. Ahmad J, Farman H, Jan Z (2019) Deep learning methods and applications, pp 31–42. Springer Singapore. https://doi.org/10. 1007/978-981-13-3459-7_3
44cc026eca4028b6bbec35aabc3457ec ; 4. Ardimento P, Aversano L, Bernardi ML, Cimitile M (2020) Temporal convolutional networks for just-in-time software defect prediction. In M. van Sinderen, H. Fill, L.A. Maciaszek (eds.) Proceedings of the 15th International Conference on Software Technologies, ICSOFT 2020, Lieusaint, Paris, France, July 7-9, 2020, pp 384–393. ScitePress. https://doi.org/10.5220/ 0009890003840393
44cc026eca4028b6bbec35aabc3457ec ; 6. Ardimento P, Bernardi ML, Cimitile M (2018) A multi-source machine learning approach to predict defect prone components. In Proceedings of the 13th International Conference on Software Technologies, ICSOFT 2018, Porto, Portugal, July 26-28, 2018, pp 306–313. https://doi.org/10.5220/0006857803060313
44cc026eca4028b6bbec35aabc3457ec ; 7. Aversano L, Bernardi ML, Cimitile M, Iammarino M, Romanyuk K (2020) Investigating on the relationships between design smells removals and refactorings. In M. van Sinderen, H. Fill, L.A. Maciaszek (eds.) Proceedings of the 15th International Conference on Software Technologies, ICSOFT 2020, Lieusaint, Paris, France, July 7-9, 2020, pp 212–219. ScitePress. https://doi.org/ 10.5220/0009887102120219
44cc026eca4028b6bbec35aabc3457ec ; 9. Barnett JG, Gathuru CK, Soldano LS, McIntosh S (2016) The relationship between commit message detail and defect proneness in java projects on github. In Proceedings of the 13th International Conference on Mining Software Repositories, MSR 2016, Austin, TX, USA, May 14-22, 2016, pp 496–499. https://doi.org/ 10.1145/2901739.2903496
44cc026eca4028b6bbec35aabc3457ec ; 15. Bernardi M, Cimitile M, Martinelli F, Mercaldo F (2018) Driver and path detection through time-series classification. J Adv Transp 2018. https://doi.org/10.1155/2018/1758731
44cc026eca4028b6bbec35aabc3457ec ; 16. Bernardi ML, Cimitile M, Martinelli F, Mercaldo F (2019) Keystroke analysis for user identification using deep neural networks. In 2019 International Joint Conference on Neural Networks (IJCNN), pp 1–8. https://doi.org/10.1109/IJCNN.2019. 8852068
44cc026eca4028b6bbec35aabc3457ec ; 18. Boucher A, Badri M (2016) Using software metrics thresholds to predict fault-prone classes in object-oriented software. In 2016 4th Intl Conf on Applied Computing and Information Technology/ 3rd Intl Conf on Computational Science/Intelligence and Applied Informatics/1st Intl Conf on Big Data, Cloud Computing, Data Science Engineering (ACIT-CSII-BCD), pp 169–176. https://doi.org/10.1109/ACIT-CSII-BCD.2016.042
44cc026eca4028b6bbec35aabc3457ec ; 33. Hassan AE (2009) Predicting faults using the complexity of code changes. In 31st International Conference on Software Engineering, ICSE 2009, May 16-24, 2009, Vancouver, Canada, Proceedings, pp 78–88. https://doi.org/10.1109/ICSE.2009. 5070510
44cc026eca4028b6bbec35aabc3457ec ; 50. Moser R, Pedrycz W, Succi G (2008) A comparative analysis of the efficiency of change metrics and static code attributes for defect prediction. In 30th International Conference on Software Engineering (ICSE 2008), Leipzig, Germany, May 10-18, 2008, pp 181–190. https://doi.org/10.1145/1368088.1368114
44cc026eca4028b6bbec35aabc3457ec ; 64. Vani S, Rao TVM (2019) An experimental approach towards the performance assessment of various optimizers on convolutional neural network. In 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI), pp 331–336. https://doi. org/10.1109/ICOEI.2019.8862686
44cc026eca4028b6bbec35aabc3457ec ; 70. Yang X, Lo D, Xia X, Zhang Y, Sun J (2015) Deep learning for just-in-time defect prediction. In 2015 IEEE International Conference on Software Quality, Reliability and Security, QRS 2015, Vancouver, BC, Canada, August 3-5, 2015, pp 17–26. https://doi. org/10.1109/QRS.2015.14
bf215181b5140522137b3d4f6b73544a ; 3. Aniche M (2015) Java code metrics calculator (CK). Available in https://github.com/mauricioaniche/ck/
22511f77a97e6c3dd0b2ae699e13d0ec ; 12. Bengio Y, Courville A, Vincent P (2014) Representation learning: a review and new perspectives
5ceb0efe2a2d12123112d65383f4a4e0 ; 13. Bergstra J, Bardenet R, Bengio Y, Ke´gl B (2011) Algorithms for hyper-parameter optimization. In Proceedings of the 24th International Conference on Neural Information Processing Systems, NIPS’11, p 2546–2554. Curran Associates Inc., Red Hook, NY, USA
ef3890bb465c67fcd04ae4609eb94482 ; 14. Bergstra J, Yamins D, Cox DD (2013) Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures. In Proceedings of the 30th International Conference on International Conference on Machine Learning - Volume 28, ICML’13, p I–115–I–123. JMLR.org
36bfc76f67d9a8498ec9590f54857cbf ; 17. Bird C, Nagappan N, Murphy B, Gall H, Devanbu PT (2011) Don’t touch my code!: examining the effects of ownership on software quality. In: SIGSOFT/FSE’11 19th ACM SIGSOFT Symposium on the Foundations of Software Engineering (FSE- 19) and ESEC’11: 13rd European Software Engineering Conference (ESEC-13), Szeged, Hungary, September 5-9, 2011, pp 4–14. ACM
560aab6462f6804477fe8299700abb98 ; 19. Brito e Abreu F, Melo W (1996) Evaluating the impact of objectoriented design on software quality. In: Proceedings of the 3rd International Software Metrics Symposium, pp 90–99. https://doi. org/10.1109/METRIC.1996.492446
6e5f91089cd4efebc89f8c2bf0a64673 ; 20. Cabral GG, Minku LL, Shihab E, Mujahid S (2019) Class imbalance evolution and verification latency in just-in-time software defect prediction. In: Proceedings of the 41st International Conference on Software Engineering, ICSE 2019, Montreal, QC, Canada, May 25-31, 2019, pp 666–676. https://doi.org/ 10.1109/ICSE.2019.00076
b2689e5141ea1cafd4a8732ce47e409e ; 21. Chawla NV (2009) Data mining for imbalanced datasets: an overview. In Data mining and knowledge discovery handbook, pp 875–886. Springer
2d27679ae8c6a040babe79efb59711dc ; 22. Chen X, Zhao Y, Wang Q, Yuan Z (2018) Multi: Multi-objective effort-aware just-in-time software defect prediction. Inf Softw Technol 93:1–13
22f83d52decee2a8e95a58caeef39b2f ; 25. Dabic O, Aghajani E, Bavota G (2021) Sampling projects in github for MSR studies. In: Proceedings of the 18th International Conference on Mining Software Repositories, MSR’21, p. To appear. arXiv:2103.04682
94e0b4c7eec58f8aff75c00a131b191f ; 26. Dam HK, Tran T, Pham TTM, Ng SW, Grundy J, Ghose A (2018) Automatic feature learning for predicting vulnerable software components. IEEE Trans Softw Eng
efc3aa34c66af07310c871212ce17d1b ; 27. Ding Z, Xing L (2020) Improved software defect prediction using pruned histogram-based isolation forest. Reliab Eng Syst Saf 204:107170
a591eec3d138881c2a372f5d947a795a ; 28. DAmbros M, Lanza M, Robbes R (2012) Evaluating defect prediction approaches: a benchmark and an extensive comparison. Empir Softw Eng 17(4–5):531–577
42fb242e39584afe34669d770f06117a ; 29. Fischer M, Pinzger M, Gall H (2003) Populating a release history database from version control and bug tracking systems. In 19th International Conference on Software Maintenance (ICSM 2003), The Architecture of Existing Systems, 22-26 September 2003, Amsterdam, The Netherlands, p 23. IEEE Computer Society
78987b0f00be064a6b632d882db30604 ; 30. Graves TL, Karr AF, Marron JS, Siy H (2000) Predicting fault incidence using software change history. IEEE Trans Softw Eng 26(7):653–661
e1ed940264178e83c587bf2240fbbe2b ; 31. Greiler, M., Herzig, K., Czerwonka, J. (2015) Code ownership and software quality: a replication study. In 2015 IEEE/ACM 12th Working Conference on Mining Software Repositories, pp 2–12. 10.1109/MSR.2015.8
da984e42a5899bbdac496ef0cbadcee2 ; 32. Hall MA (1999) Correlation-based feature selection for machine learning. Ph.D. thesis, Department of Computer Science, University of Waikato, The address of the publisher
1f627fa3417741e7ea399b5cddb05883 ; 34. Hilton R J: Java Source Metrics (2009 (accessed January 16, 2020)). Available in https://github.com/rodhilton/jasome
260f31cdcac09efc8ec83db7753ff21c ; 37. Ioffe S, Szegedy C (2015) Batch normalization: Accelerating deep network training by reducing internal covariate shift. In Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37, ICML’15, pp 448–456. JMLR.org. http://dl.acm.org/citation.cfm?id= 3045118.3045167
7f4528d5c372f063ca28d394d6523600 ; 38. Jahanshahi H, Jothimani D, Bas¸ar A, Cevik M (2019) Does chronology matter in jit defect prediction? a partial replication study. In Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering, pp 90–99
0956f79d4d89bb784ce49cfba2324a97 ; 42. Khatri Y, Singh SK (2021) Cross project defect prediction: a comprehensive survey with its swot analysis. Innovations in Systems and Software Engineering pp 1–19
48fe09ee7dddcc092f1613803a89b0c2 ; 45. Mannor S, Peleg D, Rubinstein R (2005) The cross entropy method for classification. In Proceedings of the 22Nd International Conference on Machine Learning, ICML ’05, pp 561–568. ACM, New York, NY, USA
4baf02b17aa5ccd52ec156ed827e7faf ; 46. Misra D M: A self regularized non-monotonic neural activation function (arXiv pre-print, 2019)
ff18b868c8b68815bdaa5f501a27ee0d ; 47. Mitchell TM (1997) Machine learning, 1st edn. McGraw-Hill Inc, New York, NY, USA
c98174929d8b5c2189697b746e68f0a1 ; 49. Moser R, Pedrycz W, Succi G (2008) Analysis of the reliability of a subset of change metrics for defect prediction. In Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement, pp 309–311
b99cd83ff2e7722c64fbc2a96d4a104a ; 51. Myers GJ, Sandler C (2004) The art of software testing. Wiley, Hoboken, NJ, USA
cca2c524936598493964142309686ea8 ; 53. Peters F, Menzies T, Marcus A (2013) Better cross company defect prediction. In 2013 10th Working Conference on Mining Software Repositories (MSR), pp 409–418. IEEE
3f80c4024b42fd19eb026b7cbbdc808f ; 55. Pickerill P, Jungen HJ, Ochodek M, Mackowiak M, Staron M (2020) PHANTOM: curating github for engineered software projects using time-series clustering. Empir Softw Eng 25(4):2897–2929. https://doi.org/10.1007/s10664-020-09825-8
c994e3f662438aefe9a42f87f127e7f1 ; 56. Porto FR, Simao A (2016) Feature subset selection and instance filtering for cross-project defect prediction-classification and ranking. CLEI Electron J 19(3):4
70ba14115e297e6344e9766931a781fa ; 57. Rahman F, Devanbu P (2013) How, and why, process metrics are better. In 2013 35th International Conference on Software Engineering (ICSE), pp 432–441. IEEE
ccca286fb8f3bcaa9f0ace1d3274445c ; 59. Schaul T, Antonoglou I, Silver D (2013) Unit tests for stochastic optimization
c2d9d38ee990675751a1e15f65049df4 ; 60. Spinellis D (2005) Tool writing: a forgotten art? (software tools). IEEE Softw 22(4):9–11. https://doi.org/10.1109/MS.2005.111
f3ca0ea24e25a37c58c1cb24591f590b ; 62. Subramanyam R, Krishnan M (2003) Empirical analysis of ck metrics for object-oriented design complexity: Implications for software defects. IEEE Trans Softw Eng 29:297–310. https://doi. org/10.1109/TSE.2003.1191795
13b6ab2fe0d63c6840687ed5f7756284 ; 63. Sutskever I, Martens J, Dahl G, Hinton G (2013) On the importance of initialization and momentum in deep learning. In Proceedings of the 30th International Conference on International Conference on Machine Learning - Volume 28, ICML’13, pp III– 1139–III–1147. JMLR.org
48b7d768e102c39e8d22e74c83d9881c ; 68. Xu Z, Li S, Xu J, Liu J, Luo X, Zhang Y, Zhang T, Keung J, Tang Y (2019) LDFR: learning deep feature representation for software defect prediction. J Syst Softw. https://doi.org/10.1016/j.jss.2019. 110402
c26be151b7c402f444e5e3c6880a74b3 ; 71. Yang Z, Yang D, Dyer C, He X, Smola A, Hovy E (2016) Hierarchical attention networks for document classification. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp 1480–1489. Association for Computational Linguistics, San Diego, California. https://doi.org/ 10.18653/v1/N16-1174. https://www.aclweb.org/anthology/N16- 1174
e5a6de929564aab904b1ebe382c6b919 ; 73. Zimmermann T, Nagappan N, Gall H, Giger E, Murphy B (2009) Cross-project defect prediction: a large scale experiment on data vs. domain vs. process. In Proceedings of the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering, pp 91–100
966d316aa446821a39b8c931b1c177d3 ; [1] M. Dsouza, “5 ways artificial intelligence is upgrading software engineering,” https://hub.packtpub.com/5-ways-artificial-intelligence-isupgrading- software-engineering/, 2018, [Online; accessed 9-July-2019].
d20c3f1e8e6b988a336af5b869b77002 ; [2] T. Menzies and T. Zimmermann, “Software analytics: Whats next?” IEEE Software, vol. 35, no. 5, pp. 64–70, 2018.
ea42d4c54010a19aa583df645b51d23f ; [3] M. Felleisen, R. B. Findler, M. Flatt, S. Krishnamurthi, E. Barzilay, J. McCarthy, and S. Tobin-Hochstadt, “The racket manifesto,” in 1st Summit on Advances in Programming Languages (SNAPL), vol. 32, 2015, pp. 113–128.
e64b0b627d9d849f0e6180a600dac0b6 ; [4] A. Scott, J. Bader, and S. Chandra, “Getafix: Learning to fix bugs automatically,” arXiv preprint arXiv:1902.06111, 2019.
0348a8b19055bfc3bbaa28df9c1fa6c2 ; [5] S. Ali, L. C. Briand, H. Hemmati, and R. K. Panesar-Walawege, “A systematic review of the application and empirical investigation of search-based test case generation,” IEEE Transactions on Software Engineering, vol. 36, no. 6, pp. 742–762, 2009.
eaa9409a4cd04a0ec115447f66060b87 ; [6] G. Catolino, F. Palomba, A. Zaidman, and F. Ferrucci, “Not all bugs are the same: Understanding, characterizing, and classifying bug types,” Journal of Systems and Software, vol. 152, pp. 165–181, 2019.
8441f19d3d5aabff8b838068076d7d48 ; [8] D. Radjenovi´c, M. Heriˇcko, R. Torkar, and A. ˇ Zivkoviˇc, “Software fault prediction metrics: A systematic literature review,” Information and Software Technology, vol. 55, no. 8, pp. 1397–1418, 2013.
b58f2b7e4f69f54eca38182165508b3a ; [9] B. Caglayan, A. Bener, and S. Koch, “Merits of using repository metrics in defect prediction for open source projects,” in ICSE Workshop on Emerging Trends in Free/Libre/Open Source Software Research and Development, 2009, pp. 31–36.
4e223b91afa42e09587e3c709776f299 ; [10] C. Bird, N. Nagappan, H. Gall, B. Murphy, and P. Devanbu, “Putting it all together: Using socio-technical networks to predict failures,” in 20th International Symposium on Software Reliability Engineering, 2009, pp. 109–119.
3f210ec938cb656f61fcbf8a6d16e87e ; [16] T. T. Nguyen, T. N. Nguyen, and T. M. Phuong, “Topic-based defect prediction (nier track),” in Proc. of 33rd Int. Conf. on Software Engineering, 2011, pp. 932–935.
ff93582e52e5ee6819e3db86d5a94faa ; [18] D. D. Lee and H. S. Seung, “Learning the parts of objects by nonnegative matrix factorization,” Nature, vol. 401, no. 6755, p. 788, 1999.
f83520c1853719cff9cbae8de578d314 ; [19] D. M. Blei, A. Y. Ng, and M. I. Jordan, “Latent dirichlet allocation,” Journal of machine Learning research, vol. 3, no. Jan, pp. 993–1022, 2003.
10a951496ba94498060ba318bef7d979 ; [20] A. G´omez-R´ıos, J. Luengo, and F. Herrera, “A study on the noise label influence in boosting algorithms: Adaboost, gbm and xgboost,” in Int. Conf. on Hybrid Artificial Intelligence Systems, 2017, pp. 268–280.
410407b40e29648987b6a8b226489ecb ; [21] E. Sahal and A. Tosun, “Identifying bug-inducing changes for code additions,” in Proc. of 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, 2018, p. 57.
f0218a7e46794d3067c507c35a5df0b6 ; [22] J.-S. Zhang, C.-P. Wang, and Y.-Q. Yang, “Learning latent features by nonnegative matrix factorization combining similarity judgments,” Neurocomputing, vol. 155, pp. 43–52, 2015.
632f40dd5f124d7bc4b711d624fabac6 ; [23] J. Shen and P. Li, “Learning structured low-rank representation via matrix factorization,” in Artificial Intelligence and Statistics, 2016, pp. 500–509.
ee831f1bf1bf93f934b57fb740b46d0f ; [25] J. C. Campbell, A. Hindle, and E. Stroulia, “Latent dirichlet allocation: extracting topics from software engineering data,” in The art and science of analyzing software data. Elsevier, 2015, pp. 139–159.
06916d9034e1194e96e5e007b11f4b17 ; [31] V. Sandulescu and M. Chiru, “Predicting the future relevance of research institutions-the winning solution of kdd cup 2016,” arXiv preprint arXiv:1609.02728, 2016.
ea7125b86ca434e95f5f0371048aa56b ; [32] H. Altinger, S. Herbold, F. Schneemann, J. Grabowski, and F. Wotawa, “Performance tuning for automotive software fault prediction,” in 24th Int. Conf. on Software Analysis, Evolution and Reengineering (SANER), 2017, pp. 526–530.
eea1c62a8a34af4b4f220aa729db1a46 ; [33] S. E. Sahin and A. Tosun, “A conceptual replication on predicting the severity of software vulnerabilities,” in Proc. of Evaluation and Assessment on Software Engineering, 2019, pp. 244–250.
467d7c5f09d955f8b9beeee70d62c46c ; [35] B. W. Matthews, “Comparison of the predicted and observed secondary structure of t4 phage lysozyme,” Biochimica et Biophysica Acta (BBA)- Protein Structure, vol. 405, no. 2, pp. 442–451, 1975.
70493a5fb848b3aec2c69159b1686fad ; [36] J. A. Hanley and B. J. McNeil, “The meaning and use of the area under a receiver operating characteristic (roc) curve.” Radiology, vol. 143, no. 1, pp. 29–36, 1982.
715a615033d8866fecf9b6137e9a56a3 ; [39] B. Eken, “Assessing personalized software defect predictors,” in Proc. of 40th Int. Conf. on Software Engineering, 2018, pp. 488–491.
11dc06b2beb627f9d9e9daf3edc742be ; [40] T.-H. Chen, S. W. Thomas, M. Nagappan, and A. E. Hassan, “Explaining software defects using topic models,” in 9th IEEE Working Conference on Mining Software Repositories (MSR), 2012, pp. 189–198.
4116dd423b4fb091786f87a1ea6addc2 ; [41] M. S. Khan, “A topic modeling approach for code clone detection,” Master’s thesis, Univ. of North Florida, 2019.
483980797051448dfa749de0e79d08f0 ; [42] H. U. Asuncion, A. U. Asuncion, and R. N. Taylor, “Software traceability with topic modeling,” in ACM/IEEE 32nd Int. Conf. on Software Engineering, vol. 1, 2010, pp. 95–104.
fe06c6bce5759b40edaae794ce62d9d3 ; [43] D. Guillamet and J. Vitri`a, “Non-negative matrix factorization for face recognition,” in Catalonian Conference on Artificial Intelligence, 2002, pp. 336–344.
327931e96af0f830cf3e73f0da21d361 ; [44] Y. Koren, R. Bell, and C. Volinsky, “Matrix factorization techniques for recommender systems,” IEEE Computer, no. 8, pp. 30–37, 2009.
9bd73673b12d77780991ec7d51bd7bc8 ; [45] O¨ . Bozcan and A. B. Bener, “Handling missing attributes using matrix factorization,” in 2nd International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering (RAISE), 2013, pp. 49– 55.
d8a34afd87cad8ae1727b13d2a2fe7f1 ; [46] R. Chang, X. Mu, and L. Zhang, “Software defect prediction using nonnegative matrix factorization,” Journal of Software, vol. 6, no. 11, pp. 2114–2120, 2011.
919894fbfc3419351b1702b2cd7d599c ; [2] N. Nagappan, B. Murphy, V. Basili, “The influence of organizational structure on software quality”, Proc. ICSE’08, pp. 521-530, 2010
35dd9ed075365c1341c48a684d7a86ad ; [3] A. Tarvo, “Using Statistical Models to Predict Software Regressions”, Proc. ISSRE’08, pp. 259-264, 2008
9c9638c7bad630c94b5dd7e896dce4d9 ; [4] A. Tarvo, T. Zimmermann, J. Czerwonka, “An Integration Resolution Algorithm for Mining Multiple Branches in Version Control Systems”, Proc. ICSM’11, pp. 402-411, 2011
1012622bee70ca67170a95f5f8f103df ; [6] Hand D.J., Mannila H., Smyth P., “Principles of Data Mining”, The MIT Press, 2001
f8046cf66d75a5f28f59c39775a96853 ; [7] Larose D. T., “Data Mining Methods and Models”, Wiley-Interscience, Hoboken, NJ , 2006
02e78272feeeee1166b28d9fa63450b8 ; [8] M. Sumner, E. Frank, M. Hall, “Speeding up Logistic Model Tree Induction”, Proc. ECML-PKDD’05, pp. 675-683, 2005.
07f85aaede543ef4657c2c4636896b25 ; [19] A. Hassan, “Predicting Faults Using Complexity of Code Changes”, Proc. ICSE’09, pp. 78-88, 2009
7abc217d63c53a42b31671cc1950547a ; [21] S. Kim, T. Zimmermann, E. Whitehead, A. Zeller, “Predicting Faults from Cacned History”, Proc. ICSE’07, pp. 489-498, 2007
9fbbde4d0388e340e1eb2504b3194c2b ; [22] A. Mockus, R. Fielding, J. Herbsleb, “A Case Study of Open Source Software Development: the Apache Server”, Proc. ICSE’00, pp. 263-272, 2000
c27da42c78cd6a224fd55f87106a4389 ; [1] K. Berg and O. Svensson. 2018. SZZ Unleashed: Bug Prediction on the Jenkins Core Repository (Open Source Implementations of Bug Prediction Tools on Commit Level). https://doi.org/student-papers/search/publication/8971266 Msc Thesis, Lund University, Sweden.
e56f37731be1b6f7db1d59957a18b5af ; [2] G. Canfora, L. Cerulo, and M. Di Penta. 2007. Identifying Changed Source Code Lines from Version Repositories. In Proc. of the 4th International Workshop on Mining Software Repositories. https://doi.org/10.1109/MSR.2007.14
3207065d3750c835c3841dbefb958bc6 ; [3] Y. Cavalcanti, P. Silveira Neto, I. Machado, T. Vale, E. Almeida, and S. Meira. 2014. Challenges and Opportunities for Software Change Request Repositories: A Systematic Mapping Study. Journal of Software: Evolution and Process 26, 7 (2014), 620–653. https://doi.org/10.1002/smr.1639
389cd24fb76d2e713bf06317deec6e63 ; [4] J. Correia. 2017. old-szz. https://github.com/intelligentagents/old-szz
3c3f42e4600d95c202a15a120a7160ca ; [5] J. Czerwonka, R. Das, N. Nagappan, A. Tarvo, and A. Teterev. 2011. CRANE: Failure Prediction, Change Analysis and Test Prioritization in Practice âĂŞ Experiences from Windows. In Proc. of the 4th Conference on Software Testing, Verification and Validation. 357–366. https://doi.org/10.1109/ICST.2011.24
adbfcb3eaabfa0522f25022d06288c34 ; [6] M. D’Ambros, M. Lanza, and R. Robbes. 2009. On the Relationship Between Change Coupling and Software Defects. In 2009 16th Working Conference on Reverse Engineering. 135–144. https://doi.org/10.1109/WCRE.2009.19
e0590213883cc58cec08837bda84a10b ; [7] M. de Freitas Farias, R. Novais, M. Junior, L. da Silva Carvalho, M. Mendonca, and R. Spinola. 2016. A Systematic Mapping Study on Mining Software Repositories. In Proc. of the 31st Annual ACM Symposium on Applied Computing. 1472–1479. https://doi.org/10.1145/2851613.2851786
e18f2dfb925ec5cfee073202934726df ; [8] E. Engström, P. Runeson, and M. Skoglund. 2010. A Systematic Review on Regression Test Selection Techniques. Information and Software Technology 52, 1 (2010), 14–30. https://doi.org/10.1016/j.infsof.2009.07.001
19a6eb191fcca7e12eebf9a6ca55ed8a ; [10] M. Godfrey and L. Zou. 2005. Using Origin Analysis to Detect Merging and Splitting of Source Code Entities. Transactions on Software Engineering 31, 2 (2005), 166–181. https://doi.org/10.1109/TSE.2005.28
3bc62702b0b093bbbe8d447c77f810fe ; [12] L. Jonsson, M. Borg, D. Broman, K. Sandahl, S. Eldh, and P. Runeson. 2016. Automated Bug Assignment: Ensemble-based Machine Learning in Large Scale Industrial Contexts. Empirical Software Engineering 21, 4 (2016), 1533–1578.
4b4d1189010996b45137397498a4c039 ; [15] G. Lemaitre, F. Nogueira, and C. Aridas. 2017. Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning. Journal of Machine Learning Research 18, 17 (2017), 1–5.
6b9162f60d0b8f3064d8be69c2f87f5e ; [22] M. Sohn, S. Pearce, A. Loskutov, C. Aniszczyk, C. Halstrick, C. Ranger, D. Borowitz, D. Pursehouse, G. Wagenknecht, J. Nieder, K. Sawicki, M. Kinzler, R. Rosenberg, R. Stocker, S. Zivkov, S. Lay, T. Parker, and T. Wolf. 2017. Eclipse JGit. https: //github.com/eclipse/jgit
67754da7cd421fc6e7e1c9a0f69a7a5d ; [23] O. Svensson and K. Berg. 2018. SZZ Unleashed. https://github.com/wogscpar/ SZZUnleashed
3dfc388fbdf73755d676255b51f1279c ; [25] A. Tornhill. 2017. code-maat. https://github.com/adamtornhill/code-maat
b17d07a4df662dbcf0ae8a6836336a48 ; [1] A. Agresti, Categorical data analysis. JohnWiley & Sons, 2013.
148382006690d053c575507a8dbe0da8 ; [2] N. Bettenburg, M. Nagappan, and A. E. Hassan, “Towards improving statistical modeling of software engineering data: think locally, act globally!” Empirical Software Engineering, vol. 20, no. 2, pp. 294–335, 2015.
800c23f892d18fc5d17faf879aa859d5 ; [7] A. Hajjem, F. Bellavance, and D. Larocque, “Mixedeffects random forest for clustered data,” Journal of Statistical Computation and Simulation, vol. 84, no. 6, pp. 1313–1328, 2014.
430130fc3b9fb6d3bc92c524d4d766ac ; [8] A. Hajjem, D. Larocque, and F. Bellavance, “Generalized mixed effects regression trees,” Statistics & Probability Letters, vol. 126, pp. 114–118, 2017.
f21b9c5f770dcb4f04ce192d6c76bb5c ; [12] ——, “Global vs. local models for cross-project defect prediction,” Empirical Software Engineering, vol. 22, no. 4, pp. 1866–1902, 2017.
d4197a8b86f2a11bbae2d3414fe48059 ; [15] J. Jiarpakdee, C. Tantithamthavorn, H. K. Dam, and J. Grundy, “An empirical study of model-agnostic techniques for defect prediction models,” IEEE Transactions on Software Engineering (TSE), 2020.
75e69251b93991c4b428a7d818b13735 ; [16] J. Jiarpakdee, C. Tantithamthavorn, and J. Grundy, “Practitioners’ perceptions of the goals and visual explanations of defect prediction models,” in Proceedings of the International Conference on Mining Software Repositories (MSR), 2021, p. To Appear.
1fbb971b686ac8d6277867f449766b35 ; [18] J. Jiarpakdee, C. Tantithamthavorn, and C. Treude, “Autospearman: Automatically mitigating correlated metrics for interpreting defect models,” in Proceeding of the International Conference on Software Maintenance and Evolution (ICSME), 2018, pp. 92–103.
2423cd7dad6369e9b6ed3a691e1dfc8f ; [19] ——, “AutoSpearman: Automatically Mitigating Correlated Software Metrics for Interpreting Defect Models,” in ICSME, 2018, pp. 92–103.
02b49eb825f5833ec010ea5f1408d285 ; [20] ——, “The impact of automated feature selection techniques on the interpretation of defect models,” EMSE, 2020.
08980085374087eca6f29b4c7e888a5b ; [26] B. A. Kitchenham, E. Mendes, and G. H. Travassos, “Cross versus within-company cost estimation studies: A systematic review,” IEEE Transactions on Software Engineering, vol. 33, no. 5, 2007.
786f21ef7c02140ae4e599cbb3b71698 ; [27] R. Krishna and T. Menzies, “Bellwethers: A Baseline Method For Transfer Learning,” IEEE Transactions on Software Engineering, p. To appear, 2018.
ec45cfd5238fe858cd285ce706f58721 ; [28] S. Lambiase, A. Cupito, F. Pecorelli, A. De Lucia, and F. Palomba, “Just-in-time test smell detection and refactoring: The darts project,” in Proceedings of the 28th International Conference on Program Comprehension, 2020, pp. 441–445.
3a522b4f2caa900184ad29c6d59a420c ; [29] D. Lin, C. Tantithamthavorn, and A. E. Hassan, “Replication package of our paper,” https://github. com/SAILResearch/suppmaterial-19-dayi-risk data merging jit, 2019, (last visited: Nov 11, 2019).
9ee9ac786fd03940dbb9331144014719 ; [30] J. N. Mandrekar, “Receiver operating characteristic curve in diagnostic test assessment,” Journal of Thoracic Oncology, vol. 5, no. 9, pp. 1315–1316, 2010.
5d7858e1026ab93d43de496391cf4eeb ; [39] J. C. Pinheiro and D. M. Bates, “Mixed-effects models in s and s-plus springer,” New York, 2000.
1f23510605ee062d9fe9ffedb3950210 ; [42] D. Rajapaksha, C. Tantithamthavorn, J. Jiarpakdee, C. Bergmeir, J. Grundy, and W. Buntine, “SQAPlanner: Generating Data-Informed Software Quality Improvement Plans,” arXiv preprint arXiv:2102.09687, 2021.
5de6836a4a8b5eb929fdcdc3c2aa6fd7 ; [50] C. Tantithamthavorn, J. Jiarpakdee, and J. Grundy, “Explainable AI for Software Engineering,” arXiv preprint arXiv:2012.01614, 2020.
0281d68e6505823e191bbbc5b228cbce ; [55] P. Thongtanunam and A. E. Hassan, “Review dynamics and their impact on software quality,” in IEEE Transaction on Software Engineering (TSE), 2020, p. to appear.
e4111c75375af3809c1fc3a0e213560f ; [59] J. Wang, E. R. Gamazon, B. L. Pierce, B. E. Stranger, H. K. Im, R. D. Gibbons, N. J. Cox, D. L. Nicolae, and L. S. Chen, “Imputing gene expression in uncollected tissues within and beyond gtex,” The American Journal of Human Genetics, vol. 98, no. 4, pp. 697–708, 2016.
574f6ee00b73e9436f4bbe7ac6a24573 ; [60] S. Yathish, J. Jiarpakdee, P. Thongtanunam, and C. Tantithamthavorn, “Mining Software Defects: Should We Consider Affected Releases?” in ICSE, 2019, pp. 654– 665.
40587e91813f22c203aced50f654add4 ; [39] F. Zhang, A. Mockus, I. Keivanloo, and Y. Zou, “Towards building a universal defect prediction model with rank transformed predictors,” Empirical Software Engineering, vol. 21, no. 5, pp. 2107–2145, 2016.
b018da9f767dba86396dc4b5dba20ba2 ; [1] S. Bird, E. Loper, and E. Klein. Natural Language Pro- cessing with Python. O'Reilly Media Inc, 2009.
a147e136bfa717592f2bd70bd4b53b17 ; [2] J. M. Chambers and T. J. Hastie, editors. Statistical Models in S. Wadsworth and Brooks/Cole, 1992.
24bd574f37c5ea29adbadcadced0a656 ; [3] R. Dyer, H. A. Nguyen, H. Rajan, and T. N. Nguyen. Boa: A Language and Infrastructure for Analyzing Ultra-Large-Scale Software Repositories. In Proc. of the 35th Int'l Conf. on Software Engineering (ICSE), pages 422{431, 2013.
fdec018bdef19adb0cd13e167523c0b3 ; [4] B. Efron. How Biased is the Apparent Error Rate of a Prediction Rule? Journal of the American Statistical Association, 81(394):461{470, 1986.
4a6134b35e69955d5f9d9754c00210dc ; [7] Y. Kamei, E. Shihab, B. Adams, A. E. Hassan, A. Mockus, A. Sinha, and N. Ubayashi. A Large- Scale Empirical Study of Just-in-Time Quality Assurance. Transactions on Software Engineering (TSE), 39(6):757{773, 2013.
da41bceff97b1cf96078ffb249b3d66e ; [8] S. Kim, E. J.Whitehead, Jr., and Y. Zhang. Classifying software changes: Clean or buggy? Transactions on Software Engineering (TSE), 34(2):181{196, 2008.
d1d0a8afd5237214114e35bb23d47971 ; [11] T. Myer and B. Whately. SpamBayes: Effective opensource, Bayesian based, email classification system. In Proc. of the 7th Annual Collaboration, Electronic Mes- saging, Anti-Abuse and Spam Conference, 2004.
d77957226e7461f87123bfb8cad9b7da ; [13] E. Shihab, A. E. Hassan, B. Adams, and Z. M. Zhang. An Industrial Study on the Risk of Software Change. In Proc. of the 20th Symposium on the Foundations of Software Engineering (FSE), pages 62:1{62:11, 2012.
bc9289423bbc34bc836f382ae7ef31a8 ; [1] “The heartbleed bug,” [Accessed 20-March-2017]. [Online]. Available: http://heartbleed.com/
47f9fcbc3e5be67567b8ad67b79e5fbf ; [2] S. Neuhaus, T. Zimmermann, C. Holler, and A. Zeller, “Predicting vulnerable software components,” in Proceedings of the 14th ACM conference on Computer and communications security. ACM, 2007, pp. 529–540.
9cd3adabd7dad0b479d60c3ee58199fa ; [3] Y. Shin and L. Williams, “An empirical model to predict security vulnerabilities using code complexity metrics,” in Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement. ACM, 2008, pp. 315–317.
f88e31d69c7e5ca967acc6ba1dd8b229 ; [5] R. Scandariato, J. Walden, A. Hovsepyan, and W. Joosen, “Predicting vulnerable software components via text mining,” IEEE Transactions on Software Engineering, vol. 40, no. 10, pp. 993–1006, 2014.
5c8194964605a0bdaa0e8f89817763cc ; [6] H. Perl, S. Dechand, M. Smith, D. Arp, F. Yamaguchi, K. Rieck, S. Fahl, and Y. Acar, “Vccfinder: Finding potential vulnerabilities in open-source projects to assist code audits,” in Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security. ACM, 2015, pp. 426–437.
2d506c20c1c42f768839a6859741ada4 ; [8] “Flawfinder homepage,” [Accessed 20-March-2017]. [Online]. Available: http://www.dwheeler.com/flawfinder/
33d7923362df911160a679da3ed33877 ; [9] J. Walden, J. Stuckman, and R. Scandariato, “Predicting vulnerable components: Software metrics vs text mining,” in Software Reliability Engineering (ISSRE), 2014 IEEE 25th International Symposium on. IEEE, 2014, pp. 23–33.
cc9ef6ad9805b5f03c006c090d0602e5 ; [10] A. Meneely, H. Srinivasan, A. Musa, A. R. Tejeda, M. Mokary, and B. Spates, “When a patch goes bad: Exploring the properties of vulnerability-contributing commits,” in 2013 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement. IEEE, 2013, pp. 65–74.
675c271a385528a52186053e20f45e7e ; [11] A. Bosu, J. C. Carver, M. Hafiz, P. Hilley, and D. Janni, “Identifying the characteristics of vulnerable code changes: An empirical study,” in Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering. ACM, 2014, pp. 257–268.
5998626f3c23057657fa17534d38268d ; [12] “Mozilla foundations security advisories,” [Accessed 31-March-2017]. [Online]. Available: https://www.mozilla.org/en-US/security/advisories/
c0ba0982fb039465490ee84ef1c7a713 ; [14] F. Massacci, S. Neuhaus, and V. H. Nguyen, “After-life vulnerabilities: a study on firefox evolution, its vulnerabilities, and fixes,” in International Symposium on Engineering Secure Software and Systems. Springer, 2011, pp. 195–208.
303e9ef0c5c6aa9f41909694fa2efc05 ; [16] “Github api v3 | github developer guide,” [Accessed 12-March-2017]. [Online]. Available: https://developer.github.com/v3/
b07ce1497e3084699ea54f39d0244094 ; [19] M. Piancó, B. Fonseca, and N. Antunes, “Code change history and software vulnerabilities,” in Dependable Systems and Networks Workshop, 2016 46th Annual IEEE/IFIP International Conference on. IEEE, 2016, pp. 6–9.
f19500cffe6a5e8f31499bea9557cac7 ; [20] M. P. Fay and M. A. Proschan, “Wilcoxon-mann-whitney or t-test? on assumptions for hypothesis tests and multiple interpretations of decision rules,” Statistics surveys, vol. 4, p. 1, 2010.
4cd73c188be356ebf5f32d046607f31b ; [21] R. E. McGrath and G. J. Meyer, “When effect sizes disagree: the case of r and d.” Psychological methods, vol. 11, no. 4, p. 386, 2006.
7a2c21a083f9d7e0d92fde0f6bc55f2a ; [22] J. L. Myers, A. Well, and R. F. Lorch, Research design and statistical analysis. Routledge, 2010.
30c7c95b4f01f6237bb41e0fcc294ce9 ; [23] “scikit-learn: Machine learning in python,” [Accessed 30-March-2017]. [Online]. Available: http://scikit-learn.org/stable/
18a7fc7632c4a9272c2e73b522acdc09 ; [1] M. Tufano, F. Palomba, G. Bavota, M. Di Penta, R. Oliveto, A. De Lucia, and D. Poshyvanyk, “There and back again: Can you compile that snapshot?” Journal of Software: Evolution and Process, vol. 29, no. 4, p. e1838, 2017.
67cde7b408db427820280e4a85387247 ; [4] L.-P. Querel and P. C. Rigby, “WarningsGuru, research scripts and data for replication,” https://doi.org/10.5281/zenodo.3747582.
6a93c75c42339a8614fd68798235d208 ; [5] ——, “WarningsGuru tool GitHub Repo,” https://github.com/louisq/ warningsguru.
5564f02d4264aa15a3d85bc630d44a8b ; [6] N. Ayewah, W. Pugh, J. D. Morgenthaler, J. Penix, and Y. Zhou, “Evaluating static analysis defect warnings on production software,” in Proceedings of the 7th ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software Tools and Engineering, ser. PASTE ’07. New York, NY, USA: ACM, 2007, pp. 1–8. [Online]. Available: http://doi.acm.org/10.1145/1251535.1251536
fbd8c5269cc81c7163735a51d5b2f768 ; [7] M. Beller, R. Bholanath, S. McIntosh, and A. Zaidman, “Analyzing the state of static analysis: A large-scale evaluation in open source software,” in 2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER), vol. 1, March 2016, pp. 470–481.
950048fecdb9be1240cb7a6cbbe757d7 ; [8] C. Couto, J. E. Montandon, C. Silva, and M. T. Valente, “Static correspondence and correlation between field defects and warnings reported by a bug finding tool,” vol. 21, no. 2, 2013, pp. 241–257. [Online]. Available: http://dx.doi.org/10.1007/s11219-011-9172-5
d58aebedf6b892231eb39d83a593e0e9 ; [13] The Apache Software Foundation, “Maven - POM Reference,” 2016, https://maven.apache.org/pom.html.
a0c8a3c94d76ab12d2f665944cfa248c ; [14] KDM Analytics, “Blade Tool Output Integration Framework (TOIF),” 2016, http://www.kdmanalytics.com/toif/.
0dc75d74a36932ba9860f7b88accbb70 ; [15] MITRE Corporation, “Common Weakness Enumeration (CWE),” 2016, https://cwe.mitre.org/.
429246fe27f4daef79387bb932afdc70 ; [16] H. Tang, T. Lan, D. Hao, and L. Zhang, “Enhancing defect prediction with static defect analysis,” in Proceedings of the 7th Asia-Pacific Symposium on Internetware, ser. Internetware ’15. New York, NY, USA: ACM, 2015, pp. 43–51. [Online]. Available: http://doi.acm.org/10.1145/2875913.2875922
049e2ea5408addd8107089256cc387bd ; [17] M. G. Nanda, M. Gupta, S. Sinha, S. Chandra, D. Schmidt, and P. Balachandran, “Making defect-finding tools work for you,” in Proceedings of the 32Nd ACM/IEEE International Conference on Software Engineering - Volume 2, ser. ICSE ’10. New York, NY, USA: ACM, 2010, pp. 99–108. [Online]. Available: http://doi.acm.org/10.1145/1810295.1810310
61a550bea0f4bb3125c3ccb486e9fa8a ; [20] P. C. Rigby, D. M. German, L. Cowen, and M.-A. Storey, “Peer review on open-source software projects: Parameters, statistical models, and theory,” ACM Trans. Softw. Eng. Methodol., vol. 23, no. 4, Sep. 2014. [Online]. Available: https://doi.org/10.1145/2594458
c2277068b7975f34f65caf486e442b8e ; [23] C. Bird, N. Nagappan, P. Devanbu, H. Gall, and B. Murphy, “Does distributed development affect software quality?: An empirical case study of windows vista,” vol. 52, no. 8. New York, NY, USA: ACM, Aug. 2009, pp. 85–93. [Online]. Available: http://doi.acm.org/10.1145/1536616.1536639
858dd4ea9c9cb2d7c848064d47d4819a ; [24] J. D. Herbsleb and A. Mockus, “An empirical study of speed and communication in globally distributed software development,” vol. 29, no. 6. Piscataway, NJ, USA: IEEE Press, Jun. 2003, pp. 481–494. [Online]. Available: http://dx.doi.org/10.1109/TSE.2003.1205177
82884b0393b836f4b5aa709db8ee9743 ; [25] F. Camilo, A. Meneely, and M. Nagappan, “Do bugs foreshadow vulnerabilities? a study of the chromium project,” in Mining Software Repositories (MSR), 2015 IEEE/ACM 12th Working Conference on. IEEE, 2015, pp. 269–279.
71fa800f51db27805f263c8bc7c3168b ; [26] L. Averell and A. Heathcote, “The form of the forgetting curve and the fate of memories,” vol. 55, no. 1. Elsevier, 2011, pp. 25–35.
28270a7ef123d0ccdde5cbf7c3500217 ; [28] F. Wedyan, D. Alrmuny, and J. M. Bieman, “The effectiveness of automated static analysis tools for fault detection and refactoring prediction,” in Proceedings of the 2009 International Conference on Software Testing Verification and Validation, ser. ICST ’09. Washington, DC, USA: IEEE Computer Society, 2009, pp. 141–150. [Online]. Available: http://dx.doi.org/10.1109/ICST.2009.21
eebce8d2b0d3147542e3c5a6acbc8810 ; [1] G. Rodr´ıguez-P´erez, A. Zaidman, A. Serebrenik, G. Robles, and J. M. Gonzalez-Barahona, “What if a bug has a different origin? making sense of bugs without an explicit bug introducing change,” in Proceedings of the 12th International Symposium on Empirical Software Engineering and Measurement, p. 52, ACM, 2018.
fc3dcbb026b745fd6d7e5ef1a748bd5a ; [2] G. Rodr´ıguez-P´erez, G. Robles, A. Serebrenik, A. Zaidman, D. M. German, and J. M. Gonzalez-Barahona, “How bugs are born: A model to identify how bugs are introduced in software components,” Empirical Software Engineering, 2019.
f02aabee0b6208c86cbc04b1c1e3b94c ; [13] A. Mockus, “Missing data in software engineering,” in Guide to advanced empirical software engineering, pp. 185–200, Springer, 2008.
b168085e3dab864931d956daa55a21ca ; [17] A. Zeller, W. Hughes, J. Lavery, K. Doran, C. T. Morrison, R. T. Snodgrass, and R. F. St¨ark, “Causes and effects in computer programs,” in Proceedings of the 5th InternationalWorkshop on Computer, pp. 482–508, 2011.
a2ad3a0455c1fc01c8659cc29e69a019 ; [18] D. M. German, A. E. Hassan, and G. Robles, “Change impact graphs: Determining the impact of prior codechanges,” Information and Software Technology, vol. 51, no. 10, pp. 1394–1408, 2009.
5da75a8f9ec2ba5786e113e1b81fb400 ; [21] A. Ahluwalia, D. Falessi, and M. Di Penta, “Snoring: a noise in defect prediction datasets,” in Proceedings of the 16th International Conference on Mining Software Repositories, pp. 63–67, IEEE Press, 2019.
1d7c15b15fd1de5d4e10a656f4671dda ; [33] G. Rodr´ıguez-P´erez, J. M. Gonzalez-Barahona, G. Robles, D. Dalipaj, and N. Sekitoleko, “Bugtracking: A tool to assist in the identification of bug reports,” in IFIP International Conference on Open Source Systems, pp. 192–198, Springer, 2016.
a8b406bbc074583567059d09abacfbe9 ; [35] C. Seiffert, T. M. Khoshgoftaar, J. Van Hulse, and A. Folleco, “An empirical study of the classification performance of learners on imbalanced and noisy software quality data,” Information Sciences, vol. 259, pp. 571–595, 2014.
00d1fc980ca214d28e55c503a8a4291b ; [40] P. E. McKight and J. Najab, “Kruskal-wallis test,” The corsini encyclopedia of psychology, pp. 1–1, 2010.
f530efe14384fc13cdc89f0ce4555a1b ; [41] E. Whitley and J. Ball, “Statistics review 6: Nonparametric methods,” Critical care, vol. 6, no. 6, p. 509, 2002.
09df1ed7ab1b1b2f8ce0c838bc485cd7 ; [46] W. Maalej and H. Nabil, “Bug report, feature request, or simply praise? on automatically classifying app reviews,” in IEEE 23rd international requirements engineering conference (RE), pp. 116–125, IEEE, 2015.
e924f9f96232dab3426d26ef7fa75c95 ; [49] M. Wen, R. Wu, and S.-C. Cheung, “Locus: Locating bugs from software changes,” in 31st IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 262–273, IEEE, 2016.
32f4c6c92f2eadcfcabdf4ed8b65b453 ; [50] C. Wohlin, P. Runeson, M. H¨ ost, M. C. Ohlsson, B. Regnell, and A. Wessl´en, Experimentation in software engineering. Springer Science & Business Media, 2012.
62b23acdf1c2d62b2117825166ab4bca ; [51] P. Runeson, M. Host, A. Rainer, and B. Regnell, Case study research in software engineering: Guidelines and examples. John Wiley & Sons, 2012.
35470b55b094d19d4673538f74b40114 ; [52] S. Easterbrook, J. Singer, M.-A. Storey, and D. Damian, “Selecting empirical methods for software engineering research,” in Guide to advanced empirical software engineering, pp. 285–311, Springer, 2008.
