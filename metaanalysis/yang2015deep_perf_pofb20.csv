#
# In Yang et al.~\cite{yang2015deep}
#
# TABLE IV. POFB20 VALUES OF DEEPER AND THE TWO BASELINES
#
# 10 times ten-fold cross validation
#
# we use the multiples of 1000 instances for simplicity
#
# We compare Deeper against two baselines. 
#
# The first baseline
# is an approach using a standard Logistic Regression.
# For this baseline, we ignore unbalanced-data preprocessing
# and don’t use DBN. It is referred to as LR in the following
# text. 
#
# The second baseline is the approach proposed by Kamei
# et al. [1]. The approach uses Random Under-Sampling and
# Logistic Regression but doesn’t use DBN. It is referred to as
# Kamei et al.’s approach in the following text.''
#
# To compute cost-effectiveness, given a
# number of changes, we firstly sort them according to their
# likelihood to be buggy. We then simulate to review the changes
# one-by-one from the highest ranked change to the lowest
# and record buggy changes found. Using this process we can
# obtain the percentage of buggy changes found when reviewing
# different percentages of lines of code (1% to 100%).
#
Project,LR(%),Kamei_et_al.’s(%),Deeper(%)
Bugzilla,21.35,21.44,42.80
Columba,12.52,12.29,41.00
JDT,18.31,17.79,55.77
Platform,25.71,24.92,61.87
Mozilla,18.85,18.13,58.09
PostgreSQL,17.82,18.38,46.70
Average,19.09,18.82,51.04
