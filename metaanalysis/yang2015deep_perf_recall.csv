#
# In Yang et al.~\cite{yang2015deep}
#
# TABLE VI. RECALL OF DEEPER AND THE TWO BASELINES
#
# 10 times ten-fold cross validation
#
# we use the multiples of 1000 instances for simplicity
#
# ``We compare Deeper against two baselines. 
#
# The first baseline
# is an approach using a standard Logistic Regression.
# For this baseline, we ignore unbalanced-data preprocessing
# and don’t use DBN. It is referred to as LR in the following
# text. 
#
# The second baseline is the approach proposed by Kamei
# et al. [1]. The approach uses Random Under-Sampling and
# Logistic Regression but doesn’t use DBN. It is referred to as
# Kamei et al.’s approach in the following text.''
#
# To compute cost-effectiveness, given a
# number of changes, we firstly sort them according to their
# likelihood to be buggy. We then simulate to review the changes
# one-by-one from the highest ranked change to the lowest
# and record buggy changes found. Using this process we can
# obtain the percentage of buggy changes found when reviewing
# different percentages of lines of code (1% to 100%).
# 
#
#
Project,LR,Kamei_et_al.’s,Deeper
Bugzilla,0.4026,0.7027,0.7207
Columba,0.3104,0.6486,0.6703
JDT,0.0304,0.6613,0.6883
Platform,0.0320,0.7085,0.7003
Mozilla,0.0397,0.6084,0.6820
PostgreSQL,0.2819,0.6016,0.6799
