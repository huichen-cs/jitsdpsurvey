#
# In Yang et al.~\cite{yang2015deep}
#
# TABLE V. PRECISION OF DEEPER AND THE TWO BASELINES
#
# 10 times ten-fold cross validation
#
# we use the multiples of 1000 instances for simplicity
#
# ``We compare Deeper against two baselines. 
#
# The first baseline
# is an approach using a standard Logistic Regression.
# For this baseline, we ignore unbalanced-data preprocessing
# and don’t use DBN. It is referred to as LR in the following
# text. 
#
# The second baseline is the approach proposed by Kamei
# et al. [1]. The approach uses Random Under-Sampling and
# Logistic Regression but doesn’t use DBN. It is referred to as
# Kamei et al.’s approach in the following text.''
#
# To compute cost-effectiveness, given a
# number of changes, we firstly sort them according to their
# likelihood to be buggy. We then simulate to review the changes
# one-by-one from the highest ranked change to the lowest
# and record buggy changes found. Using this process we can
# obtain the percentage of buggy changes found when reviewing
# different percentages of lines of code (1% to 100%).
# 
Project,LR,Kamei_et_al.’s,Deeper
Bugzilla,0.5106,0.6147,0.6264
Columba,0.4148,0.5550,0.5493
JDT,0.0568,0.3616,0.3769
Platform,0.0603,0.3496,0.3833
Mozilla,0.0742,0.2058,0.2213
PostgreSQL,0.4014,0.5480,0.5463
